{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSy-sfxOsclS"
      },
      "source": [
        "# CS 447 Homework 2 $-$ Word Embeddings \\& Text Classification with Neural Networks\n",
        "In this homework, you will first train word embeddings using the continuous-bag-of-words (CBOW) method. Then, you will build a convolutional neural network (CNN) classifier to detect the sentiment of movie reviews using the IMDb movie reviews dataset.\n",
        "\n",
        "In addition to the Pytorch tutorial we have provided online, we highly recommend that you take a look at the PyTorch tutorials before starting this assignment:\n",
        "<ul>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\">https://pytorch.org/tutorials/beginner/pytorch_with_examples.html</a>\n",
        "<li><a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">https://pytorch.org/tutorials/beginner/data_loading_tutorial.html</a>\n",
        "<li><a href=\"https://github.com/yunjey/pytorch-tutorial\">https://github.com/yunjey/pytorch-tutorial</a>\n",
        "</ul>\n",
        "\n",
        "<font color='green'><b>Hint:</b> While you work, we suggest that you keep your hardware accelerator set to \"CPU\" (the default for Colab). However, when you have finished debugging and are ready to train your models, you should select \"GPU\" as your runtime type. This will speed up the training of your models. You can find this by going to <TT>Runtime > Change Runtime Type</TT> and select \"GPU\" from the dropdown menu.</font>\n",
        "\n",
        "We have imported all the libraries you need to do this homework. <b>You should not import any extra libraries. Furthermore, you should not write any code outside of TODO sections.</b> If you do, the autograder will fail to run your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCBhL7pR9E3N"
      },
      "source": [
        "# Part 1: Continuous-Bag-of-Words (CBOW) Embeddings [50 points]\n",
        "\n",
        "In the first part of this assignment you will learn dense word embeddings based on the word2vec paradigm. In particular, you will use the continuous-bag-of-words approach, which trains a model to predict a word based on the embeddings of surrounding words. For example, in the sentence \"the man walks the dog in the park\", the embeddings for the words (\"man, \"walks\", \"dog\", \"in\") will be used to predict the word \"the\" (if your context size is 2 on each side of the target word)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hw9Zahp38Iv"
      },
      "source": [
        "## Download \\& Preprocess the Data\n",
        "First we will download the dataset using [torchtext](https://torchtext.readthedocs.io/en/latest/index.html), which is a package that supports NLP for PyTorch.\n",
        "\n",
        "Unfortunately, you have to install the <TT>torchdata</TT> package on the Colab machine in order to access the data. To do this, run the cell below (you may need to click the \"Restart Runtime\" button when it finishes). You will have to do this every time you return to work on the homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvIRroBT9Hgf",
        "outputId": "0ed34fd3-e597-47cc-817b-a926e0af2796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata==0.5.1\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.1) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata==0.5.1) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.5.1) (2.10)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1 urllib3-1.26.14\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8Ak_A674YAT",
        "outputId": "66b50d8b-9a13-45b1-b172-5dec4c34c5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if __name__=='__main__':\n",
        "    print('Using device:', DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLbs3wht5weP"
      },
      "source": [
        "Now, we download the data. As with Homework 1, we will use WikiText-2, a corpus of high-quality Wikipedia articles. The dataset was originally introduced in the following paper: https://arxiv.org/pdf/1609.07843v1.pdf. A raw version of the data can easily be viewed here: https://github.com/pytorch/examples/tree/master/word_language_model/data/wikitext-2.preprocess \n",
        "\n",
        "After downloading the data, we preprocess the text as in Homework 1. <i>You do not need to edit this code.</i>\n",
        "\n",
        "* <b>Sentence splitting:</b>&nbsp;&nbsp;&nbsp;&nbsp;In this homework, we are interested in modeling individual sentences, rather than longer chunks of text such as paragraphs or documents. The WikiTest dataset provides paragraphs; thus, we provide a simple method to identify individual sentences by splitting paragraphs at punctuation tokens (\".\",  \"!\",  \"?\").\n",
        "\n",
        "* <b>Sentence markers:</b>&nbsp;&nbsp;&nbsp;&nbsp;For both training and testing corpora, each sentence must be surrounded by a start-of-sentence (`<s>`) and end-of-sentence marker (`/s`). These markers will allow your models to generate sentences that have realistic beginnings and endings.\n",
        "\n",
        "* <b>Unknown words:</b>&nbsp;&nbsp;&nbsp;&nbsp;In order to deal with unknown words, all words that do not appear in the vocabulary must be replaced with a special token for unknown words (`<UNK>`). The WikiText dataset has already done this, and you can read about the method in the paper above. When unknown words are encountered in the test corpus, they should be treated as that special token instead.\n",
        "\n",
        "We provide you with preprocessing code here, and you should not modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lbkr6F2N9lvd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "### DO NOT EDIT ###\n",
        "\n",
        "# Constants (feel free to use these in your code, but do not change them)\n",
        "CBOW_START = \"<s>\"   # Start-of-sentence token\n",
        "CBOW_END = \"</s>\"    # End-of-sentence-token\n",
        "CBOW_UNK = \"<UNK>\"   # Unknown word token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rnSyKLij9ocH"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torchtext\n",
        "import random\n",
        "import sys\n",
        "\n",
        "def cbow_preprocess(data, vocab=None, do_lowercase=True):\n",
        "    final_data = []\n",
        "    lowercase = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "    for paragraph in data:\n",
        "        paragraph = [x if x != '<unk>' else CBOW_UNK for x in paragraph.split()]\n",
        "        if vocab is not None:\n",
        "            paragraph = [x if x in vocab else CBOW_UNK for x in paragraph]\n",
        "        if paragraph == [] or paragraph.count('=') >= 2: continue\n",
        "        sen = []\n",
        "        prev_punct, prev_quot = False, False\n",
        "        for word in paragraph:\n",
        "            if prev_quot:\n",
        "                if word[0] not in lowercase:\n",
        "                    final_data.append(sen)\n",
        "                    sen = []\n",
        "                    prev_punct, prev_quot = False, False\n",
        "            if prev_punct:\n",
        "                if word == '\"':\n",
        "                    prev_punct, prev_quot = False, True\n",
        "                else:\n",
        "                    if word[0] not in lowercase:\n",
        "                        final_data.append(sen)\n",
        "                        sen = []\n",
        "                        prev_punct, prev_quot = False, False\n",
        "            if word in {'.', '?', '!'}: prev_punct = True\n",
        "            sen += [word]\n",
        "        if sen[-1] not in {'.', '?', '!', '\"'}: continue # Prevent a lot of short sentences\n",
        "        final_data.append(sen)\n",
        "    vocab_was_none = vocab is None\n",
        "    if vocab is None:\n",
        "        vocab = {}\n",
        "    for i in range(len(final_data)):\n",
        "        # Make words lowercase for this assignment\n",
        "        final_data[i] = [x.lower() if do_lowercase and x != CBOW_UNK else x for x in final_data[i]]\n",
        "        final_data[i] = [CBOW_START] + final_data[i] + [CBOW_END]\n",
        "        if vocab_was_none:\n",
        "            for word in final_data[i]:\n",
        "                vocab[word] = vocab.get(word, 0) + 1\n",
        "    return final_data, vocab\n",
        "\n",
        "def getDataset():\n",
        "    dataset = torchtext.datasets.WikiText2(root='.data', split=('train',))\n",
        "    train_dataset, vocab = cbow_preprocess(dataset[0])\n",
        "    return train_dataset, vocab\n",
        "\n",
        "if __name__=='__main__':\n",
        "    sentences, vocab = getDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRDXzF956c6n"
      },
      "source": [
        "Run the next cell to see 10 random sentences of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLSERYow7Cbt",
        "outputId": "7008d406-fa65-48db-9a4a-85f97a995183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'it', 'was', 'released', 'internationally', 'in', 'france', 'and', 'the', 'united', 'kingdom', 'in', '1982', ',', 'and', 'broadcast', 'on', 'various', 'american', 'cable', 'television', 'channels', '.', '</s>']\n",
            "['<s>', 'david', 'lee', 'roth', \"'s\", 'self', '@-@', 'titled', 'video', 'consisted', 'of', 'promotional', 'clips', 'created', 'for', 'his', 'debut', 'solo', 'ep', 'crazy', 'from', 'the', 'heat', 'and', 'album', 'eat', \"'\", 'em', 'and', 'smile', '.', '</s>']\n",
            "['<s>', 'defender', 'keith', 'lowe', ',', 'of', 'cheltenham', ',', 'and', 'goalkeeper', 'nick', 'pope', ',', 'of', 'charlton', 'athletic', ',', 'were', 'signed', 'on', 'loan', 'until', 'january', '2014', '.', '</s>']\n",
            "['<s>', 'the', 'contest', 'was', 'best', 'of', 'three', ',', 'two', 'falls', 'with', 'jackets', 'and', 'one', 'without', ',', 'and', 'maeda', 'won', 'the', 'two', 'with', 'jackets', 'and', 'lost', 'the', 'one', 'without', '.', '</s>']\n",
            "['<s>', 'in', 'addition', 'to', 'the', 'storms', 'which', 'attained', 'at', 'least', 'tropical', 'storm', 'strength', 'in', '1940', ',', 'five', 'additional', 'tropical', 'depressions', 'were', 'analyzed', 'by', 'the', 'hurdat', 'reanalysis', 'project', 'to', 'have', 'developed', 'during', 'the', 'season', '.', '</s>']\n",
            "['<s>', 'white', 'pine', 'church', 'of', 'the', 'brethren', '<UNK>', 'at', 'the', 'church', 'from', 'the', '1870s', 'until', 'the', 'construction', 'of', 'their', 'own', 'church', 'building', 'in', '1907', '.', '</s>']\n",
            "['<s>', 'for', 'instance', ',', 'ln', '@-@', 'suo', 'flew', '36', '@,@', '000', 'hours', 'with', '76', '@,@', '000', 'landings', '.', '</s>']\n",
            "['<s>', 'in', 'fourth', 'place', ',', 'max', 'verstappen', 'was', 'faster', 'than', 'teammate', 'ricciardo', 'for', 'the', 'first', 'time', ',', 'who', 'finished', 'fifth', ',', 'ahead', 'of', 'räikkönen', '.', '</s>']\n",
            "['<s>', '<UNK>', 'live', 'by', 'espn', ',', 'the', 'crimson', 'team', 'of', 'offensive', 'starters', 'defeated', 'the', 'white', 'team', 'of', 'defensive', 'starters', 'by', 'a', 'final', 'score', 'of', '23', '–', '17', 'before', '91', '@,@', '312', 'fans', 'in', 'bryant', '–', 'denny', 'stadium', '.', '</s>']\n",
            "['<s>', 'after', 'years', 'of', 'experimenting', 'with', '\"', 'standard', 'fare', '\"', ',', 'he', 'wrote', 'and', 'filmed', 'his', 'first', 'real', 'production', 'as', 'a', 'senior', 'in', 'high', 'school', 'at', '<UNK>', '<UNK>', 'using', 'money', 'he', 'earned', 'cleaning', '<UNK>', 'at', 'a', 'pet', 'store', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for x in random.sample(sentences, 10):\n",
        "        print (x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZwVLt4n7ksc"
      },
      "source": [
        "##<font color='red'>TODO:</font> Define the Dataset Class [15 points]\n",
        "In the following cell, we will define the <b>dataset</b> class. The dataset contains input-output pairs for each training example we will provide to the model. You need to implement the following functions: \n",
        "\n",
        "*   <b>` make_training_examples(self)`:</b>  <b>[5 points]</b> Each training example will be a list of <em>context</em> words along with a <em>target</em> word. The context words consist of $c$ words on either side of the target word; hence, each list of context words has size $2c$. The goal will be to have your model predict the target word from the context words. Thus, you must convert each sentence into a series of context-target pairs, as follows:\n",
        "<ul>\n",
        "<li>For each sentence $s=[w_1,w_2,...,w_n]$ and a context size $c$, compute the following (context, target) pairs:<br>&emsp;&emsp;&emsp;&emsp;$([w_1,...,w_c,w_{c+2},...,w_{2c+1}]$, $w_{c+1}$)<br>&emsp;&emsp;&emsp;&emsp;$([w_2,...,w_{c+1},w_{c+3},...,w_{2c+2}]$, $w_{c+2}$)<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\vdots$<br>&emsp;&emsp;&emsp;&emsp;$([w_{n-2c},...,w_{n-c-1},w_{n-c+1},...,w_{n}]$, $w_{n-c}$)<br>For example, suppose your sentence is \"the man walks the dog in the park\" and the context size is $c=2$. Your method should find the following training pairs:<br>&emsp;&emsp;&emsp;&emsp;([\"the\", \"man\", \"the\", \"dog\"], \"walks\")<br>&emsp;&emsp;&emsp;&emsp;([\"man\", \"walks\", \"dog\", \"in\"], \"the\")<br>&emsp;&emsp;&emsp;&emsp;([\"walks\", \"the\", \"in\", \"the\"], \"dog\")<br>&emsp;&emsp;&emsp;&emsp;([\"the\", \"dog\", \"the\", \"park\"], \"in\")<br>Of course, the sentences in your dataset have start- and end-of-sentence tokens as well, which you should treat as any other word.\n",
        "</ul>\n",
        "This function should return a list of <b>all</b> such training pairs.\n",
        "\n",
        "*   <b>` build_dictionaries(self, vocab)`:</b>  <b>[4 points]</b> Creates the dictionaries `word2idx` and `idx2word`. You will represent each word in the vocabulary with a unique index, and keep track of this in these dictionaries. The input `vocab` is a list of words: you must assign indexes in the order the words appear in this list.\n",
        "\n",
        "* <b>`get_context_vector(self, idx)`:</b> Returns a vector representing the <em>context</em> of the `idx`th training example. Specifically, if the context size is $c$, this should be a tensor of $2c$ word indices corresponding to the context words of the `idx`th example. \n",
        "\n",
        "   <font color='green'><b>Hint:</b> You may want to pre-compute and save all context vectors (using word indices rather than the words themselves) in `__init__(...)`, and then access these in `get_context_vector(self, idx)`. This would give you a slight speedup at train time.</font>\n",
        "\n",
        "*   <b>`get_target_index(self, idx) `</b>: Return the target word index for the `idx`th training example.\n",
        "\n",
        "*  <b> ` __len__(self) `: [1 points]</b> Return the total number of training examples in the dataset as an `int`.\n",
        "\n",
        "*   <b>` __getitem__(self, idx)`:</b> <b>[5 points]</b> Return the `idx`th training example as a tuple of `(context_vector, target_word_index)`. You should use the ` get_context_vector(self, idx) ` and ` get_label(self, idx) ` functions here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "beABjh82XyXA"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "from collections import defaultdict\n",
        "\n",
        "class CbowDataset(data.Dataset):\n",
        "    def __init__(self, sentences, vocab, context_size):\n",
        "        ##### DO NOT EDIT #####\n",
        "\n",
        "        assert CBOW_START in vocab and CBOW_END in vocab and CBOW_UNK in vocab\n",
        "        self.sentences = sentences\n",
        "        self.context_size = context_size\n",
        "\n",
        "        self.training_examples = []\n",
        "        self.make_training_examples()\n",
        "\n",
        "        self.word2idx = {} # Mapping of word to index\n",
        "        self.idx2word = {} # Mapping of index to word\n",
        "        self.build_dictionaries(sorted(vocab.keys()))\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        #Precomputing context vectors\n",
        "        \n",
        "\n",
        "    def make_training_examples(self):\n",
        "        '''\n",
        "        Builds a list of context-target_word pairs that will be used as training examples for the model and stores them in \n",
        "        self.training_examples.\n",
        "        Each example is a (context, target_word) tuple, where context is a list of strings of size 2*context_size and \n",
        "        target_word is simply a string.\n",
        "        Returns nothing.\n",
        "        '''     \n",
        "        #print(\"sentences are  :\",self.sentences)\n",
        "        # For each sentence, loop over each word in the sentence. If there are c words before and c words after the word,\n",
        "        # make a (context, word) pair, where context is a list made up of the c words before the word and the c words\n",
        "        # after the word (in the same order they appear in the sentence). Append this (context, word) pair to self.training_examples.\n",
        "        for sent in self.sentences:\n",
        "          #s=[]\n",
        "          for target in range(self.context_size,len(sent) - self.context_size):\n",
        "            #print(sentences[target])\n",
        "              #temp = []\n",
        "              c_temp_left = []\n",
        "              c_temp_right = []\n",
        "              c_temp_left.append(sent[target-self.context_size:target])\n",
        "              c_temp_right.append(sent[target+1:target+self.context_size+1])\n",
        "              \n",
        "              #print(c_temp_left)\n",
        "              #print(c_temp_right)\n",
        "\n",
        "              temp = (c_temp_left[0] + c_temp_right[0] , sent[target])\n",
        "              #print(temp)\n",
        "              #temp.append(self.sentences[target])\n",
        "              #print(temp)\n",
        "              self.training_examples.append(temp)\n",
        "        print(self.training_examples)\n",
        "           \n",
        "    \n",
        "    def build_dictionaries(self, vocab): \n",
        "        '''\n",
        "        Builds the dictionaries self.idx2word and self.word2idx. Make sure that you assign indices\n",
        "        in the order the words appear in vocab (a list of words).\n",
        "        Returns nothing.\n",
        "        ''' \n",
        "        self.vocab = vocab       \n",
        "        #print(\"vocab\", self.vocab)\n",
        "\n",
        "        for i in range(len(self.vocab)):\n",
        "          self.word2idx[self.vocab[i]] = i\n",
        "          self.idx2word[i] = self.vocab[i]\n",
        "\n",
        "        \n",
        "    \n",
        "    def get_context_vector(self, idx):\n",
        "        '''\n",
        "        Returns the context vector (as a torch.tensor) for the training example at index idx.\n",
        "        This is is a tensor containing the indices of each word in the context. \n",
        "        '''\n",
        "        #print(\"These are the training examples: \",self.training_examples)\n",
        "        sent = self.training_examples[idx]\n",
        "        context_words = sent[0]\n",
        "        context_vector = []\n",
        "        for i in context_words:\n",
        "          context_vector.append(self.vocab.index(i))\n",
        "        context_vector_tensor = torch.tensor(context_vector)\n",
        "        #print(\"context_tensors: \",context_vector_tensor)\n",
        "        \n",
        "        assert len(self.training_examples) > 0\n",
        "\n",
        "        \n",
        "        return context_vector_tensor\n",
        "    \n",
        "    def get_target_index(self, idx):\n",
        "        '''\n",
        "        Returns the index of the target word (as type int) of the training example at index idx.\n",
        "        '''\n",
        "        ##### TODO ##### \n",
        "        sent = self.training_examples[idx]\n",
        "        target = sent[1]\n",
        "        target_index = self.vocab.index(target)\n",
        "        #target_tensor = torch.tensor(target_index)\n",
        "\n",
        "        return target_index\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Returns the number of training examples (as type int) in the dataset\n",
        "        '''\n",
        "\n",
        "        return len(self.training_examples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns the context vector (as a torch.tensor) and target index (as type int) of the training example at index idx.\n",
        "        '''\n",
        "        c = self.get_context_vector(idx)\n",
        "        t = self.get_target_index(idx)\n",
        "\n",
        "        return c,t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqmwBVMDkqEQ"
      },
      "source": [
        "##Sanity Check: Dataset Class\n",
        "\n",
        "The code below runs a sanity check for your `CbowDataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug.\n",
        "\n",
        "You do <b>not</b> need to edit this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qapAnsEMeoAq",
        "outputId": "dd257dce-c859-43a7-b0cf-bcd31dbc076c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "['<s>', 'the', 'man', 'walks', 'the', 'dog', 'in', 'the', 'park', '</s>']\n",
            "['<s>', 'i', 'saw', 'the', 'man', 'with', 'the', 'telescope', 'on', 'the', '<UNK>', '</s>']\n",
            "\n",
            "--- TEST: training_examples ---\n",
            "[(['<s>', 'man'], 'the'), (['the', 'walks'], 'man'), (['man', 'the'], 'walks'), (['walks', 'dog'], 'the'), (['the', 'in'], 'dog'), (['dog', 'the'], 'in'), (['in', 'park'], 'the'), (['the', '</s>'], 'park'), (['<s>', 'saw'], 'i'), (['i', 'the'], 'saw'), (['saw', 'man'], 'the'), (['the', 'with'], 'man'), (['man', 'the'], 'with'), (['with', 'telescope'], 'the'), (['the', 'on'], 'telescope'), (['telescope', 'the'], 'on'), (['on', '<UNK>'], 'the'), (['the', '</s>'], '<UNK>')]\n",
            "\tcontext_size: 1 \tPASSED \t\n",
            "[(['<s>', 'the', 'man', 'the', 'dog', 'in'], 'walks'), (['the', 'man', 'walks', 'dog', 'in', 'the'], 'the'), (['man', 'walks', 'the', 'in', 'the', 'park'], 'dog'), (['walks', 'the', 'dog', 'the', 'park', '</s>'], 'in'), (['<s>', 'i', 'saw', 'man', 'with', 'the'], 'the'), (['i', 'saw', 'the', 'with', 'the', 'telescope'], 'man'), (['saw', 'the', 'man', 'the', 'telescope', 'on'], 'with'), (['the', 'man', 'with', 'telescope', 'on', 'the'], 'the'), (['man', 'with', 'the', 'on', 'the', '<UNK>'], 'telescope'), (['with', 'the', 'telescope', 'the', '<UNK>', '</s>'], 'on')]\n",
            "\tcontext_size: 3 \tPASSED \t\n",
            "[(['<s>', 'i', 'saw', 'the', 'man', 'the', 'telescope', 'on', 'the', '<UNK>'], 'with'), (['i', 'saw', 'the', 'man', 'with', 'telescope', 'on', 'the', '<UNK>', '</s>'], 'the')]\n",
            "\tcontext_size: 5 \tPASSED \t\n",
            "\n",
            "--- TEST: idx2word and word2idx dictionaries ---\n",
            "[(['<s>', 'man'], 'the'), (['the', 'walks'], 'man'), (['man', 'the'], 'walks'), (['walks', 'dog'], 'the'), (['the', 'in'], 'dog'), (['dog', 'the'], 'in'), (['in', 'park'], 'the'), (['the', '</s>'], 'park'), (['<s>', 'saw'], 'i'), (['i', 'the'], 'saw'), (['saw', 'man'], 'the'), (['the', 'with'], 'man'), (['man', 'the'], 'with'), (['with', 'telescope'], 'the'), (['the', 'on'], 'telescope'), (['telescope', 'the'], 'on'), (['on', '<UNK>'], 'the'), (['the', '</s>'], '<UNK>')]\n",
            "\tcontext_size: 1 \tPASSED \t\n",
            "[(['<s>', 'the', 'man', 'the', 'dog', 'in'], 'walks'), (['the', 'man', 'walks', 'dog', 'in', 'the'], 'the'), (['man', 'walks', 'the', 'in', 'the', 'park'], 'dog'), (['walks', 'the', 'dog', 'the', 'park', '</s>'], 'in'), (['<s>', 'i', 'saw', 'man', 'with', 'the'], 'the'), (['i', 'saw', 'the', 'with', 'the', 'telescope'], 'man'), (['saw', 'the', 'man', 'the', 'telescope', 'on'], 'with'), (['the', 'man', 'with', 'telescope', 'on', 'the'], 'the'), (['man', 'with', 'the', 'on', 'the', '<UNK>'], 'telescope'), (['with', 'the', 'telescope', 'the', '<UNK>', '</s>'], 'on')]\n",
            "\tcontext_size: 3 \tPASSED \t\n",
            "[(['<s>', 'i', 'saw', 'the', 'man', 'the', 'telescope', 'on', 'the', '<UNK>'], 'with'), (['i', 'saw', 'the', 'man', 'with', 'telescope', 'on', 'the', '<UNK>', '</s>'], 'the')]\n",
            "\tcontext_size: 5 \tPASSED \t\n",
            "\n",
            "--- TEST: len(dataset) ---\n",
            "[(['<s>', 'man'], 'the'), (['the', 'walks'], 'man'), (['man', 'the'], 'walks'), (['walks', 'dog'], 'the'), (['the', 'in'], 'dog'), (['dog', 'the'], 'in'), (['in', 'park'], 'the'), (['the', '</s>'], 'park'), (['<s>', 'saw'], 'i'), (['i', 'the'], 'saw'), (['saw', 'man'], 'the'), (['the', 'with'], 'man'), (['man', 'the'], 'with'), (['with', 'telescope'], 'the'), (['the', 'on'], 'telescope'), (['telescope', 'the'], 'on'), (['on', '<UNK>'], 'the'), (['the', '</s>'], '<UNK>')]\n",
            "\tcontext_size: 1 \tPASSED \t\n",
            "[(['<s>', 'the', 'man', 'the', 'dog', 'in'], 'walks'), (['the', 'man', 'walks', 'dog', 'in', 'the'], 'the'), (['man', 'walks', 'the', 'in', 'the', 'park'], 'dog'), (['walks', 'the', 'dog', 'the', 'park', '</s>'], 'in'), (['<s>', 'i', 'saw', 'man', 'with', 'the'], 'the'), (['i', 'saw', 'the', 'with', 'the', 'telescope'], 'man'), (['saw', 'the', 'man', 'the', 'telescope', 'on'], 'with'), (['the', 'man', 'with', 'telescope', 'on', 'the'], 'the'), (['man', 'with', 'the', 'on', 'the', '<UNK>'], 'telescope'), (['with', 'the', 'telescope', 'the', '<UNK>', '</s>'], 'on')]\n",
            "\tcontext_size: 3 \tPASSED \t\n",
            "[(['<s>', 'i', 'saw', 'the', 'man', 'the', 'telescope', 'on', 'the', '<UNK>'], 'with'), (['i', 'saw', 'the', 'man', 'with', 'telescope', 'on', 'the', '<UNK>', '</s>'], 'the')]\n",
            "\tcontext_size: 5 \tPASSED \t\n",
            "\n",
            "--- TEST: __getitem__(self, idx) ---\n",
            "[(['<s>', 'man'], 'the'), (['the', 'walks'], 'man'), (['man', 'the'], 'walks'), (['walks', 'dog'], 'the'), (['the', 'in'], 'dog'), (['dog', 'the'], 'in'), (['in', 'park'], 'the'), (['the', '</s>'], 'park'), (['<s>', 'saw'], 'i'), (['i', 'the'], 'saw'), (['saw', 'man'], 'the'), (['the', 'with'], 'man'), (['man', 'the'], 'with'), (['with', 'telescope'], 'the'), (['the', 'on'], 'telescope'), (['telescope', 'the'], 'on'), (['on', '<UNK>'], 'the'), (['the', '</s>'], '<UNK>')]\n",
            "\tcontext_size: 1 \tidx: 0 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 1 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 2 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 3 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 4 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 5 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 6 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 7 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 8 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 9 \t \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 10  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 11  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 12  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 13  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 14  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 15  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 16  \t PASSED \t\n",
            "\tcontext_size: 1 \tidx: 17  \t PASSED \t\n",
            "[(['<s>', 'the', 'man', 'the', 'dog', 'in'], 'walks'), (['the', 'man', 'walks', 'dog', 'in', 'the'], 'the'), (['man', 'walks', 'the', 'in', 'the', 'park'], 'dog'), (['walks', 'the', 'dog', 'the', 'park', '</s>'], 'in'), (['<s>', 'i', 'saw', 'man', 'with', 'the'], 'the'), (['i', 'saw', 'the', 'with', 'the', 'telescope'], 'man'), (['saw', 'the', 'man', 'the', 'telescope', 'on'], 'with'), (['the', 'man', 'with', 'telescope', 'on', 'the'], 'the'), (['man', 'with', 'the', 'on', 'the', '<UNK>'], 'telescope'), (['with', 'the', 'telescope', 'the', '<UNK>', '</s>'], 'on')]\n",
            "\tcontext_size: 3 \tidx: 0 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 1 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 2 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 3 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 4 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 5 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 6 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 7 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 8 \t \t PASSED \t\n",
            "\tcontext_size: 3 \tidx: 9 \t \t PASSED \t\n",
            "[(['<s>', 'i', 'saw', 'the', 'man', 'the', 'telescope', 'on', 'the', '<UNK>'], 'with'), (['i', 'saw', 'the', 'man', 'with', 'telescope', 'on', 'the', '<UNK>', '</s>'], 'the')]\n",
            "\tcontext_size: 5 \tidx: 0 \t \t PASSED \t\n",
            "\tcontext_size: 5 \tidx: 1 \t \t PASSED \t\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def sanityCheckCbowDataset():\n",
        "    #\tRead in the sample corpus\n",
        "    test_sents = [['<s>', 'the', 'man', 'walks', 'the', 'dog', 'in', 'the', 'park', '</s>'],\n",
        "            ['<s>', 'i', 'saw', 'the', 'man', 'with', 'the', 'telescope', 'on', 'the', CBOW_UNK, '</s>']]\n",
        "    test_vocab = {'<s>':2, 'the':6, 'man':2, 'walks': 1, 'dog': 1, 'in': 1, 'park': 1, 'i': 1, 'saw': 1, 'with': 1, 'telescope':1, 'on': 1, CBOW_UNK: 1, '</s>': 2}\n",
        "    print(\"Sample dataset:\")\n",
        "    for x in test_sents: print(x)\n",
        "\n",
        "    context_sizes = [1,3,5]\n",
        "\n",
        "    print('\\n--- TEST: training_examples ---')\n",
        "    training_examples_expected = [[(['<s>', 'man'], 'the'), (['the', 'walks'], 'man'), (['man', 'the'], 'walks'), (['walks', 'dog'], 'the'), (['the', 'in'], 'dog'), (['dog', 'the'], 'in'), (['in', 'park'], 'the'), (['the', '</s>'], 'park'), (['<s>', 'saw'], 'i'), (['i', 'the'], 'saw'), (['saw', 'man'], 'the'), (['the', 'with'], 'man'), (['man', 'the'], 'with'), (['with', 'telescope'], 'the'), (['the', 'on'], 'telescope'), (['telescope', 'the'], 'on'), (['on', '<UNK>'], 'the'), (['the', '</s>'], '<UNK>')],\n",
        "                                  [(['<s>', 'the', 'man', 'the', 'dog', 'in'], 'walks'), (['the', 'man', 'walks', 'dog', 'in', 'the'], 'the'), (['man', 'walks', 'the', 'in', 'the', 'park'], 'dog'), (['walks', 'the', 'dog', 'the', 'park', '</s>'], 'in'), (['<s>', 'i', 'saw', 'man', 'with', 'the'], 'the'), (['i', 'saw', 'the', 'with', 'the', 'telescope'], 'man'), (['saw', 'the', 'man', 'the', 'telescope', 'on'], 'with'), (['the', 'man', 'with', 'telescope', 'on', 'the'], 'the'), (['man', 'with', 'the', 'on', 'the', '<UNK>'], 'telescope'), (['with', 'the', 'telescope', 'the', '<UNK>', '</s>'], 'on')],\n",
        "                                  [(['<s>', 'i', 'saw', 'the', 'man', 'the', 'telescope', 'on', 'the', '<UNK>'], 'with'), (['i', 'saw', 'the', 'man', 'with', 'telescope', 'on', 'the', '<UNK>', '</s>'], 'the')]\n",
        "                                 ]\n",
        "    for i in range(len(context_sizes)):\n",
        "        c=context_sizes[i]\n",
        "        test_dataset = CbowDataset(test_sents, test_vocab, c)\n",
        "        has_passed, message = True, ''\n",
        "        training_examples = test_dataset.training_examples\n",
        "        expected = training_examples_expected[i]\n",
        "        if has_passed and len(training_examples) != len(expected):\n",
        "            has_passed, message = False, 'len(training_examples) is incorrect. Expected: ' + str(len(expected)) + '\\tGot: ' + str(len(training_examples))\n",
        "        if has_passed and set([(type(x), len(x)) for x in training_examples]) != {(tuple, 2)}:\n",
        "            has_passed, message = False, 'Each item of training_examples must be a 2-tuple; at least one of your items is not a 2-tuple.'\n",
        "        if has_passed and set([(type(x[0]), type(x[1])) for x in training_examples]) != {(list, str)}:\n",
        "            has_passed, message = False, 'Each item must contain a list of context words and a target word as a string. At least one of your items does not meet this condition.'\n",
        "        if has_passed and sorted(training_examples, key = lambda x: (' '.join(x[0]), x[1])) != sorted(expected, key = lambda x: (' '.join(x[0]), x[1])):\n",
        "            has_passed, message = False, 'training_examples is incorrect (note that the order of the examples does not matter). Expected: '+str(sorted(expected, key = lambda x: (' '.join(x[0]), x[1]))) + '\\tGot: ' + str(sorted(training_examples, key = lambda x: (' '.join(x[0]), x[1])))\n",
        "          \n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tcontext_size:', c, '\\t'+status, '\\t'+message)\n",
        "\n",
        "    print('\\n--- TEST: idx2word and word2idx dictionaries ---')\n",
        "    expected_word2idx = {'</s>': 0, '<UNK>': 1, '<s>': 2, 'dog': 3, 'i': 4, 'in': 5, 'man': 6, 'on': 7, 'park': 8, 'saw': 9, 'telescope': 10, 'the': 11, 'walks': 12, 'with': 13}\n",
        "    expected_idx2word = {0: '</s>', 1: '<UNK>', 2: '<s>', 3: 'dog', 4: 'i', 5: 'in', 6: 'man', 7: 'on', 8: 'park', 9: 'saw', 10: 'telescope', 11: 'the', 12: 'walks', 13: 'with'}\n",
        "    for i in range(len(context_sizes)):\n",
        "        c=context_sizes[i]\n",
        "        test_dataset = CbowDataset(test_sents, test_vocab, c)\n",
        "        has_passed, message = True, ''\n",
        "        word2idx = test_dataset.word2idx\n",
        "        idx2word = test_dataset.idx2word\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and (test_dataset.vocab_size != len(test_dataset.word2idx) or test_dataset.vocab_size != len(test_dataset.idx2word)):\n",
        "            has_passed, message = False, 'dataset.vocab_size (' + str(test_dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(test_dataset.word2idx)) + ') and dataset.idx2word ('+str(len(test_dataset.idx2word)) +').'\n",
        "        if has_passed and (test_dataset.vocab_size != len(expected_word2idx)):\n",
        "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(expected_word2idx)) + '\\tGot: ' + str(test_dataset.vocab_size)\n",
        "        if has_passed and sorted(list(test_dataset.idx2word.keys())) != list(range(0, test_dataset.vocab_size)):\n",
        "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(test_dataset.idx2word.keys())))\n",
        "        if has_passed and sorted(list(test_dataset.word2idx.keys())) != sorted(list(expected_word2idx.keys())):\n",
        "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(sorted(list(expected_word2idx.keys()))) + '\\tGot: ' + str(sorted(list(test_dataset.word2idx.keys())))\n",
        "        if has_passed: # Check that word2idx and idx2word are consistent\n",
        "            widx = sorted(list(test_dataset.word2idx.items())) \n",
        "            idxw = sorted(list([(v,k) for k,v in test_dataset.idx2word.items()]))\n",
        "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
        "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
        "        if has_passed and word2idx != expected_word2idx:\n",
        "            has_passed, message = False, 'Your dataset.word2idx is incorrect. Expected: ' + str(expected_word2idx) + '\\tGot: ' + str(word2idx)\n",
        "        if has_passed and idx2word != expected_idx2word:\n",
        "            has_passed, message = False, 'Your dataset.word2idx is incorrect. Expected: ' + str(expected_idx2word) + '\\tGot: ' + str(idx2word)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tcontext_size:', c, '\\t'+status, '\\t'+message)\n",
        "    \n",
        "    print('\\n--- TEST: len(dataset) ---')\n",
        "    correct_lens = [18,10,2]\n",
        "    for i in range(len(context_sizes)):\n",
        "        c=context_sizes[i]\n",
        "        test_dataset = CbowDataset(test_sents, test_vocab, c)\n",
        "        has_passed = len(test_dataset) == correct_lens[i]\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        if has_passed: message = ''\n",
        "        else: message = 'len(dataset) is incorrect. Expected: ' + str(correct_lens[i]) + '\\tGot: ' + str(len(test_dataset))\n",
        "        print('\\tcontext_size:', c, '\\t'+status, '\\t'+message)\n",
        "    \n",
        "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
        "    for i in range(len(context_sizes)):\n",
        "        c=context_sizes[i]\n",
        "        test_dataset = CbowDataset(test_sents, test_vocab, c)\n",
        "        for j in range(correct_lens[i]):\n",
        "            returned = test_dataset.__getitem__(j)\n",
        "\n",
        "            has_passed, message = True, ''\n",
        "            if has_passed and len(returned) != 2:\n",
        "                has_passed, message = False, 'dataset.__getitem__(idx) must return 2 items. Got ' + str(len(returned)) +' items instead.'\n",
        "            if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != int):\n",
        "                has_passed, message = False, 'The context vector must be a torch.Tensor and the target index must be an int. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
        "            if has_passed and (returned[0].shape != torch.randint(0,100,(2*c,)).shape):\n",
        "                has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct_items[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
        "\n",
        "            status = 'PASSED' if has_passed else 'FAILED'\n",
        "            print('\\tcontext_size:', c, '\\tidx:',str(j),'\\t' if j<10 else '','\\t',status, '\\t'+message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sanityCheckCbowDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZhEl32wk5EM"
      },
      "source": [
        "##<font color='red'>TODO:</font> Define the CBOW Model [20 points]\n",
        "\n",
        "Here, you will define a simple feed-forward neural network that takes in a context vector and predicts the word that completes the context. We provide you with the `CbowModel` class, and you just need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth <b>10 points</b>.\n",
        "\n",
        "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep the PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "osmSxlkFBsx0"
      },
      "outputs": [],
      "source": [
        "class CbowModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, context_size):\n",
        "        '''\n",
        "        vocab_size: Size of the vocabulary\n",
        "        embed_size: Size of your embedding vectors\n",
        "        hidden_size: Size of hidden layer of neural network\n",
        "        context_size: The size of your context window used to generate training examples\n",
        "        '''\n",
        "        super(CbowModel, self).__init__()\n",
        "\n",
        "        self.context_size = context_size\n",
        "\n",
        "        ##### TODO #####\n",
        "        # 1. Create an embedding layer using nn.Embedding, that will take an index in your vocabulary as input\n",
        "        #    (referring to a word) and return a vector of size embed_size (i.e. your embedding vector).\n",
        "        #    Note that providing a word index to nn.Embedding is the same (conceptually) as providing a one-hot\n",
        "        #    vector to nn.Linear (however, nn.Embedding takes sparsity into account, so is more efficient)\n",
        "\n",
        "        # 2. Create a linear layer that projects your embedding vector to a vector of size hidden_size.\n",
        "        \n",
        "        # 3. Create an output linear layer, that projects your hidden vector to a vector the size of your vocabulary.\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.hidden_layer = nn.Linear(embed_size , hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        '''\n",
        "        inputs: Tensor of size [batch_size, 2*context_size]\n",
        "\n",
        "        Returns output: Tensor of size [batch_size, vocab_size]\n",
        "        '''\n",
        "\n",
        "        ##### TODO #####\n",
        "        # 1. Feed the inputs through your embedding layer to get a tensor of size [batch_size, 2*context size, embed_size]\n",
        "        # 2. Average the embedding vectors of each of your context word embeddings (for each example in your batch). \n",
        "        #    Expected size: [batch_size, embed_size]\n",
        "        # 3. Feed this through your linear layer and then a ReLU activation. Expected size: [batch_size, hidden_size]\n",
        "        # 4. Feed this through your output layer and return the result. Expected size [batch_size, vocab_size]\n",
        "        #    Do NOT apply a softmax to the final output - this is done in the training method!\n",
        "        embedded = self.embedding(inputs)\n",
        "        averaged = torch.mean(embedded, dim=1)\n",
        "        hidden = F.relu(self.hidden_layer(averaged)) \n",
        "        output = self.output_layer(hidden)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlw_pe2uNyJ"
      },
      "source": [
        "## Sanity Check: CBOW Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7IJDXGkuQlz",
        "outputId": "b9b5c7e1-8d77-491d-d173-81c45b93b76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tExpected Num. Params: 3082\tYour Num. Params: 3082\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tExpected Num. Params: 3082\tYour Num. Params: 3082\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 128, 'context_size': 2}\tExpected Num. Params: 5834\tYour Num. Params: 5834\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 128, 'context_size': 4}\tExpected Num. Params: 5834\tYour Num. Params: 5834\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tExpected Num. Params: 5450\tYour Num. Params: 5450\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tExpected Num. Params: 5450\tYour Num. Params: 5450\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 128, 'context_size': 2}\tExpected Num. Params: 10250\tYour Num. Params: 10250\n",
            "\tPASSED\tInput: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 128, 'context_size': 4}\tExpected Num. Params: 10250\tYour Num. Params: 10250\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tExpected Num. Params: 99112\tYour Num. Params: 99112\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tExpected Num. Params: 99112\tYour Num. Params: 99112\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 128, 'context_size': 2}\tExpected Num. Params: 165224\tYour Num. Params: 165224\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 128, 'context_size': 4}\tExpected Num. Params: 165224\tYour Num. Params: 165224\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tExpected Num. Params: 133160\tYour Num. Params: 133160\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tExpected Num. Params: 133160\tYour Num. Params: 133160\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 128, 'context_size': 2}\tExpected Num. Params: 201320\tYour Num. Params: 201320\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 128, 'context_size': 4}\tExpected Num. Params: 201320\tYour Num. Params: 201320\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([1, 4])\tExpected Output Shape: torch.Size([1, 10])\tYour Output Shape: torch.Size([1, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([5, 4])\tExpected Output Shape: torch.Size([5, 10])\tYour Output Shape: torch.Size([5, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([500, 4])\tExpected Output Shape: torch.Size([500, 10])\tYour Output Shape: torch.Size([500, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([1, 8])\tExpected Output Shape: torch.Size([1, 10])\tYour Output Shape: torch.Size([1, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([5, 8])\tExpected Output Shape: torch.Size([5, 10])\tYour Output Shape: torch.Size([5, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([500, 8])\tExpected Output Shape: torch.Size([500, 10])\tYour Output Shape: torch.Size([500, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([1, 4])\tExpected Output Shape: torch.Size([1, 10])\tYour Output Shape: torch.Size([1, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([5, 4])\tExpected Output Shape: torch.Size([5, 10])\tYour Output Shape: torch.Size([5, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([500, 4])\tExpected Output Shape: torch.Size([500, 10])\tYour Output Shape: torch.Size([500, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([1, 8])\tExpected Output Shape: torch.Size([1, 10])\tYour Output Shape: torch.Size([1, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([5, 8])\tExpected Output Shape: torch.Size([5, 10])\tYour Output Shape: torch.Size([5, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([500, 8])\tExpected Output Shape: torch.Size([500, 10])\tYour Output Shape: torch.Size([500, 10])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([1, 4])\tExpected Output Shape: torch.Size([1, 1000])\tYour Output Shape: torch.Size([1, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([5, 4])\tExpected Output Shape: torch.Size([5, 1000])\tYour Output Shape: torch.Size([5, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([500, 4])\tExpected Output Shape: torch.Size([500, 1000])\tYour Output Shape: torch.Size([500, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([1, 8])\tExpected Output Shape: torch.Size([1, 1000])\tYour Output Shape: torch.Size([1, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([5, 8])\tExpected Output Shape: torch.Size([5, 1000])\tYour Output Shape: torch.Size([5, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([500, 8])\tExpected Output Shape: torch.Size([500, 1000])\tYour Output Shape: torch.Size([500, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([1, 4])\tExpected Output Shape: torch.Size([1, 1000])\tYour Output Shape: torch.Size([1, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([5, 4])\tExpected Output Shape: torch.Size([5, 1000])\tYour Output Shape: torch.Size([5, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}\tForward Input Shape: torch.Size([500, 4])\tExpected Output Shape: torch.Size([500, 1000])\tYour Output Shape: torch.Size([500, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([1, 8])\tExpected Output Shape: torch.Size([1, 1000])\tYour Output Shape: torch.Size([1, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([5, 8])\tExpected Output Shape: torch.Size([5, 1000])\tYour Output Shape: torch.Size([5, 1000])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}\tForward Input Shape: torch.Size([500, 8])\tExpected Output Shape: torch.Size([500, 1000])\tYour Output Shape: torch.Size([500, 1000])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "count_parameters = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def makeCbowSanityBatch(test_params):\n",
        "    batch_size = test_params['batch_size']\n",
        "    new_test_params = {k:v for k,v in test_params.items() if k != 'batch_size'}\n",
        "    batch = torch.randint(0, new_test_params['vocab_size'], (batch_size,new_test_params['context_size']*2))\n",
        "    return batch, new_test_params\n",
        "\n",
        "def sanityCheckModel(all_test_params, NN, expected_outputs, init_or_forward, make_batch_fxn=None):\n",
        "    print('--- TEST: ' + ('Number of Model Parameters (tests __init__(...))' if init_or_forward=='init' else 'Output shape of forward(...)') + ' ---')\n",
        "    \n",
        "    for tp_idx, (test_params, expected_output) in enumerate(zip(all_test_params, expected_outputs)):       \n",
        "        if init_or_forward == \"forward\":\n",
        "            input, test_params = make_batch_fxn(test_params)\n",
        "\n",
        "        # Construct the student model\n",
        "        tps = {k:v for k, v in test_params.items()}\n",
        "        stu_nn = NN(**tps)\n",
        "\n",
        "        if init_or_forward == \"forward\":\n",
        "            with torch.no_grad(): \n",
        "                stu_out = stu_nn(input)\n",
        "            ref_out_shape = expected_output\n",
        "\n",
        "            has_passed = torch.is_tensor(stu_out)\n",
        "            if not has_passed: msg = 'Output must be a torch.Tensor; received ' + str(type(stu_out))\n",
        "            else: \n",
        "                has_passed = stu_out.shape == ref_out_shape\n",
        "                msg = 'Your Output Shape: ' + str(stu_out.shape)\n",
        "            \n",
        "\n",
        "            status = 'PASSED' if has_passed else 'FAILED'\n",
        "            message = '\\t' + status + \"\\t Init Input: \" + str({k:v for k,v in tps.items()}) + '\\tForward Input Shape: ' + str(input.shape) + '\\tExpected Output Shape: ' + str(ref_out_shape) + '\\t' + msg\n",
        "            print(message)\n",
        "        else:\n",
        "            stu_num_params = count_parameters(stu_nn)\n",
        "            ref_num_params = expected_output\n",
        "            comparison_result = (stu_num_params == ref_num_params)\n",
        "\n",
        "            status = 'PASSED' if comparison_result else 'FAILED'\n",
        "            message = '\\t' + status + \"\\tInput: \" + str({k:v for k,v in test_params.items()}) + ('\\tExpected Num. Params: ' + str(ref_num_params) + '\\tYour Num. Params: '+ str(stu_num_params))\n",
        "            print(message)\n",
        "\n",
        "        del stu_nn\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    cbow_init_inputs = [{'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 128, 'context_size': 2}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 128, 'context_size': 4}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 128, 'context_size': 2}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 128, 'context_size': 4}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 128, 'context_size': 2}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 128, 'context_size': 4}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 128, 'context_size': 2}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 128, 'context_size': 4}]\n",
        "    cbow_init_expected_outputs = [3082, 3082, 5834, 5834, 5450, 5450, 10250, 10250, 99112, 99112, 165224, 165224, 133160, 133160, 201320, 201320]\n",
        "\n",
        "    sanityCheckModel(cbow_init_inputs, CbowModel, cbow_init_expected_outputs, \"init\")\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    cbow_forward_inputs = [{'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 1}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 5}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 500}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 1}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 5}, {'vocab_size': 10, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 500}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 1}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 5}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 500}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 1}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 5}, {'vocab_size': 10, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 500}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 5}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 2, 'batch_size': 500}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 5}, {'vocab_size': 1000, 'embed_size': 32, 'hidden_size': 64, 'context_size': 4, 'batch_size': 500}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 5}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 2, 'batch_size': 500}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 5}, {'vocab_size': 1000, 'embed_size': 64, 'hidden_size': 64, 'context_size': 4, 'batch_size': 500}]\n",
        "    cbow_forward_expected_outputs = [torch.Size([1, 10]), torch.Size([5, 10]), torch.Size([500, 10]), torch.Size([1, 10]), torch.Size([5, 10]), torch.Size([500, 10]), torch.Size([1, 10]), torch.Size([5, 10]), torch.Size([500, 10]), torch.Size([1, 10]), torch.Size([5, 10]), torch.Size([500, 10]), torch.Size([1, 1000]), torch.Size([5, 1000]), torch.Size([500, 1000]), torch.Size([1, 1000]), torch.Size([5, 1000]), torch.Size([500, 1000]), torch.Size([1, 1000]), torch.Size([5, 1000]), torch.Size([500, 1000]), torch.Size([1, 1000]), torch.Size([5, 1000]), torch.Size([500, 1000])]\n",
        "\n",
        "    sanityCheckModel(cbow_forward_inputs, CbowModel, cbow_forward_expected_outputs, \"forward\", makeCbowSanityBatch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QekcRZjslC93"
      },
      "source": [
        "##Train the CBOW Model [15 points]\n",
        "\n",
        "Now, we initialize the <b>dataloader</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate dataset.\n",
        "\n",
        "You do not need to edit this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q17j2AwNZ20J"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "BATCH_SIZE = 512 # You may change the batch size if you'd like\n",
        "CONTEXT_SIZE = 3  # You may change the context size if you'd like\n",
        "\n",
        "if __name__=='__main__':\n",
        "    cbow_dataset = CbowDataset(sentences, vocab, CONTEXT_SIZE)\n",
        "    cbow_dataloader = torch.utils.data.DataLoader(cbow_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVAnU3-L7Md5"
      },
      "source": [
        "Now we provide you with a function that takes your model and trains it on the data.\n",
        "\n",
        "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hl52H5T7MGV"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import optim\n",
        "\n",
        "def train_cbow_model(model, num_epochs, data_loader, optimizer, criterion):\n",
        "    print(\"Training CBOW model....\")\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss, n = 0, 0\n",
        "        for context, target in tqdm(data_loader):\n",
        "            optimizer.zero_grad()\n",
        "            log_probs = model(context.long().to(DEVICE)) # to(torch.float32)\n",
        "            loss = criterion(log_probs, target.to(DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            n += context.shape[0]\n",
        "            epoch_loss += (loss*context.shape[0])\n",
        "\n",
        "        epoch_loss = epoch_loss/n\n",
        "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}'.format(epoch+1, epoch_loss))\n",
        "    print('CBOW Model Trained!\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sogetmSb8z2I"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHmJio5W8z2I",
        "outputId": "2b015516-75ba-4cf0-ea90-5b64eccc5cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 7,438,415 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    cbow_model = CbowModel(vocab_size = cbow_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128, # Feel free to change\n",
        "                hidden_size = 128, # Feel free to change \n",
        "                context_size = CONTEXT_SIZE) # Don't change this (though you may change the value of CONTEXT_SIZE above if you wish)\n",
        "\n",
        "    # Put your model on the device (cuda or cpu)\n",
        "    cbow_model = cbow_model.to(DEVICE)\n",
        "    PATH = 'model.pth'\n",
        "\n",
        "    # Save the model state dictionary to the specified file path\n",
        "    torch.save(cbow_model.state_dict(), PATH)\n",
        "    \n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(cbow_model)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV2sajpX9mN-"
      },
      "source": [
        "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
        "\n",
        "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTlIN_Nz9nsx"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "if __name__=='__main__':    \n",
        "    LEARNING_RATE = 0.01 # Feel free to try other learning rates\n",
        "\n",
        "    # Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(cbow_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WrKoEW9nsx"
      },
      "source": [
        "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>3 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "246c6d8b460a4133b0c1b8f9ec360f1b",
            "62d58ad268e04dfca605b80a8723a10e",
            "7229b6cbeb8240d5a15b2d5ef6d99660",
            "0b4cec7870034dae8d30ed9227aefa7b",
            "18a12d620d324e2ca00e26e60c39dc34",
            "4770f5f9962d46098398bcd5ea3f8ece",
            "9e253eaceb2347cd8f8edc09e4303f9e",
            "d2b93f927d8d4aee853292a3524910fe",
            "cdb3b30a81de4e658d765e26acb59511",
            "4dd670015258479aad55c385b83ada16",
            "ff1b497a9c3445699d2fb5b460583a4b"
          ]
        },
        "id": "e7BlulY89nsx",
        "outputId": "b08258f9-b0e4-4b1a-ee72-abd68f1da464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CBOW model....\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1684 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "246c6d8b460a4133b0c1b8f9ec360f1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "context_tensors:  context_tensors: tensor([   76, 28356, 28175, 18520, 26042, 28115]) \n",
            "tensor([16742, 13448, 26026,  6140, 22541,    79])\n",
            "context_tensors:  context_tensors:  tensor([28356, 28175, 17451, 26042, 28115,  2784])\n",
            "tensor([13448, 26026,     1, 22541,    79,     1])context_tensors:  \n",
            "tensor([28175, 17451, 18520, 28115,  2784,    79])context_tensors:  \n",
            "tensor([26026,     1,  6140,    79,     1,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 1411,  9878, 10866,  5938, 16744,    76])\n",
            " tensor([17451, 18520, 26042,  2784,    79,  1409])context_tensors: \n",
            " tensor([ 9878, 10866, 28791, 16744,    76, 26026])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 26910,  7516,  3698, 26026,  5445])\n",
            "context_tensors:   tensor([26910,  7516,  1410, 26026,  5445,  6942])\n",
            "context_tensors:  tensor([10866, 28791,  5938,    76, 26026, 26440])tensor([7516, 1410, 3698, 5445, 6942, 3623])\n",
            "context_tensors: \n",
            "  context_tensors: tensor([28791,  5938, 16744, 26026, 26440,  4666])tensor([ 1410,  3698, 26026,  6942,  3623,  9095])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3698, 26026,  5445,  3623,  9095,    79]) tensor([ 5938, 16744,    76, 26440,  4666, 21809])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026,  5445,  6942,  9095,    79,     1]) tensor([16744,    76, 26026,  4666, 21809, 15231])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 26026, 26440, 21809, 15231, 27200])\n",
            " context_tensors: tensor([5445, 6942, 3623,   79,    1, 1409])\n",
            "context_tensors:  tensor([ 1411, 26026,  6450,  9708,  3017, 15729]) tensor([26026, 26440,  4666, 15231, 27200, 10866])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26440,  4666, 21809, 27200, 10866,  2183]) \n",
            "context_tensors: tensor([26026,  6450, 18728,  3017, 15729, 22464]) tensor([ 4666, 21809, 15231, 10866,  2183, 10492])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([21809, 15231, 27200,  2183, 10492, 28614]) \n",
            "tensor([ 6450, 18728,  9708, 15729, 22464, 27965])context_tensors: \n",
            " context_tensors:  tensor([18728,  9708,  3017, 22464, 27965, 21347])\n",
            "tensor([15231, 27200, 10866, 10492, 28614,  2371])\n",
            "context_tensors: context_tensors:  tensor([ 9708,  3017, 15729, 27965, 21347, 13448]) \n",
            "tensor([27200, 10866,  2183, 28614,  2371, 25246])\n",
            "context_tensors: context_tensors:  tensor([10866,  2183, 10492,  2371, 25246, 23872])\n",
            " context_tensors: tensor([ 3017, 15729, 22464, 21347, 13448,  3130])\n",
            " tensor([ 2183, 10492, 28614, 25246, 23872,  7988])context_tensors: \n",
            " context_tensors:  tensor([15729, 22464, 27965, 13448,  3130,    76])tensor([10492, 28614,  2371, 23872,  7988,    79])\n",
            "\n",
            "context_tensors:  tensor([22464, 27965, 21347,  3130,    76,   618])context_tensors: \n",
            " tensor([28614,  2371, 25246,  7988,    79,  1409])context_tensors: \n",
            " tensor([27965, 21347, 13448,    76,   618,    79])\n",
            "context_tensors:  tensor([ 1411, 26026, 28791, 20776, 17546,  1416])\n",
            "context_tensors: context_tensors:  tensor([26026, 28791,  5938, 17546,  1416, 17904]) tensor([21347, 13448,  3130,   618,    79,  1409])\n",
            "\n",
            "context_tensors:  tensor([ 1411, 15855,  2806,  1423, 25268, 19571])\n",
            "context_tensors: context_tensors:   tensor([28791,  5938, 20776,  1416, 17904, 10549])tensor([15855,  2806, 10866, 25268, 19571, 26285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2806, 10866,  1423, 19571, 26285, 12452])tensor([ 5938, 20776, 17546, 17904, 10549, 25376])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([20776, 17546,  1416, 10549, 25376,  8889]) tensor([10866,  1423, 25268, 26285, 12452, 26115])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1423, 25268, 19571, 12452, 26115,  1676])tensor([17546,  1416, 17904, 25376,  8889, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1416, 17904, 10549,  8889, 26026, 19528])tensor([25268, 19571, 26285, 26115,  1676,    76])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([19571, 26285, 12452,  1676,    76, 11505])tensor([17904, 10549, 25376, 26026, 19528,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285, 12452, 26115,    76, 11505, 12740])\n",
            "context_tensors: tensor([10549, 25376,  8889, 19528,  2371,  9801])\n",
            "context_tensors:   tensor([12452, 26115,  1676, 11505, 12740, 26855])tensor([25376,  8889, 26026,  2371,  9801, 19069])\n",
            "\n",
            "context_tensors:  tensor([26115,  1676,    76, 12740, 26855, 26285])context_tensors:  tensor([ 8889, 26026, 19528,  9801, 19069, 26026])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026, 19528,  2371, 19069, 26026,  9164])\n",
            "tensor([ 1676,    76, 11505, 26855, 26285, 26026])context_tensors: \n",
            " context_tensors: tensor([19528,  2371,  9801, 26026,  9164,  3940]) \n",
            "tensor([   76, 11505, 12740, 26285, 26026,  6450])context_tensors: \n",
            "context_tensors:   tensor([11505, 12740, 26855, 26026,  6450, 17848])\n",
            "tensor([ 2371,  9801, 19069,  9164,  3940,  8889])\n",
            "context_tensors:  tensor([12740, 26855, 26285,  6450, 17848,  2371])context_tensors: \n",
            " context_tensors:  tensor([26855, 26285, 26026, 17848,  2371,  4290])\n",
            "context_tensors:  tensor([ 9801, 19069, 26026,  3940,  8889, 26026])\n",
            "tensor([26285, 26026,  6450,  2371,  4290, 15565])\n",
            "context_tensors:  context_tensors: tensor([19069, 26026,  9164,  8889, 26026, 11914])\n",
            " tensor([26026,  6450, 17848,  4290, 15565, 14442])\n",
            "context_tensors: context_tensors:   tensor([ 6450, 17848,  2371, 15565, 14442, 27842])\n",
            "context_tensors: tensor([26026,  9164,  3940, 26026, 11914,  7875]) \n",
            "tensor([17848,  2371,  4290, 14442, 27842,  8870])\n",
            " context_tensors: context_tensors:  tensor([ 2371,  4290, 15565, 27842,  8870,    79])tensor([ 9164,  3940,  8889, 11914,  7875,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3940,  8889, 26026,  7875,    79,  1409])tensor([ 4290, 15565, 14442,  8870,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 28791, 14156, 24887, 12468])tensor([ 1411, 15948,  8870, 26026,  6188, 18520])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 28791,  5938, 24887, 12468, 13448]) \n",
            "tensor([15948,  8870, 27965,  6188, 18520, 26026])context_tensors:  \n",
            "tensor([28791,  5938, 14156, 12468, 13448, 26026])context_tensors: \n",
            " context_tensors: tensor([ 8870, 27965, 26026, 18520, 26026, 12086]) \n",
            "tensor([ 5938, 14156, 24887, 13448, 26026, 26440])context_tensors: \n",
            " context_tensors: tensor([27965, 26026,  6188, 26026, 12086,  1410]) \n",
            "tensor([14156, 24887, 12468, 26026, 26440,  4666])context_tensors: \n",
            " context_tensors: tensor([26026,  6188, 18520, 12086,  1410,  1410])\n",
            " tensor([24887, 12468, 13448, 26440,  4666,    79])context_tensors: \n",
            " tensor([ 6188, 18520, 26026,  1410,  1410,    76])\n",
            "context_tensors:  context_tensors: tensor([12468, 13448, 26026,  4666,    79,  1409]) tensor([18520, 26026, 12086,  1410,    76, 28175])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026, 12086,  1410,    76, 28175, 12153])tensor([ 1411, 26026,  4666, 26026, 25429, 19218])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([12086,  1410,  1410, 28175, 12153,  3686]) tensor([26026,  4666,  2371, 25429, 19218, 28115])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1410,  1410,    76, 12153,  3686,  4593]) \n",
            "tensor([ 4666,  2371, 26026, 19218, 28115, 27347])context_tensors:  \n",
            "tensor([ 1410,    76, 28175,  3686,  4593, 26285])context_tensors:  \n",
            "tensor([ 2371, 26026, 25429, 28115, 27347, 10866])context_tensors: \n",
            " tensor([   76, 28175, 12153,  4593, 26285, 15729])context_tensors:  \n",
            "tensor([26026, 25429, 19218, 27347, 10866, 16343])context_tensors: \n",
            " tensor([28175, 12153,  3686, 26285, 15729, 22464])context_tensors:  tensor([25429, 19218, 28115, 10866, 16343, 20839])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12153,  3686,  4593, 15729, 22464, 13448])tensor([19218, 28115, 27347, 16343, 20839, 20942])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3686,  4593, 26285, 22464, 13448, 12918])tensor([28115, 27347, 10866, 20839, 20942, 26170])\n",
            "\n",
            "context_tensors:  tensor([ 4593, 26285, 15729, 13448, 12918, 18520])context_tensors:  \n",
            "tensor([27347, 10866, 16343, 20942, 26170, 26026])context_tensors: \n",
            " tensor([26285, 15729, 22464, 12918, 18520,  6768])context_tensors: \n",
            " context_tensors: tensor([10866, 16343, 20839, 26170, 26026,  8958]) \n",
            "tensor([15729, 22464, 13448, 18520,  6768, 14210])context_tensors: \n",
            " context_tensors: tensor([16343, 20839, 20942, 26026,  8958,   830]) \n",
            "tensor([22464, 13448, 12918,  6768, 14210, 26285])context_tensors: \n",
            "context_tensors:   tensor([20839, 20942, 26170,  8958,   830,  5356])tensor([13448, 12918, 18520, 14210, 26285,  2334])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([20942, 26170, 26026,   830,  5356,    79])tensor([12918, 18520,  6768, 26285,  2334, 14132])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18520,  6768, 14210,  2334, 14132,    79])\n",
            " context_tensors:  tensor([26170, 26026,  8958,  5356,    79,  1409])tensor([ 6768, 14210, 26285, 14132,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  8870, 27965, 26285, 12452, 26026])tensor([ 1411, 26026, 26440, 23468,  2858, 12469])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 26440,  4666,  2858, 12469, 10866]) tensor([ 8870, 27965, 23341, 12452, 26026, 18728])\n",
            "context_tensors: \n",
            " tensor([26440,  4666, 23468, 12469, 10866, 26026])\n",
            "context_tensors:  tensor([ 4666, 23468,  2858, 10866, 26026, 27167])\n",
            "context_tensors:  tensor([23468,  2858, 12469, 26026, 27167,  6450])\n",
            "context_tensors: context_tensors:   tensor([27965, 23341, 26285, 26026, 18728, 28449])\n",
            "tensor([ 2858, 12469, 10866, 27167,  6450, 27593])\n",
            "context_tensors: context_tensors:   tensor([23341, 26285, 12452, 18728, 28449,  3017])tensor([12469, 10866, 26026,  6450, 27593,  1410])\n",
            "\n",
            "context_tensors:  tensor([10866, 26026, 27167, 27593,  1410,    76])context_tensors: \n",
            " tensor([26285, 12452, 26026, 28449,  3017, 15729])\n",
            "context_tensors: context_tensors:   tensor([12452, 26026, 18728,  3017, 15729, 22464])\n",
            "tensor([26026, 27167,  6450,  1410,    76, 16599])\n",
            "context_tensors: context_tensors:  tensor([26026, 18728, 28449, 15729, 22464,    76]) \n",
            "tensor([27167,  6450, 27593,    76, 16599,   325])context_tensors: \n",
            "context_tensors:   tensor([18728, 28449,  3017, 22464,    76,  2371])tensor([ 6450, 27593,  1410, 16599,   325, 28846])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28449,  3017, 15729,    76,  2371,  2217])tensor([27593,  1410,    76,   325, 28846,   541])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410,    76, 16599, 28846,   541,    76])\n",
            "context_tensors: tensor([ 3017, 15729, 22464,  2371,  2217, 12451])\n",
            " tensor([   76, 16599,   325,   541,    76,   679])\n",
            "context_tensors: context_tensors:   tensor([16599,   325, 28846,    76,   679,    79])\n",
            "tensor([15729, 22464,    76,  2217, 12451,  6699])context_tensors: \n",
            " context_tensors: tensor([  325, 28846,   541,   679,    79,  1409]) \n",
            "context_tensors:  tensor([22464,    76,  2371, 12451,  6699, 26285])tensor([ 1411, 18921,   145,    88,  5778, 27921])\n",
            "context_tensors:  \n",
            "tensor([   76,  2371,  2217,  6699, 26285,  8714])\n",
            "context_tensors:  context_tensors:  tensor([ 2371,  2217, 12451, 26285,  8714, 12762])tensor([18921,   145,  1415,  5778, 27921, 27593])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2217, 12451,  6699,  8714, 12762, 19377])tensor([  145,  1415,    88, 27921, 27593,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12451,  6699, 26285, 12762, 19377, 11158])tensor([ 1415,    88,  5778, 27593,    76, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   88,  5778, 27921,    76, 26026, 15233])tensor([ 6699, 26285,  8714, 19377, 11158, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285,  8714, 12762, 11158, 26026,  6450])tensor([ 5778, 27921, 27593, 26026, 15233, 20119])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 8714, 12762, 19377, 26026,  6450, 17848])\n",
            "tensor([27921, 27593,    76, 15233, 20119, 11445])\n",
            "context_tensors:  tensor([12762, 19377, 11158,  6450, 17848,  7831])\n",
            "tensor([27593,    76, 26026, 20119, 11445, 13448])context_tensors:  \n",
            "context_tensors:  context_tensors: tensor([19377, 11158, 26026, 17848,  7831,    76])\n",
            " context_tensors: tensor([   76, 26026, 15233, 11445, 13448, 26026]) \n",
            "tensor([ 2334,  2793, 10866,  2776, 17809, 12035])context_tensors:  \n",
            "tensor([26026, 15233, 20119, 13448, 26026, 12777])\n",
            "context_tensors: context_tensors:   tensor([15233, 20119, 11445, 26026, 12777, 18520])tensor([ 2793, 10866, 26026, 17809, 12035,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10866, 26026,  2776, 12035,    79,  1409])tensor([20119, 11445, 13448, 12777, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 13448,   680, 26026, 23265, 10758])tensor([11445, 13448, 26026, 18520, 26026,  5775])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([13448,   680,    76, 23265, 10758, 18520])tensor([13448, 26026, 12777, 26026,  5775, 27275])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 12777, 18520,  5775, 27275, 26285]) \n",
            "tensor([  680,    76, 26026, 10758, 18520, 26026])\n",
            "context_tensors: context_tensors:   tensor([12777, 18520, 26026, 27275, 26285, 26023])tensor([   76, 26026, 23265, 18520, 26026, 26440])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18520, 26026,  5775, 26285, 26023, 26232]) \n",
            "tensor([26026, 23265, 10758, 26026, 26440,  4666])context_tensors: \n",
            " tensor([26026,  5775, 27275, 26023, 26232,    76])\n",
            "context_tensors: context_tensors:   tensor([ 5775, 27275, 26285, 26232,    76,  3077])\n",
            "context_tensors: tensor([23265, 10758, 18520, 26440,  4666,  3666])\n",
            " context_tensors: tensor([27275, 26285, 26023,    76,  3077,  2371])\n",
            " context_tensors:  tensor([26285, 26023, 26232,  3077,  2371, 28115])tensor([10758, 18520, 26026,  4666,  3666, 15729])\n",
            "\n",
            "context_tensors:  tensor([26023, 26232,    76,  2371, 28115, 12991])context_tensors: \n",
            " tensor([18520, 26026, 26440,  3666, 15729, 22464])context_tensors: \n",
            "context_tensors:  tensor([26232,    76,  3077, 28115, 12991, 13448])\n",
            " tensor([26026, 26440,  4666, 15729, 22464,    62])context_tensors: \n",
            " context_tensors: tensor([   76,  3077,  2371, 12991, 13448, 26026]) tensor([26440,  4666,  3666, 22464,    62, 10609])\n",
            "\n",
            "context_tensors:  tensor([ 4666,  3666, 15729,    62, 10609, 20839])context_tensors:  \n",
            "tensor([ 3077,  2371, 28115, 13448, 26026,  4666])context_tensors: \n",
            " context_tensors: tensor([ 3666, 15729, 22464, 10609, 20839, 15548])\n",
            "context_tensors:  tensor([15729, 22464,    62, 20839, 15548,    79])\n",
            "context_tensors:  tensor([22464,    62, 10609, 15548,    79,  1409])\n",
            "context_tensors:  tensor([ 1411, 13448,   685, 15729, 22464,  4670])\n",
            " tensor([ 2371, 28115, 12991, 26026,  4666, 18691])context_tensors:  \n",
            "tensor([13448,   685,    76, 22464,  4670,  1423])\n",
            "context_tensors: context_tensors:   tensor([  685,    76, 15729,  4670,  1423, 10590])tensor([28115, 12991, 13448,  4666, 18691,  4937])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 15729, 22464,  1423, 10590, 24763])\n",
            " tensor([12991, 13448, 26026, 18691,  4937, 13448])\n",
            "context_tensors: context_tensors:   tensor([13448, 26026,  4666,  4937, 13448, 26026])tensor([15729, 22464,  4670, 10590, 24763, 13448])\n",
            "\n",
            "context_tensors:  tensor([22464,  4670,  1423, 24763, 13448, 26026])\n",
            "context_tensors: context_tensors:  tensor([26026,  4666, 18691, 13448, 26026, 19218])\n",
            " context_tensors: tensor([ 4670,  1423, 10590, 13448, 26026, 19218]) \n",
            "tensor([ 4666, 18691,  4937, 26026, 19218,    76])context_tensors: \n",
            " context_tensors: tensor([ 1423, 10590, 24763, 26026, 19218,    76])\n",
            " context_tensors: tensor([18691,  4937, 13448, 19218,    76, 28175]) \n",
            "tensor([10590, 24763, 13448, 19218,    76, 26023])context_tensors:  \n",
            "tensor([ 4937, 13448, 26026,    76, 28175, 12153])\n",
            "context_tensors:  context_tensors: tensor([24763, 13448, 26026,    76, 26023,  4666])\n",
            " tensor([13448, 26026, 19218, 28175, 12153,  2197])\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 19218, 26023,  4666, 14156])tensor([26026, 19218,    76, 12153,  2197,  3672])\n",
            "context_tensors: \n",
            " tensor([26026, 19218,    76,  4666, 14156, 18306])context_tensors: \n",
            " context_tensors: tensor([19218,    76, 28175,  2197,  3672,  1423]) tensor([19218,    76, 26023, 14156, 18306, 11762])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 26023,  4666, 18306, 11762,    79])tensor([   76, 28175, 12153,  3672,  1423, 20119])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26023,  4666, 14156, 11762,    79,  1409])\n",
            " tensor([28175, 12153,  2197,  1423, 20119,  4942])context_tensors: \n",
            "context_tensors:   tensor([ 1411,  1423,  3393, 17741, 10866, 12132])tensor([12153,  2197,  3672, 20119,  4942,  2734])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423,  3393, 23635, 10866, 12132, 12132])tensor([2197, 3672, 1423, 4942, 2734,   79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3672,  1423, 20119,  2734,    79,  1409])tensor([ 3393, 23635, 17741, 12132, 12132, 10979])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 15261, 26026, 23468,  2858,  2334])tensor([23635, 17741, 10866, 12132, 10979,  2197])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([15261, 26026,  4666,  2858,  2334,  2793]) \n",
            "tensor([17741, 10866, 12132, 10979,  2197, 27965])context_tensors: \n",
            " context_tensors: tensor([26026,  4666, 23468,  2334,  2793, 10866])\n",
            " context_tensors:  \n",
            "tensor([10866, 12132, 12132,  2197, 27965,  4670])tensor([ 4666, 23468,  2858,  2793, 10866, 26026])context_tensors: \n",
            " context_tensors: tensor([12132, 12132, 10979, 27965,  4670, 13448])\n",
            "context_tensors:  tensor([23468,  2858,  2334, 10866, 26026,  2776]) \n",
            "tensor([12132, 10979,  2197,  4670, 13448, 26026])context_tensors: \n",
            " context_tensors: tensor([ 2858,  2334,  2793, 26026,  2776, 17809]) \n",
            "tensor([10979,  2197, 27965, 13448, 26026, 19218])context_tensors: \n",
            " tensor([    1,  5716, 10866, 15481, 20529,    79])context_tensors:  \n",
            "context_tensors: tensor([ 2197, 27965,  4670, 26026, 19218,  8889]) \n",
            "tensor([ 5716, 10866, 26026, 20529,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([27965,  4670, 13448, 19218,  8889, 26115]) tensor([ 1411,  3476, 24266, 20158, 18520, 12600])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4670, 13448, 26026,  8889, 26115, 26232])tensor([ 3476, 24266, 13516, 18520, 12600, 10385])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 19218, 26115, 26232,    76])tensor([24266, 13516, 20158, 12600, 10385, 19215])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13516, 20158, 18520, 10385, 19215, 13448])tensor([26026, 19218,  8889, 26232,    76,  4767])\n",
            "\n",
            "context_tensors:  tensor([20158, 18520, 12600, 19215, 13448, 12600])\n",
            "context_tensors:  context_tensors:  tensor([19218,  8889, 26115,    76,  4767,  2197])\n",
            "tensor([18520, 12600, 10385, 13448, 12600, 21789])\n",
            "context_tensors:  context_tensors:  tensor([ 8889, 26115, 26232,  4767,  2197, 18145])tensor([12600, 10385, 19215, 12600, 21789, 28449])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26115, 26232,    76,  2197, 18145, 15839]) \n",
            "tensor([10385, 19215, 13448, 21789, 28449,    79])context_tensors: \n",
            " context_tensors: tensor([26232,    76,  4767, 18145, 15839,  9957]) \n",
            "tensor([19215, 13448, 12600, 28449,    79,  1409])context_tensors: \n",
            " context_tensors:  tensor([   76,  4767,  2197, 15839,  9957,    79])\n",
            "context_tensors: tensor([ 1411, 23615, 27965,  4787,  4986, 13696])\n",
            " tensor([ 4767,  2197, 18145,  9957,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([23615, 27965,  7912,  4986, 13696, 12718]) \n",
            "tensor([ 1411, 13448,   708, 28449, 20613,  1748])context_tensors: \n",
            "context_tensors:   tensor([27965,  7912,  4787, 13696, 12718,  2858])tensor([13448,   708,    76, 20613,  1748,  4670])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 7912,  4787,  4986, 12718,  2858,     1])tensor([  708,    76, 28449,  1748,  4670, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 28449, 20613,  4670, 26026, 17625])\n",
            "context_tensors: tensor([ 4787,  4986, 13696,  2858,     1, 18609])\n",
            " context_tensors: tensor([28449, 20613,  1748, 26026, 17625, 18520]) \n",
            "context_tensors: tensor([ 4986, 13696, 12718,     1, 18609, 18520]) \n",
            "tensor([20613,  1748,  4670, 17625, 18520, 10561])context_tensors: \n",
            " tensor([13696, 12718,  2858, 18609, 18520, 26026])context_tensors: \n",
            " context_tensors:  tensor([ 1748,  4670, 26026, 18520, 10561,  2852])tensor([12718,  2858,     1, 18520, 26026, 19781])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4670, 26026, 17625, 10561,  2852,    76])tensor([ 2858,     1, 18609, 26026, 19781,     1])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 17625, 18520,  2852,    76, 18306])\n",
            "context_tensors: tensor([    1, 18609, 18520, 19781,     1, 18520])\n",
            " tensor([17625, 18520, 10561,    76, 18306,  4890])\n",
            "context_tensors:  tensor([18609, 18520, 26026,     1, 18520, 24637])context_tensors:  \n",
            "tensor([18520, 10561,  2852, 18306,  4890, 26026])context_tensors: \n",
            " context_tensors: tensor([18520, 26026, 19781, 18520, 24637,  2385]) tensor([10561,  2852,    76,  4890, 26026,  2776])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 19781,     1, 24637,  2385,    62])tensor([ 2852,    76, 18306, 26026,  2776,  2852])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19781,     1, 18520,  2385,    62,    79])tensor([   76, 18306,  4890,  2776,  2852,  5334])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18306,  4890, 26026,  2852,  5334,    76])tensor([    1, 18520, 24637,    62,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4890, 26026,  2776,  5334,    76, 14576])\n",
            "tensor([ 1411, 26026,  5614, 26026, 14860, 17219])context_tensors: \n",
            " context_tensors: tensor([26026,  2776,  2852,    76, 14576, 24336]) tensor([26026,  5614, 13448, 14860, 17219, 10866])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 5614, 13448, 26026, 17219, 10866, 26026]) \n",
            "context_tensors:  tensor([ 2776,  2852,  5334, 14576, 24336, 18520])tensor([13448, 26026, 14860, 10866, 26026, 10776])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 14860, 17219, 26026, 10776, 10179])tensor([ 2852,  5334,    76, 24336, 18520, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([14860, 17219, 10866, 10776, 10179, 27255])\n",
            " tensor([ 5334,    76, 14576, 18520, 26026, 26440])\n",
            "context_tensors:  tensor([   76, 14576, 24336, 26026, 26440,  4666])context_tensors: \n",
            " context_tensors: tensor([17219, 10866, 26026, 10179, 27255, 26026]) \n",
            "tensor([14576, 24336, 18520, 26440,  4666,    79])\n",
            "context_tensors: context_tensors:   tensor([24336, 18520, 26026,  4666,    79,  1409])tensor([10866, 26026, 10776, 27255, 26026, 14860])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026,  2831, 15696, 13448, 26026])tensor([26026, 10776, 10179, 26026, 14860,  5918])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([10776, 10179, 27255, 14860,  5918, 13448])tensor([26026,  2831, 27965, 13448, 26026, 17809])\n",
            "context_tensors:  \n",
            "tensor([10179, 27255, 26026,  5918, 13448,   713])context_tensors: \n",
            " context_tensors:  tensor([27255, 26026, 14860, 13448,   713,    79])\n",
            "context_tensors:  tensor([26026, 14860,  5918,   713,    79,  1409])\n",
            "tensor([ 2831, 27965, 15696, 26026, 17809, 21669])context_tensors: \n",
            " tensor([ 1411, 13448,  2334, 13448,   737,    76])\n",
            "context_tensors: context_tensors:   tensor([27965, 15696, 13448, 17809, 21669, 18520])tensor([13448,  2334, 13997,   737,    76,  3476])\n",
            "context_tensors: \n",
            " context_tensors: tensor([15696, 13448, 26026, 21669, 18520, 12772])\n",
            " context_tensors: tensor([ 2334, 13997, 13448,    76,  3476, 22806]) \n",
            "tensor([13448, 26026, 17809, 18520, 12772, 19858])\n",
            "context_tensors:  tensor([13997, 13448,   737,  3476, 22806,    76])context_tensors: \n",
            " context_tensors:  tensor([26026, 17809, 21669, 12772, 19858, 13448])\n",
            "tensor([13448,   737,    76, 22806,    76,     1])\n",
            "context_tensors: context_tensors:  tensor([  737,    76,  3476,    76,     1, 17668])\n",
            " context_tensors:  tensor([   76,  3476, 22806,     1, 17668, 23970])\n",
            "context_tensors: tensor([17809, 21669, 18520, 19858, 13448,   752]) \n",
            " context_tensors: tensor([21669, 18520, 12772, 13448,   752,    79])\n",
            "tensor([ 3476, 22806,    76, 17668, 23970, 21220])context_tensors: \n",
            " context_tensors: tensor([18520, 12772, 19858,   752,    79,  1409])\n",
            " tensor([22806,    76,     1, 23970, 21220,  1423])context_tensors: \n",
            " context_tensors: tensor([ 1411,  8830, 26285,  2966, 28356, 26026]) \n",
            "tensor([   76,     1, 17668, 21220,  1423, 14860])\n",
            "context_tensors: context_tensors:   tensor([ 8830, 26285, 14227, 28356, 26026,  4913])\n",
            "tensor([    1, 17668, 23970,  1423, 14860,  2371])context_tensors:  \n",
            "tensor([26285, 14227,  2966, 26026,  4913,  9985])\n",
            "context_tensors: context_tensors:  tensor([17668, 23970, 21220, 14860,  2371, 13179]) tensor([14227,  2966, 28356,  4913,  9985, 18520])\n",
            "context_tensors: \n",
            " tensor([23970, 21220,  1423,  2371, 13179, 27347])context_tensors:  \n",
            "context_tensors:  tensor([21220,  1423, 14860, 13179, 27347, 26285])tensor([ 2966, 28356, 26026,  9985, 18520,   620])\n",
            "context_tensors: \n",
            " tensor([ 1423, 14860,  2371, 27347, 26285,  4289])\n",
            "context_tensors:  context_tensors:  tensor([14860,  2371, 13179, 26285,  4289, 12600])\n",
            "tensor([28356, 26026,  4913, 18520,   620,    76])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 13179, 27347,  4289, 12600, 25095])tensor([26026,  4913,  9985,   620,    76, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4913,  9985, 18520,    76, 26026,  2831])tensor([13179, 27347, 26285, 12600, 25095, 10866])\n",
            "\n",
            "context_tensors:  tensor([ 9985, 18520,   620, 26026,  2831, 16599])context_tensors:  \n",
            "tensor([27347, 26285,  4289, 25095, 10866, 17221])\n",
            "context_tensors:  context_tensors:  tensor([18520,   620,    76,  2831, 16599,  3623])tensor([26285,  4289, 12600, 10866, 17221,    79])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([  620,    76, 26026, 16599,  3623, 13495])\n",
            "tensor([ 4289, 12600, 25095, 17221,    79,  1409])context_tensors:  \n",
            "context_tensors: tensor([   76, 26026,  2831,  3623, 13495, 13448]) \n",
            "tensor([ 1411, 10866, 16343, 13179, 12153,  2334])\n",
            "context_tensors:  context_tensors: tensor([26026,  2831, 16599, 13495, 13448, 26026]) tensor([10866, 16343, 28614, 12153,  2334,  3042])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2831, 16599,  3623, 13448, 26026,  4913])tensor([16343, 28614, 13179,  2334,  3042, 18520])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([16599,  3623, 13495, 26026,  4913,  9985])\n",
            " tensor([28614, 13179, 12153,  3042, 18520,  5614])context_tensors: \n",
            " context_tensors: tensor([ 3623, 13495, 13448,  4913,  9985, 23978]) \n",
            "tensor([13179, 12153,  2334, 18520,  5614,  1497])context_tensors: \n",
            " context_tensors: tensor([13495, 13448, 26026,  9985, 23978, 17809]) \n",
            "tensor([12153,  2334,  3042,  5614,  1497, 16681])context_tensors: \n",
            " tensor([13448, 26026,  4913, 23978, 17809, 12772])context_tensors: \n",
            " context_tensors:  tensor([26026,  4913,  9985, 17809, 12772, 15190])\n",
            "tensor([ 2334,  3042, 18520,  1497, 16681, 28846])context_tensors: \n",
            " context_tensors: tensor([ 4913,  9985, 23978, 12772, 15190,  7925]) \n",
            "context_tensors: tensor([ 3042, 18520,  5614, 16681, 28846, 13179]) \n",
            "tensor([ 9985, 23978, 17809, 15190,  7925, 13448])context_tensors: \n",
            " tensor([18520,  5614,  1497, 28846, 13179, 18002])\n",
            "context_tensors: context_tensors:  tensor([23978, 17809, 12772,  7925, 13448,   781])\n",
            " context_tensors:  tensor([ 5614,  1497, 16681, 13179, 18002,  1410])\n",
            "tensor([17809, 12772, 15190, 13448,   781,    79])context_tensors:  \n",
            "tensor([ 1497, 16681, 28846, 18002,  1410, 14210])\n",
            "context_tensors: context_tensors:   tensor([12772, 15190,  7925,   781,    79,  1409])\n",
            "tensor([16681, 28846, 13179,  1410, 14210,    79])context_tensors:  \n",
            "tensor([ 1411, 13448,   716, 26026, 26440,  4666])\n",
            "context_tensors:  context_tensors: tensor([28846, 13179, 18002, 14210,    79,     1])\n",
            "context_tensors:   tensor([13448,   716,    76, 26440,  4666, 27965])\n",
            "tensor([13179, 18002,  1410,    79,     1,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 23615,  2197, 26026,  5614, 18520])tensor([  716,    76, 26026,  4666, 27965, 21881])\n",
            "context_tensors: \n",
            " context_tensors: tensor([23615,  2197, 19076,  5614, 18520, 21751]) \n",
            "tensor([   76, 26026, 26440, 27965, 21881,  8830])\n",
            "context_tensors:  context_tensors:  tensor([ 2197, 19076, 26026, 18520, 21751,  2858])tensor([26026, 26440,  4666, 21881,  8830, 26285])\n",
            "\n",
            "context_tensors:  tensor([19076, 26026,  5614, 21751,  2858, 28102])context_tensors: \n",
            " context_tensors:  tensor([26440,  4666, 27965,  8830, 26285, 26026])tensor([26026,  5614, 18520,  2858, 28102,  2858])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 5614, 18520, 21751, 28102,  2858, 11666]) tensor([ 4666, 27965, 21881, 26285, 26026,  9107])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([27965, 21881,  8830, 26026,  9107, 18520])tensor([18520, 21751,  2858,  2858, 11666,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([21881,  8830, 26285,  9107, 18520, 26026])\n",
            "tensor([21751,  2858, 28102, 11666,  1410,    76])\n",
            "context_tensors: context_tensors:   tensor([ 8830, 26285, 26026, 18520, 26026, 28791])tensor([ 2858, 28102,  2858,  1410,    76, 26026])\n",
            "\n",
            "context_tensors:  tensor([28102,  2858, 11666,    76, 26026,  1410])\n",
            "context_tensors:  tensor([ 2858, 11666,  1410, 26026,  1410,     6])\n",
            "context_tensors:  context_tensors: tensor([26285, 26026,  9107, 26026, 28791,  5938]) \n",
            "tensor([11666,  1410,    76,  1410,     6, 28661])\n",
            "context_tensors: context_tensors:   tensor([26026,  9107, 18520, 28791,  5938,    76])\n",
            "tensor([ 1410,    76, 26026,     6, 28661, 12995])\n",
            "context_tensors:  tensor([ 9107, 18520, 26026,  5938,    76, 15729])context_tensors: \n",
            " tensor([   76, 26026,  1410, 28661, 12995,    76])\n",
            "context_tensors: context_tensors:  tensor([26026,  1410,     6, 12995,    76, 28200])\n",
            " context_tensors:  tensor([18520, 26026, 28791,    76, 15729, 22464])tensor([ 1410,     6, 28661,    76, 28200, 20173])\n",
            "\n",
            "context_tensors:  tensor([26026, 28791,  5938, 15729, 22464, 19662])context_tensors: \n",
            "context_tensors:   tensor([    6, 28661, 12995, 28200, 20173, 10866])\n",
            "tensor([28791,  5938,    76, 22464, 19662, 11070])\n",
            "context_tensors: context_tensors:   tensor([ 5938,    76, 15729, 19662, 11070, 27842])tensor([28661, 12995,    76, 20173, 10866, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 15729, 22464, 11070, 27842,  1410])\n",
            "context_tensors:   tensor([12995,    76, 28200, 10866, 26026, 20497])tensor([15729, 22464, 19662, 27842,  1410,    76])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([22464, 19662, 11070,  1410,    76,  2371])tensor([   76, 28200, 20173, 26026, 20497, 10182])\n",
            "context_tensors: \n",
            " tensor([19662, 11070, 27842,    76,  2371, 26026])context_tensors:  tensor([28200, 20173, 10866, 20497, 10182, 13448])\n",
            "context_tensors: \n",
            " context_tensors: tensor([20173, 10866, 26026, 10182, 13448,   693])\n",
            " context_tensors: tensor([11070, 27842,  1410,  2371, 26026, 28449]) \n",
            "tensor([10866, 26026, 20497, 13448,   693,    79])context_tensors: \n",
            " context_tensors: tensor([27842,  1410,    76, 26026, 28449, 20613]) \n",
            "tensor([26026, 20497, 10182,   693,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 19891, 19076, 11158, 15567])tensor([ 1410,    76,  2371, 28449, 20613,  1748])\n",
            "\n",
            "context_tensors:  tensor([26026, 19891, 28115, 11158, 15567,    76])\n",
            "context_tensors:  context_tensors: tensor([19891, 28115, 19076, 15567,    76,  2371]) \n",
            "tensor([   76,  2371, 26026, 20613,  1748,    79])context_tensors: \n",
            " tensor([28115, 19076, 11158,    76,  2371, 13260])\n",
            "context_tensors: context_tensors:  tensor([19076, 11158, 15567,  2371, 13260,  1423])\n",
            "context_tensors:   tensor([ 2371, 26026, 28449,  1748,    79,  1409])\n",
            "tensor([11158, 15567,    76, 13260,  1423, 24429])\n",
            "context_tensors: context_tensors:  tensor([15567,    76,  2371,  1423, 24429, 27965]) \n",
            "tensor([ 1411, 14210,  3666, 18008, 12862, 18520])context_tensors: \n",
            " context_tensors: tensor([   76,  2371, 13260, 24429, 27965, 18253]) \n",
            "tensor([14210,  3666, 26026, 12862, 18520, 26026])context_tensors: \n",
            " context_tensors: tensor([ 2371, 13260,  1423, 27965, 18253, 21359]) \n",
            "tensor([ 3666, 26026, 18008, 18520, 26026,  2776])\n",
            "context_tensors: context_tensors:   tensor([13260,  1423, 24429, 18253, 21359,  3017])\n",
            "tensor([26026, 18008, 12862, 26026,  2776, 17625])\n",
            "context_tensors:  tensor([ 1423, 24429, 27965, 21359,  3017, 12252])context_tensors: \n",
            " tensor([18008, 12862, 18520,  2776, 17625, 18520])context_tensors: \n",
            " tensor([24429, 27965, 18253,  3017, 12252,    76])context_tensors: \n",
            " context_tensors:  tensor([27965, 18253, 21359, 12252,    76,  1410])\n",
            "tensor([12862, 18520, 26026, 17625, 18520, 17821])context_tensors: \n",
            " context_tensors: tensor([18253, 21359,  3017,    76,  1410, 11406])\n",
            " tensor([18520, 26026,  2776, 18520, 17821, 12777])context_tensors:  tensor([21359,  3017, 12252,  1410, 11406, 24656])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026,  2776, 17625, 17821, 12777,  2371])tensor([ 3017, 12252,    76, 11406, 24656, 28479])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2776, 17625, 18520, 12777,  2371,  2532]) tensor([12252,    76,  1410, 24656, 28479, 20775])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17625, 18520, 17821,  2371,  2532,    76])tensor([   76,  1410, 11406, 28479, 20775, 12600])\n",
            "\n",
            "context_tensors: context_tensors:   \n",
            "tensor([18520, 17821, 12777,  2532,    76, 28175])tensor([ 1410, 11406, 24656, 20775, 12600, 26026])\n",
            "context_tensors: context_tensors:   tensor([17821, 12777,  2371,    76, 28175, 12153])tensor([11406, 24656, 28479, 12600, 26026, 24430])\n",
            "\n",
            "context_tensors:  tensor([12777,  2371,  2532, 28175, 12153,  3686])context_tensors: \n",
            " context_tensors: tensor([24656, 28479, 20775, 26026, 24430, 17904]) \n",
            "tensor([ 2371,  2532,    76, 12153,  3686, 15787])\n",
            "context_tensors:  context_tensors: tensor([ 2532,    76, 28175,  3686, 15787, 13448]) \n",
            "context_tensors: tensor([28479, 20775, 12600, 24430, 17904,    79]) tensor([   76, 28175, 12153, 15787, 13448, 15729])\n",
            "context_tensors:  tensor([28175, 12153,  3686, 13448, 15729, 22464])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([12153,  3686, 15787, 15729, 22464,  5775])\n",
            " context_tensors: tensor([20775, 12600, 26026, 17904,    79,  1409])\n",
            "context_tensors:   tensor([ 3686, 15787, 13448, 22464,  5775, 12198])\n",
            "context_tensors: tensor([ 1411,  3476,  7929,  4670, 26026, 10776])\n",
            " context_tensors:  tensor([ 3476,  7929,  2371, 26026, 10776, 10182])\n",
            "context_tensors:  tensor([ 7929,  2371,  4670, 10776, 10182,  6926])\n",
            "context_tensors: tensor([15787, 13448, 15729,  5775, 12198,    79]) \n",
            "tensor([ 2371,  4670, 26026, 10182,  6926,    76])context_tensors: \n",
            " context_tensors:  tensor([13448, 15729, 22464, 12198,    79,  1409])tensor([ 4670, 26026, 10776,  6926,    76,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 17625, 13448, 26026, 26440])\n",
            "tensor([26026, 10776, 10182,    76,  2371,  3526])context_tensors:  \n",
            "tensor([26026, 17625, 21809, 26026, 26440,  4666])context_tensors: \n",
            " context_tensors:  tensor([10776, 10182,  6926,  2371,  3526,  8947])tensor([17625, 21809, 13448, 26440,  4666, 10866])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([10182,  6926,    76,  3526,  8947, 18605])\n",
            "context_tensors:   tensor([21809, 13448, 26026,  4666, 10866,  2659])\n",
            "tensor([ 6926,    76,  2371,  8947, 18605, 26026])\n",
            "context_tensors: context_tensors:  tensor([   76,  2371,  3526, 18605, 26026, 10778]) \n",
            "tensor([13448, 26026, 26440, 10866,  2659, 10492])context_tensors:  tensor([ 2371,  3526,  8947, 26026, 10778,  2371])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3526,  8947, 18605, 10778,  2371, 15375])\n",
            " context_tensors: tensor([26026, 26440,  4666,  2659, 10492,  1416])\n",
            " tensor([ 8947, 18605, 26026,  2371, 15375, 18520])context_tensors: \n",
            " tensor([26440,  4666, 10866, 10492,  1416, 10648])context_tensors: \n",
            " tensor([18605, 26026, 10778, 15375, 18520, 26026])context_tensors: \n",
            " tensor([ 4666, 10866,  2659,  1416, 10648, 28614])context_tensors: \n",
            "context_tensors:   tensor([26026, 10778,  2371, 18520, 26026, 19256])tensor([10866,  2659, 10492, 10648, 28614,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2659, 10492,  1416, 28614,    79,  1409])tensor([10778,  2371, 15375, 26026, 19256, 19884])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026,  2734, 26026, 26440,  4666])tensor([ 2371, 15375, 18520, 19256, 19884, 26285])\n",
            "\n",
            "context_tensors:  tensor([26026,  2734, 25429, 26440,  4666, 12153])\n",
            "context_tensors: context_tensors:  tensor([15375, 18520, 26026, 19884, 26285,  3623]) tensor([ 2734, 25429, 26026,  4666, 12153,  3686])\n",
            "\n",
            "context_tensors:  tensor([18520, 26026, 19256, 26285,  3623, 13307])\n",
            "context_tensors: context_tensors:   tensor([25429, 26026, 26440, 12153,  3686, 14958])tensor([26026, 19256, 19884,  3623, 13307,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([19256, 19884, 26285, 13307,    79,  1409])\n",
            " context_tensors:  tensor([ 1411, 26026,  6926, 14763, 13448,  1423])tensor([26026, 26440,  4666,  3686, 14958,  2858])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,  6926, 28115, 13448,  1423, 26767]) \n",
            "tensor([26440,  4666, 12153, 14958,  2858,  2831])context_tensors: \n",
            " context_tensors: tensor([ 6926, 28115, 14763,  1423, 26767, 13448])\n",
            " tensor([ 4666, 12153,  3686,  2858,  2831, 19218])context_tensors: \n",
            " context_tensors: tensor([28115, 14763, 13448, 26767, 13448, 12600]) \n",
            "context_tensors: tensor([12153,  3686, 14958,  2831, 19218, 28165]) \n",
            "tensor([14763, 13448,  1423, 13448, 12600, 25098])context_tensors: \n",
            " context_tensors: tensor([ 3686, 14958,  2858, 19218, 28165, 26026])\n",
            " tensor([13448,  1423, 26767, 12600, 25098,  2185])context_tensors:  \n",
            "tensor([14958,  2858,  2831, 28165, 26026, 10609])context_tensors: \n",
            "context_tensors:   tensor([ 1423, 26767, 13448, 25098,  2185, 28356])tensor([ 2858,  2831, 19218, 26026, 10609,  7612])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26767, 13448, 12600,  2185, 28356, 28315])tensor([ 2831, 19218, 28165, 10609,  7612,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19218, 28165, 26026,  7612,  2371, 26049])tensor([13448, 12600, 25098, 28356, 28315, 16104])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12600, 25098,  2185, 28315, 16104, 18520])tensor([28165, 26026, 10609,  2371, 26049, 15261])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([25098,  2185, 28356, 16104, 18520, 26899])tensor([26026, 10609,  7612, 26049, 15261, 21858])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10609,  7612,  2371, 15261, 21858,  5775])tensor([ 2185, 28356, 28315, 18520, 26899,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 7612,  2371, 26049, 21858,  5775, 19218])tensor([28356, 28315, 16104, 26899,  2371,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26049, 15261,  5775, 19218,    79])tensor([28315, 16104, 18520,  2371,  1410,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26049, 15261, 21858, 19218,    79,  1409])tensor([16104, 18520, 26899,  1410,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  8830, 26285,  9107, 18520,  3840])tensor([ 1411,  8947, 27965,  8658,  1900,  2334])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 8947, 27965,  4563,  1900,  2334, 13310])tensor([ 8830, 26285, 26026, 18520,  3840,  3279])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285, 26026,  9107,  3840,  3279,    76])tensor([27965,  4563,  8658,  2334, 13310, 27965])\n",
            "\n",
            "context_tensors:  tensor([26026,  9107, 18520,  3279,    76, 13007])context_tensors:  \n",
            "tensor([ 4563,  8658,  1900, 13310, 27965,  6320])\n",
            "context_tensors: context_tensors:   tensor([ 9107, 18520,  3840,    76, 13007,    76])tensor([ 8658,  1900,  2334, 27965,  6320,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18520,  3840,  3279, 13007,    76, 26026])tensor([ 1900,  2334, 13310,  6320,  2371, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3840,  3279,    76,    76, 26026,  5775])\n",
            "tensor([ 2334, 13310, 27965,  2371, 26026, 19271])\n",
            "context_tensors: context_tensors:   tensor([13310, 27965,  6320, 26026, 19271, 21538])tensor([ 3279,    76, 13007, 26026,  5775, 10544])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([   76, 13007,    76,  5775, 10544, 17741])\n",
            " context_tensors:  tensor([13007,    76, 26026, 10544, 17741, 14210])\n",
            "tensor([27965,  6320,  2371, 19271, 21538, 10866])context_tensors:  \n",
            "tensor([   76, 26026,  5775, 17741, 14210, 16067])\n",
            "context_tensors:  tensor([ 6320,  2371, 26026, 21538, 10866, 18832])context_tensors: \n",
            " context_tensors:  tensor([ 2371, 26026, 19271, 10866, 18832,  6926])tensor([26026,  5775, 10544, 14210, 16067, 19218])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 5775, 10544, 17741, 16067, 19218, 13448])\n",
            " context_tensors: tensor([26026, 19271, 21538, 18832,  6926,    79])\n",
            " context_tensors: tensor([10544, 17741, 14210, 19218, 13448,   716])\n",
            " tensor([19271, 21538, 10866,  6926,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([17741, 14210, 16067, 13448,   716, 13448]) \n",
            "tensor([ 1411, 23615, 18551, 26285,  8180,  5847])context_tensors: \n",
            " tensor([14210, 16067, 19218,   716, 13448, 12891])context_tensors: \n",
            " context_tensors: tensor([23615, 18551, 21596,  8180,  5847,  4902])\n",
            " tensor([16067, 19218, 13448, 13448, 12891, 18520])context_tensors: \n",
            " context_tensors: tensor([18551, 21596, 26285,  5847,  4902,    62])\n",
            " context_tensors: tensor([19218, 13448,   716, 12891, 18520,  8648]) tensor([21596, 26285,  8180,  4902,    62,  9457])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285,  8180,  5847,    62,  9457,  6925])tensor([13448,   716, 13448, 18520,  8648, 16067])\n",
            "context_tensors: \n",
            " context_tensors: tensor([8180, 5847, 4902, 9457, 6925,   79]) \n",
            "tensor([  716, 13448, 12891,  8648, 16067,    79])context_tensors:  \n",
            "context_tensors: tensor([5847, 4902,   62, 6925,   79, 1409]) \n",
            "tensor([13448, 12891, 18520, 16067,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 13448,   784, 26026, 17625, 18520])tensor([ 1411, 13448, 26026,   690,    76,  3476])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448,   784,    76, 17625, 18520, 23116])\n",
            " tensor([13448, 26026, 15258,    76,  3476,  3705])context_tensors: \n",
            " context_tensors:  tensor([  784,    76, 26026, 18520, 23116,  2371])tensor([26026, 15258,   690,  3476,  3705, 26285])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([15258,   690,    76,  3705, 26285,  8642])tensor([   76, 26026, 17625, 23116,  2371, 17821])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  690,    76,  3476, 26285,  8642, 23615])tensor([26026, 17625, 18520,  2371, 17821, 12777])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([17625, 18520, 23116, 17821, 12777, 16846]) \n",
            "tensor([   76,  3476,  3705,  8642, 23615, 27965])context_tensors:  \n",
            "tensor([18520, 23116,  2371, 12777, 16846, 28356])\n",
            "context_tensors:  tensor([ 3476,  3705, 26285, 23615, 27965,  8544])context_tensors: \n",
            " tensor([23116,  2371, 17821, 16846, 28356, 26026])context_tensors: \n",
            " tensor([ 3705, 26285,  8642, 27965,  8544,  9490])context_tensors: \n",
            " tensor([ 2371, 17821, 12777, 28356, 26026, 15729])\n",
            "context_tensors:  tensor([26285,  8642, 23615,  8544,  9490, 10866])\n",
            "context_tensors: context_tensors:   tensor([17821, 12777, 16846, 26026, 15729, 22464])tensor([ 8642, 23615, 27965,  9490, 10866, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([12777, 16846, 28356, 15729, 22464,  5614])\n",
            " tensor([23615, 27965,  8544, 10866, 26026,  5715])\n",
            "context_tensors:  context_tensors: tensor([16846, 28356, 26026, 22464,  5614,    62]) \n",
            "tensor([27965,  8544,  9490, 26026,  5715,  2371])context_tensors: \n",
            " context_tensors: tensor([28356, 26026, 15729,  5614,    62, 17625]) \n",
            "tensor([ 8544,  9490, 10866,  5715,  2371,  6578])\n",
            "context_tensors: context_tensors:  tensor([26026, 15729, 22464,    62, 17625,    76]) \n",
            "tensor([ 9490, 10866, 26026,  2371,  6578, 10817])context_tensors:  \n",
            "context_tensors: tensor([15729, 22464,  5614, 17625,    76, 28175]) \n",
            "context_tensors: tensor([10866, 26026,  5715,  6578, 10817, 24218])\n",
            " tensor([22464,  5614,    62,    76, 28175, 12153])context_tensors: \n",
            "context_tensors:   tensor([26026,  5715,  2371, 10817, 24218, 18605])\n",
            "tensor([ 5614,    62, 17625, 28175, 12153,  3686])context_tensors: \n",
            " context_tensors: tensor([ 5715,  2371,  6578, 24218, 18605, 22774]) \n",
            "tensor([   62, 17625,    76, 12153,  3686, 15787])context_tensors: \n",
            " context_tensors: tensor([ 2371,  6578, 10817, 18605, 22774, 28449]) \n",
            "tensor([17625,    76, 28175,  3686, 15787, 13448])context_tensors: \n",
            " context_tensors: tensor([ 6578, 10817, 24218, 22774, 28449,    79]) \n",
            "tensor([   76, 28175, 12153, 15787, 13448, 27157])\n",
            "context_tensors:  context_tensors: tensor([10817, 24218, 18605, 28449,    79,  1409]) \n",
            "tensor([28175, 12153,  3686, 13448, 27157, 24763])context_tensors: \n",
            " context_tensors: tensor([ 1411, 10217,  2371, 21486, 23615,  6698]) \n",
            "tensor([12153,  3686, 15787, 27157, 24763,    76])context_tensors: \n",
            " tensor([10217,  2371, 11138, 23615,  6698, 23284])context_tensors: \n",
            " context_tensors: tensor([ 3686, 15787, 13448, 24763,    76, 26285]) \n",
            "tensor([ 2371, 11138, 21486,  6698, 23284,  2371])context_tensors: \n",
            " context_tensors: tensor([15787, 13448, 27157,    76, 26285, 10931]) \n",
            "tensor([11138, 21486, 23615, 23284,  2371, 22774])\n",
            "context_tensors:  context_tensors: tensor([13448, 27157, 24763, 26285, 10931, 26026]) \n",
            "tensor([21486, 23615,  6698,  2371, 22774, 28449])\n",
            "context_tensors:  context_tensors: tensor([27157, 24763,    76, 10931, 26026,  2776]) \n",
            "tensor([23615,  6698, 23284, 22774, 28449,    76])context_tensors: \n",
            " tensor([24763,    76, 26285, 26026,  2776, 17625])\n",
            "context_tensors: context_tensors:   tensor([ 6698, 23284,  2371, 28449,    76, 28175])tensor([   76, 26285, 10931,  2776, 17625, 18520])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([23284,  2371, 22774,    76, 28175, 23615]) \n",
            "tensor([26285, 10931, 26026, 17625, 18520,  8278])\n",
            "context_tensors: context_tensors:   tensor([10931, 26026,  2776, 18520,  8278,    79])\n",
            "tensor([ 2371, 22774, 28449, 28175, 23615,  8109])context_tensors:  tensor([26026,  2776, 17625,  8278,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22774, 28449,    76, 23615,  8109,    79])tensor([ 1411, 26026, 18008, 27965, 21798, 26285])\n",
            "\n",
            "context_tensors:  tensor([28449,    76, 28175,  8109,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([26026, 18008, 17625, 21798, 26285,  1423])\n",
            "tensor([1411, 3476, 6699, 3073, 9802, 5824])context_tensors: \n",
            " context_tensors: tensor([18008, 17625, 27965, 26285,  1423, 12772]) \n",
            "tensor([ 3476,  6699, 26285,  9802,  5824,  3017])\n",
            "context_tensors: context_tensors:   tensor([17625, 27965, 21798,  1423, 12772,  4666])tensor([ 6699, 26285,  3073,  5824,  3017, 26026])\n",
            "\n",
            "context_tensors:  tensor([27965, 21798, 26285, 12772,  4666, 13448])context_tensors:  \n",
            "tensor([26285,  3073,  9802,  3017, 26026,  7203])\n",
            "context_tensors: context_tensors:   tensor([21798, 26285,  1423,  4666, 13448, 26026])tensor([ 3073,  9802,  5824, 26026,  7203,  2833])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 9802,  5824,  3017,  7203,  2833, 23094]) \n",
            "tensor([26285,  1423, 12772, 13448, 26026, 15729])context_tensors: \n",
            "context_tensors:  tensor([ 5824,  3017, 26026,  2833, 23094,  3886]) tensor([ 1423, 12772,  4666, 26026, 15729, 22464])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3017, 26026,  7203, 23094,  3886, 26026]) \n",
            "tensor([12772,  4666, 13448, 15729, 22464, 22404])context_tensors: \n",
            " context_tensors:  tensor([ 4666, 13448, 26026, 22464, 22404, 16418])\n",
            "tensor([26026,  7203,  2833,  3886, 26026,   690])\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 15729, 22404, 16418,  8440])\n",
            "tensor([ 7203,  2833, 23094, 26026,   690,  2371])\n",
            "context_tensors:  context_tensors:  tensor([26026, 15729, 22464, 16418,  8440,    79])tensor([ 2833, 23094,  3886,   690,  2371, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([23094,  3886, 26026,  2371, 26026,   714])\n",
            " context_tensors: tensor([15729, 22464, 22404,  8440,    79,  1409]) \n",
            "tensor([ 3886, 26026,   690, 26026,   714,    76])\n",
            "context_tensors:  tensor([ 1411, 26026, 16067, 18520,  2776, 17026])\n",
            "context_tensors: context_tensors:  tensor([26026,   690,  2371,   714,    76,  9809]) \n",
            "tensor([26026, 16067, 17625,  2776, 17026, 12777])context_tensors: \n",
            " tensor([  690,  2371, 26026,    76,  9809, 21444])\n",
            "context_tensors:  tensor([ 2371, 26026,   714,  9809, 21444,  1423])context_tensors: \n",
            " context_tensors:  tensor([16067, 17625, 18520, 17026, 12777, 18633])tensor([26026,   714,    76, 21444,  1423, 25817])\n",
            "\n",
            "context_tensors:  tensor([17625, 18520,  2776, 12777, 18633, 18605])\n",
            "context_tensors: context_tensors:   tensor([  714,    76,  9809,  1423, 25817, 20176])\n",
            "tensor([18520,  2776, 17026, 18633, 18605, 16599])context_tensors: \n",
            "context_tensors:   tensor([   76,  9809, 21444, 25817, 20176,    79])\n",
            "tensor([ 2776, 17026, 12777, 18605, 16599,   664])context_tensors: \n",
            " tensor([ 9809, 21444,  1423, 20176,    79,  1409])context_tensors: \n",
            " tensor([17026, 12777, 18633, 16599,   664,    76])context_tensors: \n",
            " context_tensors: tensor([ 1411, 23615, 26353, 26712, 26285,  1410]) \n",
            "context_tensors: tensor([12777, 18633, 18605,   664,    76,   798])\n",
            "context_tensors:  tensor([18633, 18605, 16599,    76,   798, 13448]) tensor([23615, 26353,  1410, 26285,  1410,  2371])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18605, 16599,   664,   798, 13448, 26026])\n",
            " tensor([26353,  1410, 26712,  1410,  2371, 24953])context_tensors:  tensor([16599,   664,    76, 13448, 26026, 26440])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([  664,    76,   798, 26026, 26440,  4666]) \n",
            "tensor([ 1410, 26712, 26285,  2371, 24953, 13448])\n",
            "context_tensors: context_tensors:   tensor([   76,   798, 13448, 26440,  4666,    79])\n",
            "tensor([26712, 26285,  1410, 24953, 13448, 25464])context_tensors: \n",
            " tensor([  798, 13448, 26026,  4666,    79,  1409])context_tensors:  \n",
            "tensor([26285,  1410,  2371, 13448, 25464,  2371])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 18008,    62, 11723, 14156])\n",
            "tensor([ 1410,  2371, 24953, 25464,  2371, 26285])context_tensors: \n",
            " context_tensors:  tensor([26026, 18008, 17625, 11723, 14156, 26285])\n",
            "context_tensors: tensor([ 2371, 24953, 13448,  2371, 26285,  6862]) \n",
            "tensor([18008, 17625,    62, 14156, 26285,  9081])context_tensors:  \n",
            "tensor([24953, 13448, 25464, 26285,  6862,  2371])\n",
            "context_tensors: context_tensors:  tensor([13448, 25464,  2371,  6862,  2371, 26026])\n",
            " tensor([17625,    62, 11723, 26285,  9081,  2371])context_tensors: \n",
            "context_tensors:  tensor([   62, 11723, 14156,  9081,  2371, 13671])\n",
            " tensor([25464,  2371, 26285,  2371, 26026, 24344])context_tensors:  tensor([11723, 14156, 26285,  2371, 13671, 27742])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26285,  6862, 26026, 24344,  5972])\n",
            "tensor([14156, 26285,  9081, 13671, 27742,  1497])context_tensors: \n",
            " tensor([26285,  6862,  2371, 24344,  5972, 28356])\n",
            "context_tensors: context_tensors:  tensor([26285,  9081,  2371, 27742,  1497, 26026]) \n",
            "tensor([ 6862,  2371, 26026,  5972, 28356, 10217])context_tensors:  tensor([ 9081,  2371, 13671,  1497, 26026, 17026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26026, 24344, 28356, 10217,  2371])tensor([ 2371, 13671, 27742, 26026, 17026, 12777])\n",
            "context_tensors:  tensor([26026, 24344,  5972, 10217,  2371, 11138])\n",
            "tensor([24344,  5972, 28356,  2371, 11138,    79])\n",
            "context_tensors:  \n",
            "context_tensors: context_tensors:  tensor([ 5972, 28356, 10217, 11138,    79,  1409]) \n",
            "tensor([13671, 27742,  1497, 17026, 12777, 18520])\n",
            "context_tensors:  context_tensors:  tensor([27742,  1497, 26026, 12777, 18520,  2776])\n",
            "tensor([ 1411, 23615, 27739, 24784, 28356,  2848])context_tensors:  tensor([ 1497, 26026, 17026, 18520,  2776,    76])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([23615, 27739,  2371, 28356,  2848, 16380])\n",
            "context_tensors: tensor([26026, 17026, 12777,  2776,    76, 20424])\n",
            " context_tensors: tensor([27739,  2371, 24784,  2848, 16380,  1410]) \n",
            "context_tensors: tensor([17026, 12777, 18520,    76, 20424, 26026])\n",
            " tensor([ 2371, 24784, 28356, 16380,  1410, 13448])context_tensors: \n",
            " tensor([12777, 18520,  2776, 20424, 26026, 26440])context_tensors:  \n",
            "tensor([24784, 28356,  2848,  1410, 13448,  1410])\n",
            "context_tensors:  tensor([18520,  2776,    76, 26026, 26440,  4666])\n",
            "context_tensors: context_tensors:  tensor([ 2776,    76, 20424, 26440,  4666,    76])\n",
            " context_tensors: tensor([28356,  2848, 16380, 13448,  1410,    76]) tensor([   76, 20424, 26026,  4666,    76, 12891])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([20424, 26026, 26440,    76, 12891, 23474])\n",
            " context_tensors:  tensor([ 2848, 16380,  1410,  1410,    76, 25425])tensor([26026, 26440,  4666, 12891, 23474,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16380,  1410, 13448,    76, 25425,  2371])tensor([26440,  4666,    76, 23474,  2371,  1410])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 4666,    76, 12891,  2371,  1410, 18520]) \n",
            "tensor([ 1410, 13448,  1410, 25425,  2371, 28356])context_tensors: \n",
            "context_tensors:   tensor([   76, 12891, 23474,  1410, 18520, 26026])tensor([13448,  1410,    76,  2371, 28356, 10217])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410,    76, 25425, 28356, 10217, 13448])tensor([12891, 23474,  2371, 18520, 26026, 27167])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 25425,  2371, 10217, 13448,  1410])\n",
            "tensor([23474,  2371,  1410, 26026, 27167, 24759])\n",
            "context_tensors:  context_tensors: tensor([25425,  2371, 28356, 13448,  1410,    76])\n",
            " context_tensors: tensor([ 2371, 28356, 10217,  1410,    76, 17873]) \n",
            "tensor([ 2371,  1410, 18520, 27167, 24759,  2371])context_tensors: \n",
            " context_tensors: tensor([28356, 10217, 13448,    76, 17873, 28189])\n",
            " context_tensors: tensor([ 1410, 18520, 26026, 24759,  2371,  6197])\n",
            " tensor([10217, 13448,  1410, 17873, 28189,    76])\n",
            "tensor([18520, 26026, 27167,  2371,  6197, 26026])context_tensors:  context_tensors: \n",
            "context_tensors:   tensor([26026, 27167, 24759,  6197, 26026,  4001])tensor([13448,  1410,    76, 28189,    76, 18219])\n",
            "\n",
            "context_tensors: context_tensors:  \n",
            "tensor([ 1410,    76, 17873,    76, 18219, 28657])context_tensors:   tensor([   76, 17873, 28189, 18219, 28657,    79])tensor([27167, 24759,  2371, 26026,  4001, 18520])\n",
            "context_tensors: \n",
            " context_tensors: tensor([24759,  2371,  6197,  4001, 18520,  8648]) \n",
            "tensor([17873, 28189,    76, 28657,    79,  1409])context_tensors:  tensor([ 2371,  6197, 26026, 18520,  8648, 16067])\n",
            "\n",
            "context_tensors: \n",
            " tensor([ 6197, 26026,  4001,  8648, 16067,    79])context_tensors:  tensor([26026,  4001, 18520, 16067,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411,  1410, 16479,    72,   919, 14553])\n",
            "tensor([ 1411, 13448,   713, 26026,  3476,    62])\n",
            "context_tensors:  context_tensors:  tensor([ 1410, 16479,  3476,   919, 14553,   658])tensor([13448,   713,    76,  3476,    62, 15732])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16479,  3476,    72, 14553,   658, 28846])\n",
            "tensor([  713,    76, 26026,    62, 15732,  1416])\n",
            "context_tensors: context_tensors:   tensor([ 3476,    72,   919,   658, 28846,   373])\n",
            "tensor([   76, 26026,  3476, 15732,  1416, 13448])context_tensors: \n",
            "context_tensors:   tensor([26026,  3476,    62,  1416, 13448, 16164])\n",
            "context_tensors: tensor([   72,   919, 14553, 28846,   373, 10354]) \n",
            "tensor([ 3476,    62, 15732, 13448, 16164, 22156])\n",
            "context_tensors: context_tensors:   tensor([   62, 15732,  1416, 16164, 22156,    76])tensor([  919, 14553,   658,   373, 10354,   756])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([15732,  1416, 13448, 22156,    76,  2371]) tensor([14553,   658, 28846, 10354,   756,    73])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1416, 13448, 16164,    76,  2371,  8627])\n",
            "tensor([  658, 28846,   373,   756,    73, 27965])context_tensors: \n",
            "context_tensors:   tensor([28846,   373, 10354,    73, 27965,  2334])\n",
            "context_tensors: tensor([13448, 16164, 22156,  2371,  8627,  3476]) \n",
            "tensor([  373, 10354,   756, 27965,  2334,  9457])\n",
            "context_tensors: context_tensors:   tensor([16164, 22156,    76,  8627,  3476,  5918])tensor([10354,   756,    73,  2334,  9457, 13312])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  756,    73, 27965,  9457, 13312,  3862])tensor([22156,    76,  2371,  3476,  5918, 12600])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  2371,  8627,  5918, 12600, 23094])tensor([   73, 27965,  2334, 13312,  3862, 14958])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([27965,  2334,  9457,  3862, 14958, 10866])tensor([ 2371,  8627,  3476, 12600, 23094,  3017])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2334,  9457, 13312, 14958, 10866,  1423])\n",
            " tensor([ 8627,  3476,  5918, 23094,  3017, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 3476,  5918, 12600,  3017, 26026,  3293])\n",
            "tensor([ 9457, 13312,  3862, 10866,  1423, 23457])context_tensors: \n",
            " tensor([ 5918, 12600, 23094, 26026,  3293, 18520])context_tensors:  tensor([13312,  3862, 14958,  1423, 23457, 18520])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3862, 14958, 10866, 23457, 18520, 10236])\n",
            "tensor([12600, 23094,  3017,  3293, 18520, 26026])context_tensors: \n",
            "context_tensors:  tensor([23094,  3017, 26026, 18520, 26026, 12990])\n",
            " tensor([14958, 10866,  1423, 18520, 10236, 13311])\n",
            "context_tensors:  tensor([10866,  1423, 23457, 10236, 13311,  7849])\n",
            "context_tensors: context_tensors:   tensor([ 3017, 26026,  3293, 26026, 12990, 13448])\n",
            "tensor([ 1423, 23457, 18520, 13311,  7849, 10179])context_tensors: \n",
            " context_tensors:  tensor([26026,  3293, 18520, 12990, 13448, 26026])tensor([23457, 18520, 10236,  7849, 10179,  2371])\n",
            "\n",
            "context_tensors:  tensor([18520, 10236, 13311, 10179,  2371, 10778])\n",
            "context_tensors: context_tensors:  tensor([10236, 13311,  7849,  2371, 10778,    79]) \n",
            "tensor([ 3293, 18520, 26026, 13448, 26026, 27881])\n",
            "context_tensors: context_tensors:  tensor([13311,  7849, 10179, 10778,    79,  1409])\n",
            " tensor([18520, 26026, 12990, 26026, 27881,    79])\n",
            "context_tensors:  context_tensors:  tensor([ 1411,  3476,    62,  9083,  3705, 13448])\n",
            "context_tensors: tensor([26026, 12990, 13448, 27881,    79,  1409]) tensor([ 3476,    62,  2833,  3705, 13448, 11648])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 23615,  6699, 25355, 26026, 12993])tensor([   62,  2833,  9083, 13448, 11648, 28356])\n",
            "\n",
            "context_tensors:  tensor([ 2833,  9083,  3705, 11648, 28356,  6888])context_tensors: \n",
            " tensor([23615,  6699, 26285, 26026, 12993,    76])\n",
            "context_tensors: context_tensors:  tensor([ 9083,  3705, 13448, 28356,  6888,  6992])\n",
            " context_tensors: tensor([ 6699, 26285, 25355, 12993,    76,  2371])\n",
            " tensor([ 3705, 13448, 11648,  6888,  6992,  2371])context_tensors:  \n",
            "tensor([26285, 25355, 26026,    76,  2371, 26285])context_tensors: \n",
            " tensor([13448, 11648, 28356,  6992,  2371, 13844])context_tensors:  tensor([25355, 26026, 12993,  2371, 26285, 11652])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([11648, 28356,  6888,  2371, 13844,  3017]) tensor([26026, 12993,    76, 26285, 11652,  4304])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28356,  6888,  6992, 13844,  3017, 26026])tensor([12993,    76,  2371, 11652,  4304, 12600])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6888,  6992,  2371,  3017, 26026,  7203])tensor([   76,  2371, 26285,  4304, 12600, 17455])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2371, 26285, 11652, 12600, 17455,  2371])\n",
            "tensor([ 6992,  2371, 13844, 26026,  7203, 23094])\n",
            "context_tensors:  context_tensors: tensor([26285, 11652,  4304, 17455,  2371, 23970])\n",
            " tensor([ 2371, 13844,  3017,  7203, 23094, 18520])context_tensors: \n",
            " tensor([11652,  4304, 12600,  2371, 23970, 26026])\n",
            "context_tensors: context_tensors:   tensor([13844,  3017, 26026, 23094, 18520,  2833])\n",
            "tensor([ 4304, 12600, 17455, 23970, 26026,  5073])context_tensors: \n",
            " context_tensors:  tensor([12600, 17455,  2371, 26026,  5073, 26083])tensor([ 3017, 26026,  7203, 18520,  2833,    79])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,  7203, 23094,  2833,    79,  1409]) \n",
            "tensor([17455,  2371, 23970,  5073, 26083, 17904])context_tensors: \n",
            " context_tensors:  tensor([ 1411, 12600,  8956, 28438, 13495,  1410])\n",
            "tensor([ 2371, 23970, 26026, 26083, 17904,    79])context_tensors: \n",
            " context_tensors: tensor([12600,  8956, 20586, 13495,  1410,  5072])\n",
            " context_tensors: tensor([23970, 26026,  5073, 17904,    79,  1409])\n",
            "context_tensors:   tensor([ 1411,  8627,  2371, 23970,  6062, 27296])\n",
            "tensor([ 8956, 20586, 28438,  1410,  5072,  2371])context_tensors: \n",
            "context_tensors:  tensor([ 8627,  2371, 12600,  6062, 27296, 18616]) \n",
            "tensor([20586, 28438, 13495,  5072,  2371, 14584])\n",
            "context_tensors: context_tensors:   tensor([28438, 13495,  1410,  2371, 14584, 16121])\n",
            "tensor([ 2371, 12600, 23970, 27296, 18616, 26910])context_tensors:  \n",
            "tensor([13495,  1410,  5072, 14584, 16121, 13311])\n",
            "context_tensors:  tensor([ 1410,  5072,  2371, 16121, 13311,    76])\n",
            "context_tensors: context_tensors:   tensor([ 5072,  2371, 14584, 13311,    76,  2371])\n",
            "context_tensors: tensor([12600, 23970,  6062, 18616, 26910,  4246]) \n",
            "tensor([ 2371, 14584, 16121,    76,  2371, 12600])\n",
            "context_tensors:  context_tensors: tensor([23970,  6062, 27296, 26910,  4246,  1406]) \n",
            "tensor([14584, 16121, 13311,  2371, 12600, 10609])context_tensors: \n",
            " tensor([ 6062, 27296, 18616,  4246,  1406, 18848])context_tensors: \n",
            " context_tensors: tensor([16121, 13311,    76, 12600, 10609,  4240])\n",
            " context_tensors: tensor([27296, 18616, 26910,  1406, 18848,  7473]) tensor([13311,    76,  2371, 10609,  4240,    76])\n",
            "\n",
            "context_tensors:  tensor([   76,  2371, 12600,  4240,    76, 10776])\n",
            "context_tensors:  tensor([18616, 26910,  4246, 18848,  7473,    62])context_tensors: \n",
            " context_tensors:  tensor([ 2371, 12600, 10609,    76, 10776, 10179])\n",
            "tensor([26910,  4246,  1406,  7473,    62, 10609])context_tensors: \n",
            " tensor([12600, 10609,  4240, 10776, 10179, 18520])context_tensors: \n",
            " tensor([ 4246,  1406, 18848,    62, 10609,  4240])\n",
            "context_tensors: context_tensors:   tensor([10609,  4240,    76, 10179, 18520, 26026])\n",
            "tensor([ 1406, 18848,  7473, 10609,  4240,  2371])\n",
            "context_tensors: context_tensors:  tensor([18848,  7473,    62,  4240,  2371, 26026]) tensor([ 4240,    76, 10776, 18520, 26026, 24589])\n",
            "context_tensors: \n",
            " tensor([ 7473,    62, 10609,  2371, 26026,  5671])context_tensors: \n",
            " tensor([   76, 10776, 10179, 26026, 24589,    76])context_tensors: \n",
            " context_tensors:  tensor([   62, 10609,  4240, 26026,  5671,  1416])\n",
            "context_tensors: tensor([10776, 10179, 18520, 24589,    76, 27965]) \n",
            "tensor([10609,  4240,  2371,  5671,  1416, 26046])context_tensors: \n",
            " context_tensors: tensor([10179, 18520, 26026,    76, 27965, 20849]) \n",
            "tensor([ 4240,  2371, 26026,  1416, 26046,    76])\n",
            "context_tensors: context_tensors:  tensor([ 2371, 26026,  5671, 26046,    76, 12451])\n",
            " context_tensors: tensor([18520, 26026, 24589, 27965, 20849, 13448])\n",
            " context_tensors: tensor([26026,  5671,  1416,    76, 12451, 15341]) \n",
            "tensor([26026, 24589,    76, 20849, 13448,   693])\n",
            "context_tensors:  context_tensors: tensor([ 5671,  1416, 26046, 12451, 15341, 16681]) \n",
            "tensor([24589,    76, 27965, 13448,   693,    79])context_tensors: \n",
            " tensor([ 1416, 26046,    76, 15341, 16681,    79])context_tensors: \n",
            "context_tensors:   tensor([   76, 27965, 20849,   693,    79,  1409])tensor([26046,    76, 12451, 16681,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 13448,   733,  3476,  8113, 18520]) \n",
            "tensor([ 1411, 23904,  4246, 20849, 13448, 26026])\n",
            "context_tensors:  tensor([13448,   733,  8627,  8113, 18520,  1423])\n",
            "context_tensors: context_tensors:  tensor([  733,  8627,  3476, 18520,  1423, 12484]) \n",
            "tensor([23904,  4246, 28115, 13448, 26026, 10839])\n",
            "context_tensors:  tensor([ 4246, 28115, 20849, 26026, 10839,  7567])\n",
            "context_tensors: context_tensors:  tensor([28115, 20849, 13448, 10839,  7567,    79]) \n",
            "tensor([ 8627,  3476,  8113,  1423, 12484,  3058])\n",
            "context_tensors: context_tensors:  tensor([ 3476,  8113, 18520, 12484,  3058,    79]) tensor([20849, 13448, 26026,  7567,    79,  1409])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([ 8113, 18520,  1423,  3058,    79,  1409])tensor([ 1411,  3476, 27965,  8043,  2414,    76])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 3476, 27965,  1423,  2414,    76,  2371])tensor([ 1411,  3476, 27965, 26285, 20945, 12600])\n",
            "\n",
            "context_tensors:  tensor([27965,  1423,  8043,    76,  2371,  8586])context_tensors: \n",
            " context_tensors: tensor([ 3476, 27965, 26998, 20945, 12600,  2833]) \n",
            "tensor([ 1423,  8043,  2414,  2371,  8586, 12600])\n",
            "context_tensors: context_tensors:  tensor([ 8043,  2414,    76,  8586, 12600,  2855])\n",
            " context_tensors: tensor([27965, 26998, 26285, 12600,  2833, 26285])\n",
            " tensor([ 2414,    76,  2371, 12600,  2855, 26285])\n",
            "context_tensors:  tensor([   76,  2371,  8586,  2855, 26285,  5671])\n",
            "context_tensors: context_tensors:   tensor([ 2371,  8586, 12600, 26285,  5671, 11233])tensor([26998, 26285, 20945,  2833, 26285,  2553])\n",
            "\n",
            "context_tensors:  tensor([ 8586, 12600,  2855,  5671, 11233,  2371])context_tensors: \n",
            " tensor([26285, 20945, 12600, 26285,  2553, 23872])context_tensors: \n",
            " context_tensors: tensor([12600,  2855, 26285, 11233,  2371, 17148]) tensor([20945, 12600,  2833,  2553, 23872, 10080])\n",
            "\n",
            "context_tensors:  tensor([12600,  2833, 26285, 23872, 10080, 10839])\n",
            "context_tensors:  context_tensors: tensor([ 2833, 26285,  2553, 10080, 10839, 12600])\n",
            " context_tensors: tensor([ 2855, 26285,  5671,  2371, 17148, 18748]) tensor([26285,  2553, 23872, 10839, 12600, 23970])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26285,  5671, 11233, 17148, 18748,    79]) tensor([ 2553, 23872, 10080, 12600, 23970,    62])\n",
            "\n",
            "context_tensors:  tensor([23872, 10080, 10839, 23970,    62,  7548])context_tensors:  \n",
            "context_tensors: tensor([ 5671, 11233,  2371, 18748,    79,  1409]) tensor([10080, 10839, 12600,    62,  7548,    76])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([10839, 12600, 23970,  7548,    76,  2858])\n",
            " tensor([ 1411, 23615, 20574, 10446,  5671,  1416])context_tensors:  \n",
            "tensor([12600, 23970,    62,    76,  2858,  2128])\n",
            "context_tensors:  context_tensors:  tensor([23615, 20574,  1423,  5671,  1416, 26046])tensor([23970,    62,  7548,  2858,  2128, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   62,  7548,    76,  2128, 26026,  5073]) \n",
            "tensor([20574,  1423, 10446,  1416, 26046,  4246])\n",
            "context_tensors: context_tensors:   tensor([ 7548,    76,  2858, 26026,  5073, 18520])tensor([ 1423, 10446,  5671, 26046,  4246, 25230])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10446,  5671,  1416,  4246, 25230,  2858])\n",
            "tensor([   76,  2858,  2128,  5073, 18520, 12600])context_tensors: \n",
            "context_tensors:   tensor([ 2858,  2128, 26026, 18520, 12600,  1919])tensor([ 5671,  1416, 26046, 25230,  2858, 26026])\n",
            "\n",
            "context_tensors:  tensor([ 2128, 26026,  5073, 12600,  1919, 17455])\n",
            "context_tensors: context_tensors:  tensor([26026,  5073, 18520,  1919, 17455,  8031]) \n",
            "tensor([ 1416, 26046,  4246,  2858, 26026,  5614])context_tensors:  \n",
            "tensor([ 5073, 18520, 12600, 17455,  8031, 27296])\n",
            "context_tensors:  tensor([26046,  4246, 25230, 26026,  5614, 28849])\n",
            "context_tensors: context_tensors:   tensor([ 4246, 25230,  2858,  5614, 28849, 22750])tensor([18520, 12600,  1919,  8031, 27296, 12600])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12600,  1919, 17455, 27296, 12600,    76])\n",
            "tensor([25230,  2858, 26026, 28849, 22750,  4240])\n",
            "context_tensors:  tensor([ 1919, 17455,  8031, 12600,    76,  4767])context_tensors: \n",
            " context_tensors: tensor([ 2858, 26026,  5614, 22750,  4240, 18520])\n",
            " tensor([17455,  8031, 27296,    76,  4767, 23615])\n",
            "context_tensors:  tensor([26026,  5614, 28849,  4240, 18520, 13156])\n",
            "context_tensors:  tensor([ 8031, 27296, 12600,  4767, 23615,  8109])context_tensors: \n",
            " context_tensors: tensor([ 5614, 28849, 22750, 18520, 13156,  2371]) \n",
            "context_tensors: tensor([27296, 12600,    76, 23615,  8109, 16248])\n",
            " tensor([28849, 22750,  4240, 13156,  2371,    76])\n",
            "context_tensors: context_tensors:  tensor([12600,    76,  4767,  8109, 16248, 26285])\n",
            " tensor([22750,  4240, 18520,  2371,    76, 13448])context_tensors: \n",
            " context_tensors:  tensor([   76,  4767, 23615, 16248, 26285,  3706])\n",
            "tensor([ 4240, 18520, 13156,    76, 13448,  6063])context_tensors: \n",
            " context_tensors: tensor([ 4767, 23615,  8109, 26285,  3706, 19882])\n",
            " context_tensors: tensor([18520, 13156,  2371, 13448,  6063, 28356])\n",
            " context_tensors: tensor([23615,  8109, 16248,  3706, 19882,  1423])\n",
            " tensor([13156,  2371,    76,  6063, 28356, 12600])\n",
            "context_tensors:  tensor([ 8109, 16248, 26285, 19882,  1423, 24671])context_tensors:  \n",
            "tensor([ 2371,    76, 13448, 28356, 12600, 23970])context_tensors: \n",
            " tensor([16248, 26285,  3706,  1423, 24671, 11676])\n",
            "context_tensors:  context_tensors: tensor([   76, 13448,  6063, 12600, 23970,  8627]) \n",
            "tensor([26285,  3706, 19882, 24671, 11676, 28302])\n",
            "context_tensors: context_tensors:  tensor([ 3706, 19882,  1423, 11676, 28302,  7923]) \n",
            "tensor([13448,  6063, 28356, 23970,  8627,    76])\n",
            "context_tensors:  tensor([ 6063, 28356, 12600,  8627,    76, 12451])context_tensors:  \n",
            "tensor([19882,  1423, 24671, 28302,  7923, 13448])\n",
            "context_tensors:  tensor([ 1423, 24671, 11676,  7923, 13448, 12600])\n",
            "context_tensors:  context_tensors: tensor([28356, 12600, 23970,    76, 12451, 15341])\n",
            " tensor([24671, 11676, 28302, 13448, 12600, 23970])context_tensors: \n",
            " tensor([12600, 23970,  8627, 12451, 15341, 16681])context_tensors: \n",
            "context_tensors:   tensor([11676, 28302,  7923, 12600, 23970,    62])tensor([23970,  8627,    76, 15341, 16681,    79])\n",
            "context_tensors: \n",
            " context_tensors: tensor([28302,  7923, 13448, 23970,    62, 16797]) \n",
            "tensor([ 8627,    76, 12451, 16681,    79,  1409])\n",
            "context_tensors:  tensor([ 7923, 13448, 12600,    62, 16797, 10866])context_tensors: \n",
            " context_tensors:  tensor([ 1411, 23615,  7929, 24671, 11676, 28302])tensor([13448, 12600, 23970, 16797, 10866, 24637])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23615,  7929,  1423, 11676, 28302, 10866])tensor([12600, 23970,    62, 10866, 24637,  9075])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 7929,  1423, 24671, 28302, 10866, 24637]) \n",
            "tensor([23970,    62, 16797, 24637,  9075,    62])\n",
            "context_tensors: context_tensors:   tensor([   62, 16797, 10866,  9075,    62,    76])\n",
            "tensor([ 1423, 24671, 11676, 10866, 24637,  9075])\n",
            "context_tensors: context_tensors:  tensor([16797, 10866, 24637,    62,    76, 19838])\n",
            " tensor([24671, 11676, 28302, 24637,  9075,    62])context_tensors: \n",
            " tensor([10866, 24637,  9075,    76, 19838,    79])\n",
            "context_tensors: context_tensors:   tensor([11676, 28302, 10866,  9075,    62,  5715])tensor([24637,  9075,    62, 19838,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28302, 10866, 24637,    62,  5715,    76])\n",
            "tensor([ 1411,  3476,    62,  8113, 13448,   740])\n",
            "context_tensors: context_tensors:   tensor([10866, 24637,  9075,  5715,    76, 19838])\n",
            "tensor([ 3476,    62, 17455, 13448,   740,    76])\n",
            "context_tensors:  tensor([   62, 17455,  8113,   740,    76,  2371])context_tensors: \n",
            "context_tensors:   tensor([24637,  9075,    62,    76, 19838,    76])\n",
            "tensor([17455,  8113, 13448,    76,  2371,    76])context_tensors: \n",
            " tensor([ 9075,    62,  5715, 19838,    76,  2371])context_tensors: \n",
            " context_tensors: tensor([ 8113, 13448,   740,  2371,    76, 13448])\n",
            "context_tensors:  tensor([13448,   740,    76,    76, 13448,   742])\n",
            " tensor([   62,  5715,    76,    76,  2371, 12600])context_tensors: \n",
            " context_tensors: tensor([  740,    76,  2371, 13448,   742,    76])\n",
            " tensor([ 5715,    76, 19838,  2371, 12600, 19079])context_tensors:  \n",
            "tensor([  76, 2371,   76,  742,   76, 3476])\n",
            "context_tensors: context_tensors:  tensor([   76, 19838,    76, 12600, 19079, 18520])\n",
            " tensor([ 2371,    76, 13448,    76,  3476, 17511])context_tensors: \n",
            "context_tensors:   tensor([   76, 13448,   742,  3476, 17511, 11158])\n",
            "tensor([19838,    76,  2371, 19079, 18520, 26026])\n",
            "context_tensors: context_tensors:  tensor([13448,   742,    76, 17511, 11158,   855]) \n",
            "tensor([   76,  2371, 12600, 18520, 26026,  5667])context_tensors: \n",
            " tensor([  742,    76,  3476, 11158,   855, 26026])\n",
            "context_tensors:  tensor([ 2371, 12600, 19079, 26026,  5667,  5608])\n",
            "context_tensors: context_tensors:   tensor([12600, 19079, 18520,  5667,  5608,    76])\n",
            " context_tensors: tensor([19079, 18520, 26026,  5608,    76, 26026])\n",
            "context_tensors: tensor([   76,  3476, 17511,   855, 26026, 27881]) \n",
            "tensor([18520, 26026,  5667,    76, 26026,  7473])context_tensors: \n",
            " context_tensors: tensor([ 3476, 17511, 11158, 26026, 27881, 26285]) \n",
            "tensor([26026,  5667,  5608, 26026,  7473, 18520])context_tensors: \n",
            "\n",
            " context_tensors: tensor([17511, 11158,   855, 27881, 26285,  1176]) tensor([ 5667,  5608,    76,  7473, 18520, 26026])context_tensors: \n",
            " context_tensors:  tensor([ 5608,    76, 26026, 18520, 26026, 28452])\n",
            "context_tensors: tensor([11158,   855, 26026, 26285,  1176,  1410])\n",
            " tensor([   76, 26026,  7473, 26026, 28452, 12380])context_tensors: \n",
            " context_tensors: tensor([  855, 26026, 27881,  1176,  1410,  3205]) tensor([26026,  7473, 18520, 28452, 12380,  6164])\n",
            "\n",
            "context_tensors:  tensor([ 7473, 18520, 26026, 12380,  6164,    76])\n",
            "context_tensors:  tensor([26026, 27881, 26285,  1410,  3205, 13448])\n",
            "context_tensors:  tensor([18520, 26026, 28452,  6164,    76, 27965])\n",
            "context_tensors: context_tensors:   tensor([27881, 26285,  1176,  3205, 13448,  7203])\n",
            "tensor([26026, 28452, 12380,    76, 27965, 20919])\n",
            "context_tensors: context_tensors:   tensor([26285,  1176,  1410, 13448,  7203,    79])tensor([28452, 12380,  6164, 27965, 20919,  4787])\n",
            "context_tensors: \n",
            " tensor([1176, 1410, 3205, 7203,   79, 1409])\n",
            "context_tensors: context_tensors:   tensor([12380,  6164,    76, 20919,  4787, 21036])tensor([ 1411, 23615, 22107,  1410, 13448, 24953])\n",
            "\n",
            "context_tensors:  tensor([ 6164,    76, 27965,  4787, 21036, 16479])\n",
            "context_tensors: context_tensors:  tensor([   76, 27965, 20919, 21036, 16479,    79]) \n",
            "tensor([23615, 22107,  1423, 13448, 24953,    76])context_tensors: \n",
            " tensor([27965, 20919,  4787, 16479,    79,  1409])context_tensors:  \n",
            "context_tensors:  tensor([ 1411,  3476, 27965, 20594, 13448,  1410])tensor([22107,  1423,  1410, 24953,    76, 25464])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1423,  1410, 13448,    76, 25464,    76])\n",
            "tensor([ 3476, 27965,  9603, 13448,  1410,    76])\n",
            "context_tensors: context_tensors:  \n",
            "tensor([ 1410, 13448, 24953, 25464,    76,  9454]) context_tensors: tensor([27965,  9603, 20594,  1410,    76, 19444]) tensor([13448, 24953,    76,    76,  9454,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24953,    76, 25464,  9454,    76,  3811])tensor([ 9603, 20594, 13448,    76, 19444,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 25464,    76,    76,  3811,  4787])tensor([20594, 13448,  1410, 19444,  2371, 13742])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448,  1410,    76,  2371, 13742,    76])\n",
            " tensor([25464,    76,  9454,  3811,  4787, 12600])context_tensors: \n",
            " tensor([ 1410,    76, 19444, 13742,    76, 18561])\n",
            "context_tensors:  context_tensors: tensor([   76,  9454,    76,  4787, 12600, 11134])\n",
            " tensor([   76, 19444,  2371,    76, 18561,    76])\n",
            "context_tensors: context_tensors:   tensor([ 9454,    76,  3811, 12600, 11134,  9064])tensor([19444,  2371, 13742, 18561,    76,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  3811,  4787, 11134,  9064, 16187])\n",
            "context_tensors: tensor([ 2371, 13742,    76,    76,  2371,  1410]) tensor([ 3811,  4787, 12600,  9064, 16187,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4787, 12600, 11134, 16187,    76,  2371])tensor([13742,    76, 18561,  2371,  1410,    79])\n",
            "context_tensors: \n",
            " tensor([   76, 18561,    76,  1410,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([12600, 11134,  9064,    76,  2371, 17741]) \n",
            "tensor([ 1411, 14684, 11928, 26026, 20296,  1416])\n",
            "context_tensors: context_tensors:  tensor([11134,  9064, 16187,  2371, 17741, 14210])\n",
            " tensor([14684, 11928,  2371, 20296,  1416,  1410])\n",
            "context_tensors:  context_tensors: tensor([ 9064, 16187,    76, 17741, 14210, 24637])\n",
            " context_tensors: tensor([11928,  2371, 26026,  1416,  1410, 28115]) \n",
            "tensor([16187,    76,  2371, 14210, 24637,  2385])\n",
            "context_tensors: context_tensors:   tensor([   76,  2371, 17741, 24637,  2385,    62])\n",
            "tensor([ 2371, 26026, 20296,  1410, 28115, 26026])context_tensors: \n",
            " context_tensors:  tensor([26026, 20296,  1416, 28115, 26026, 20502])\n",
            "tensor([ 2371, 17741, 14210,  2385,    62,    79])\n",
            "context_tensors:  tensor([20296,  1416,  1410, 26026, 20502, 13667])context_tensors:  tensor([17741, 14210, 24637,    62,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1416,  1410, 28115, 20502, 13667, 18605])tensor([ 1411,  1900, 25693, 22035,    76, 12600])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1900, 25693, 27275,    76, 12600, 12475])tensor([ 1410, 28115, 26026, 13667, 18605, 12600])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([25693, 27275, 22035, 12600, 12475,  3705])tensor([28115, 26026, 20502, 18605, 12600, 28438])\n",
            "context_tensors:  tensor([27275, 22035,    76, 12475,  3705, 26285])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([22035,    76, 12600,  3705, 26285,  7985])\n",
            "context_tensors:  tensor([26026, 20502, 13667, 12600, 28438,    79]) \n",
            "tensor([   76, 12600, 12475, 26285,  7985,    79])\n",
            "context_tensors: context_tensors:   tensor([20502, 13667, 18605, 28438,    79,  1409])\n",
            "tensor([12600, 12475,  3705,  7985,    79,  1409])\n",
            "context_tensors:  tensor([ 1411, 23615,  5794, 19075, 13833,  2371])\n",
            "context_tensors: context_tensors:   tensor([23615,  5794, 26285, 13833,  2371, 21729])\n",
            "tensor([ 1411, 23615, 27965,  2371, 18854, 18520])context_tensors: \n",
            " tensor([ 5794, 26285, 19075,  2371, 21729,  2849])\n",
            "context_tensors:  context_tensors: tensor([23615, 27965, 13448, 18854, 18520, 18363])\n",
            " tensor([26285, 19075, 13833, 21729,  2849, 26061])\n",
            "context_tensors:  context_tensors: tensor([19075, 13833,  2371,  2849, 26061,    79])\n",
            " tensor([27965, 13448,  2371, 18520, 18363,  2371])context_tensors: \n",
            " tensor([13833,  2371, 21729, 26061,    79,  1409])context_tensors: \n",
            "context_tensors:  tensor([1411, 3476, 8113,  756,   79, 1409])\n",
            " context_tensors: tensor([13448,  2371, 18854, 18363,  2371,  1410])\n",
            " context_tensors: tensor([ 1411, 26134, 23615, 10776, 10182,  4246])\n",
            " tensor([ 2371, 18854, 18520,  2371,  1410, 12869])\n",
            "context_tensors: context_tensors:   tensor([18854, 18520, 18363,  1410, 12869,    76])\n",
            "context_tensors: tensor([26134, 23615, 20849, 10182,  4246, 28356]) tensor([18520, 18363,  2371, 12869,    76,  2371])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([18363,  2371,  1410,    76,  2371, 25904])tensor([23615, 20849, 10776,  4246, 28356, 24589])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([20849, 10776, 10182, 28356, 24589,    76])\n",
            "tensor([ 2371,  1410, 12869,  2371, 25904,  4787])context_tensors: \n",
            " tensor([10776, 10182,  4246, 24589,    76, 25294])context_tensors: \n",
            " tensor([ 1410, 12869,    76, 25904,  4787, 21751])\n",
            "context_tensors:  tensor([10182,  4246, 28356,    76, 25294,    76])context_tensors: \n",
            " tensor([12869,    76,  2371,  4787, 21751,  2371])\n",
            "context_tensors: context_tensors:  tensor([   76,  2371, 25904, 21751,  2371, 11138]) tensor([ 4246, 28356, 24589, 25294,    76,  2371])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([28356, 24589,    76,    76,  2371,  3190])tensor([ 2371, 25904,  4787,  2371, 11138,    79])\n",
            "\n",
            "context_tensors:  tensor([24589,    76, 25294,  2371,  3190, 26047])context_tensors:  tensor([25904,  4787, 21751, 11138,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  3476,  8113, 28474, 12961, 18605])\n",
            "context_tensors: tensor([   76, 25294,    76,  3190, 26047,    76])\n",
            "context_tensors:  tensor([ 3476,  8113,  3017, 12961, 18605,   373]) \n",
            "tensor([25294,    76,  2371, 26047,    76, 14210])\n",
            "context_tensors:  context_tensors:  tensor([   76,  2371,  3190,    76, 14210, 27969])\n",
            "tensor([ 8113,  3017, 28474, 18605,   373, 10354])\n",
            "context_tensors: context_tensors:   tensor([ 2371,  3190, 26047, 14210, 27969,    64])\n",
            "tensor([ 3017, 28474, 12961,   373, 10354,   756])context_tensors:  tensor([ 3190, 26047,    76, 27969,    64, 27255])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28474, 12961, 18605, 10354,   756,    76])\n",
            " context_tensors: tensor([12961, 18605,   373,   756,    76,  1919])tensor([26047,    76, 14210,    64, 27255,   770]) \n",
            "\n",
            "context_tensors: context_tensors:   tensor([18605,   373, 10354,    76,  1919,  1286])\n",
            "tensor([   76, 14210, 27969, 27255,   770, 26023])context_tensors:  tensor([  373, 10354,   756,  1919,  1286, 28614])\n",
            "\n",
            "context_tensors:  tensor([10354,   756,    76,  1286, 28614,    79])\n",
            "context_tensors:  tensor([14210, 27969,    64,   770, 26023,  1423])context_tensors:  \n",
            "tensor([  756,    76,  1919, 28614,    79,  1409])\n",
            "context_tensors:  tensor([27969,    64, 27255, 26023,  1423, 28326])context_tensors: \n",
            " context_tensors:  tensor([   64, 27255,   770,  1423, 28326,  6079])tensor([ 1411, 26910, 11236, 28115, 12540, 28846])\n",
            "\n",
            "context_tensors:  tensor([27255,   770, 26023, 28326,  6079, 27965])\n",
            "context_tensors: context_tensors:   tensor([26910, 11236, 23475, 12540, 28846, 18609])tensor([  770, 26023,  1423,  6079, 27965,  2927])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([11236, 23475, 28115, 28846, 18609, 13448])\n",
            " context_tensors:  tensor([23475, 28115, 12540, 18609, 13448, 24953])\n",
            "tensor([26023,  1423, 28326, 27965,  2927, 11158])context_tensors:  tensor([28115, 12540, 28846, 13448, 24953,  5715])\n",
            "context_tensors: \n",
            " context_tensors: tensor([12540, 28846, 18609, 24953,  5715,  2371]) \n",
            "context_tensors: \n",
            "tensor([ 1423, 28326,  6079,  2927, 11158, 12600]) context_tensors: tensor([28846, 18609, 13448,  5715,  2371, 18609]) tensor([28326,  6079, 27965, 11158, 12600, 21810])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 6079, 27965,  2927, 12600, 21810, 28438]) tensor([18609, 13448, 24953,  2371, 18609, 13448])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 24953,  5715, 18609, 13448,  3476])\n",
            "context_tensors: tensor([27965,  2927, 11158, 21810, 28438,  2371]) \n",
            "tensor([24953,  5715,  2371, 13448,  3476,    62])\n",
            "context_tensors:  context_tensors:  tensor([ 2927, 11158, 12600, 28438,  2371, 20849])tensor([ 5715,  2371, 18609,  3476,    62,  1410])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 18609, 13448,    62,  1410,    79]) \n",
            "tensor([11158, 12600, 21810,  2371, 20849, 20205])context_tensors: \n",
            " tensor([18609, 13448,  3476,  1410,    79,  1409])context_tensors: \n",
            " tensor([ 1411, 12600,  2881, 23056, 13448, 24953])\n",
            "context_tensors: context_tensors:   tensor([12600, 21810, 28438, 20849, 20205,    79])tensor([12600,  2881, 28115, 13448, 24953,  5720])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([21810, 28438,  2371, 20205,    79,  1409])tensor([ 2881, 28115, 23056, 24953,  5720,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28115, 23056, 13448,  5720,    79,  1409])tensor([ 1411,  3476, 27965, 26026, 23265,  7499])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 13448,   774, 11070, 27942,    76])tensor([ 3476, 27965,  4284, 23265,  7499,  2371])\n",
            "context_tensors: \n",
            " context_tensors: tensor([13448,   774,    76, 27942,    76,  1423]) tensor([27965,  4284, 26026,  7499,  2371, 28663])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4284, 26026, 23265,  2371, 28663,  5608])tensor([  774,    76, 11070,    76,  1423,  8481])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026, 23265,  7499, 28663,  5608, 18520])tensor([   76, 11070, 27942,  1423,  8481, 18520])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([23265,  7499,  2371,  5608, 18520, 27903])\n",
            "tensor([11070, 27942,    76,  8481, 18520, 19464])context_tensors:  tensor([ 7499,  2371, 28663, 18520, 27903,  3476])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([27942,    76,  1423, 18520, 19464,  4246])tensor([ 2371, 28663,  5608, 27903,  3476,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28663,  5608, 18520,  3476,    76,  1423])\n",
            "tensor([   76,  1423,  8481, 19464,  4246, 23934])\n",
            "context_tensors:  context_tensors: tensor([ 5608, 18520, 27903,    76,  1423, 19266]) \n",
            "tensor([ 1423,  8481, 18520,  4246, 23934,   768])context_tensors: \n",
            " context_tensors: tensor([18520, 27903,  3476,  1423, 19266, 13448]) \n",
            "tensor([ 8481, 18520, 19464, 23934,   768,    76])context_tensors: \n",
            " context_tensors: tensor([27903,  3476,    76, 19266, 13448,  1423]) \n",
            "tensor([18520, 19464,  4246,   768,    76,  1647])context_tensors: \n",
            " context_tensors: tensor([ 3476,    76,  1423, 13448,  1423, 23304]) \n",
            "tensor([19464,  4246, 23934,    76,  1647, 26026])context_tensors: \n",
            " context_tensors: tensor([   76,  1423, 19266,  1423, 23304, 25374]) \n",
            "context_tensors: tensor([ 4246, 23934,   768,  1647, 26026, 10776])\n",
            " tensor([ 1423, 19266, 13448, 23304, 25374,  6268])context_tensors: \n",
            " context_tensors: tensor([23934,   768,    76, 26026, 10776, 10179]) \n",
            "tensor([19266, 13448,  1423, 25374,  6268,  2371])\n",
            "context_tensors: context_tensors:   tensor([13448,  1423, 23304,  6268,  2371,  2334])\n",
            "tensor([  768,    76,  1647, 10776, 10179, 20687])context_tensors:  tensor([ 1423, 23304, 25374,  2371,  2334,  2243])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([23304, 25374,  6268,  2334,  2243,  2848]) \n",
            "tensor([   76,  1647, 26026, 10179, 20687,    79])\n",
            "context_tensors: context_tensors:  tensor([25374,  6268,  2371,  2243,  2848,    76]) \n",
            "context_tensors:  tensor([6268, 2371, 2334, 2848,   76, 2371])\n",
            "context_tensors: tensor([ 1647, 26026, 10776, 20687,    79,  1409]) \n",
            "tensor([ 2371,  2334,  2243,    76,  2371, 12762])context_tensors:  tensor([ 1411,  3476, 28439, 13448,  1410, 28356])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3476, 28439, 20504,  1410, 28356, 19444]) tensor([ 2334,  2243,  2848,  2371, 12762, 28243])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([28439, 20504, 13448, 28356, 19444,  1416])\n",
            "tensor([ 2243,  2848,    76, 12762, 28243, 16479])context_tensors:  tensor([20504, 13448,  1410, 19444,  1416,  2371])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2848,    76,  2371, 28243, 16479,  9155]) \n",
            "tensor([13448,  1410, 28356,  1416,  2371,  1416])context_tensors: \n",
            " context_tensors: tensor([   76,  2371, 12762, 16479,  9155,    72]) tensor([ 1410, 28356, 19444,  2371,  1416, 13742])\n",
            "context_tensors:  tensor([28356, 19444,  1416,  1416, 13742,    76])\n",
            "\n",
            "context_tensors:  tensor([ 2371, 12762, 28243,  9155,    72, 18828])\n",
            "context_tensors:  tensor([12762, 28243, 16479,    72, 18828,    73])\n",
            "context_tensors:  context_tensors:  tensor([28243, 16479,  9155, 18828,    73,  3476])tensor([19444,  1416,  2371, 13742,    76,  4767])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 1416,  2371,  1416,    76,  4767, 23615]) \n",
            "tensor([16479,  9155,    72,    73,  3476, 18605])context_tensors: \n",
            " context_tensors: tensor([ 2371,  1416, 13742,  4767, 23615, 27965]) tensor([ 9155,    72, 18828,  3476, 18605,   919])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1416, 13742,    76, 23615, 27965,  9603])tensor([   72, 18828,    73, 18605,   919, 14553])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([13742,    76,  4767, 27965,  9603,  6294])\n",
            "tensor([18828,    73,  3476,   919, 14553,   658])context_tensors: \n",
            " context_tensors: tensor([   76,  4767, 23615,  9603,  6294, 13448]) \n",
            "tensor([   73,  3476, 18605, 14553,   658,  3017])context_tensors: \n",
            " context_tensors:  tensor([ 4767, 23615, 27965,  6294, 13448,  4027])tensor([ 3476, 18605,   919,   658,  3017, 12862])\n",
            "context_tensors: \n",
            " context_tensors: tensor([23615, 27965,  9603, 13448,  4027,  1416])\n",
            "context_tensors:  tensor([18605,   919, 14553,  3017, 12862,  3017])\n",
            "context_tensors:   tensor([27965,  9603,  6294,  4027,  1416,  2371])tensor([  919, 14553,   658, 12862,  3017,  1211])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 9603,  6294, 13448,  1416,  2371,  1416])\n",
            "tensor([14553,   658,  3017,  3017,  1211, 27849])context_tensors:  \n",
            "tensor([ 6294, 13448,  4027,  2371,  1416, 28190])\n",
            "context_tensors: context_tensors:   tensor([  658,  3017, 12862,  1211, 27849, 22420])\n",
            "tensor([13448,  4027,  1416,  1416, 28190,    76])context_tensors: \n",
            " tensor([ 3017, 12862,  3017, 27849, 22420, 13448])context_tensors:  \n",
            "context_tensors: tensor([ 4027,  1416,  2371, 28190,    76, 13448]) tensor([12862,  3017,  1211, 22420, 13448,  7203])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3017,  1211, 27849, 13448,  7203,    76])\n",
            " tensor([ 1416,  2371,  1416,    76, 13448, 18561])\n",
            "context_tensors:  context_tensors:  tensor([ 1211, 27849, 22420,  7203,    76, 25425])\n",
            "tensor([ 2371,  1416, 28190, 13448, 18561,    76])\n",
            "context_tensors: context_tensors:   tensor([27849, 22420, 13448,    76, 25425,    76])\n",
            "tensor([ 1416, 28190,    76, 18561,    76,  2371])context_tensors: \n",
            " context_tensors:  tensor([22420, 13448,  7203, 25425,    76,  9454])\n",
            "tensor([28190,    76, 13448,    76,  2371, 13448])context_tensors: \n",
            " tensor([13448,  7203,    76,    76,  9454,    79])context_tensors:  \n",
            "tensor([   76, 13448, 18561,  2371, 13448,  1410])\n",
            "context_tensors:  context_tensors:  tensor([ 7203,    76, 25425,  9454,    79,  1409])tensor([13448, 18561,    76, 13448,  1410,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18561,    76,  2371,  1410,    79,  1409])\n",
            "tensor([ 1411,  3476, 27965,  1410,  2858,  1423])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 23615,  5133,  1410, 28356, 12600]) \n",
            "tensor([ 3476, 27965,  2334,  2858,  1423,  5608])context_tensors: \n",
            " context_tensors: tensor([23615,  5133,  1423, 28356, 12600, 10866]) \n",
            "tensor([27965,  2334,  1410,  1423,  5608,    76])context_tensors: \n",
            " context_tensors:  tensor([ 5133,  1423,  1410, 12600, 10866,  5048])tensor([2334, 1410, 2858, 5608,   76, 2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([1410, 2858, 1423,   76, 2371, 5074])tensor([ 1423,  1410, 28356, 10866,  5048, 13933])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410, 28356, 12600,  5048, 13933,  5614])tensor([ 2858,  1423,  5608,  2371,  5074, 10866])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28356, 12600, 10866, 13933,  5614,    79]) \n",
            "tensor([ 1423,  5608,    76,  5074, 10866,  3017])context_tensors: \n",
            " context_tensors: tensor([12600, 10866,  5048,  5614,    79,  1409]) \n",
            "tensor([ 5608,    76,  2371, 10866,  3017, 12862])context_tensors: \n",
            " context_tensors: tensor([ 1411, 23615, 18606,    76,     1, 13179]) tensor([   76,  2371,  5074,  3017, 12862,  4787])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371,  5074, 10866, 12862,  4787, 12600])\n",
            "tensor([23615, 18606, 13559,     1, 13179, 12418])\n",
            "context_tensors:  context_tensors: tensor([ 5074, 10866,  3017,  4787, 12600, 19210]) \n",
            "tensor([18606, 13559,    76, 13179, 12418,  2230])context_tensors: \n",
            " context_tensors: tensor([10866,  3017, 12862, 12600, 19210,    79]) tensor([13559,    76,     1, 12418,  2230, 26690])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,     1, 13179,  2230, 26690, 26285])tensor([ 3017, 12862,  4787, 19210,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 15261,    76, 23970,  2371,  9151])tensor([    1, 13179, 12418, 26690, 26285, 19075])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15261,    76, 12600,  2371,  9151,  4787])tensor([13179, 12418,  2230, 26285, 19075, 13833])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 12600, 23970,  9151,  4787, 26910]) \n",
            "tensor([12418,  2230, 26690, 19075, 13833, 13448])\n",
            "context_tensors: context_tensors:   tensor([12600, 23970,  2371,  4787, 26910, 28614])tensor([ 2230, 26690, 26285, 13833, 13448,  1423])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23970,  2371,  9151, 26910, 28614,    76])tensor([26690, 26285, 19075, 13448,  1423, 28015])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371,  9151,  4787, 28614,    76,  8627])tensor([26285, 19075, 13833,  1423, 28015, 26023])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19075, 13833, 13448, 28015, 26023,  6170])tensor([ 9151,  4787, 26910,    76,  8627, 18828])\n",
            "\n",
            "context_tensors:  tensor([13833, 13448,  1423, 26023,  6170, 17826])\n",
            "context_tensors: context_tensors:  tensor([ 4787, 26910, 28614,  8627, 18828,  3476])\n",
            " context_tensors: tensor([13448,  1423, 28015,  6170, 17826, 26285]) tensor([26910, 28614,    76, 18828,  3476,    76])\n",
            "\n",
            "context_tensors:  tensor([28614,    76,  8627,  3476,    76,  6699])context_tensors: \n",
            " tensor([ 1423, 28015, 26023, 17826, 26285, 16681])context_tensors: \n",
            " tensor([   76,  8627, 18828,    76,  6699, 26026])context_tensors: \n",
            " tensor([28015, 26023,  6170, 26285, 16681,    76])\n",
            "context_tensors:  tensor([ 8627, 18828,  3476,  6699, 26026,  5073])context_tensors:  tensor([26023,  6170, 17826, 16681,    76, 28368])\n",
            "context_tensors: \n",
            " tensor([18828,  3476,    76, 26026,  5073,    79])context_tensors: \n",
            " context_tensors:  tensor([ 6170, 17826, 26285,    76, 28368,  2553])tensor([3476,   76, 6699, 5073,   79, 1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([17826, 26285, 16681, 28368,  2553, 21370])\n",
            " tensor([ 1411, 26026, 10217, 10996, 27965, 17224])\n",
            "context_tensors:  tensor([26285, 16681,    76,  2553, 21370, 26135])\n",
            "context_tensors:  tensor([26026, 10217, 18520, 27965, 17224, 28102])context_tensors: \n",
            " tensor([16681,    76, 28368, 21370, 26135, 18691])context_tensors:  tensor([10217, 18520, 10996, 17224, 28102, 18521])\n",
            "\n",
            "context_tensors:  tensor([   76, 28368,  2553, 26135, 18691,  3081])context_tensors:  \n",
            "tensor([18520, 10996, 27965, 28102, 18521,    76])\n",
            "context_tensors: context_tensors:  tensor([28368,  2553, 21370, 18691,  3081, 26285])\n",
            " context_tensors: tensor([10996, 27965, 17224, 18521,    76,  2371]) \n",
            "tensor([ 2553, 21370, 26135,  3081, 26285,  2849])context_tensors: \n",
            " tensor([27965, 17224, 28102,    76,  2371,  3761])context_tensors:  tensor([21370, 26135, 18691, 26285,  2849, 26061])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26135, 18691,  3081,  2849, 26061,    79]) tensor([17224, 28102, 18521,  2371,  3761, 26285])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18691,  3081, 26285, 26061,    79,     1])\n",
            " context_tensors: tensor([28102, 18521,    76,  3761, 26285, 26026])\n",
            " tensor([ 3081, 26285,  2849,    79,     1,  1409])context_tensors:  tensor([18521,    76,  2371, 26285, 26026, 15925])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 14684, 11928,  1423,  5612, 10313]) tensor([   76,  2371,  3761, 26026, 15925,  9405])\n",
            "\n",
            "context_tensors:  tensor([14684, 11928, 27965,  5612, 10313,  2371])\n",
            "context_tensors:  tensor([11928, 27965,  1423, 10313,  2371,  2334])\n",
            "context_tensors: context_tensors:   tensor([ 2371,  3761, 26285, 15925,  9405, 18520])\n",
            "tensor([27965,  1423,  5612,  2371,  2334, 13665])\n",
            "context_tensors: context_tensors:   tensor([ 1423,  5612, 10313,  2334, 13665, 18605])tensor([ 3761, 26285, 26026,  9405, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285, 26026, 15925, 18520, 26026, 27297])tensor([ 5612, 10313,  2371, 13665, 18605, 12600])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([10313,  2371,  2334, 18605, 12600,  2833])\n",
            "context_tensors:   tensor([26026, 15925,  9405, 26026, 27297, 16968])tensor([ 2371,  2334, 13665, 12600,  2833,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([15925,  9405, 18520, 27297, 16968,  5822]) tensor([ 2334, 13665, 18605,  2833,    79,  1409])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([ 9405, 18520, 26026, 16968,  5822,    79])\n",
            "tensor([ 1411,  3476,    62, 25154, 28042, 18250])\n",
            "context_tensors: context_tensors:   tensor([18520, 26026, 27297,  5822,    79,  1409])tensor([ 3476,    62,  5608, 28042, 18250,  5931])\n",
            "\n",
            "context_tensors:  tensor([   62,  5608, 25154, 18250,  5931,  2858])\n",
            "context_tensors:  context_tensors: tensor([ 1411,  1423,  1410,  1423, 11804,    76]) \n",
            "tensor([ 5608, 25154, 28042,  5931,  2858, 11928])\n",
            "context_tensors:  tensor([ 1423,  1410,    76, 11804,    76,  2371])context_tensors: \n",
            " context_tensors: tensor([25154, 28042, 18250,  2858, 11928,    62]) \n",
            "tensor([1410,   76, 1423,   76, 2371, 1423])context_tensors: \n",
            " context_tensors: tensor([28042, 18250,  5931, 11928,    62,  5614]) \n",
            "context_tensors: tensor([   76,  1423, 11804,  2371,  1423,  6788]) \n",
            "tensor([18250,  5931,  2858,    62,  5614,  8505])context_tensors: \n",
            " context_tensors: tensor([ 1423, 11804,    76,  1423,  6788, 26285]) \n",
            "tensor([ 5931,  2858, 11928,  5614,  8505,    76])context_tensors: \n",
            " context_tensors: tensor([11804,    76,  2371,  6788, 26285, 20396]) \n",
            "tensor([ 2858, 11928,    62,  8505,    76, 26134])context_tensors: \n",
            " context_tensors: tensor([   76,  2371,  1423, 26285, 20396, 24409]) \n",
            "tensor([11928,    62,  5614,    76, 26134,  3476])context_tensors: \n",
            " context_tensors: tensor([ 2371,  1423,  6788, 20396, 24409, 16686]) \n",
            "tensor([   62,  5614,  8505, 26134,  3476,    62])\n",
            "context_tensors: context_tensors:   tensor([ 1423,  6788, 26285, 24409, 16686, 10866])tensor([5614, 8505,   76, 3476,   62, 5614])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6788, 26285, 20396, 16686, 10866,  3476])tensor([ 8505,    76, 26134,    62,  5614,  2733])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 26134,  3476,  5614,  2733, 15481])tensor([26285, 20396, 24409, 10866,  3476, 28115])\n",
            "context_tensors:  tensor([26134,  3476,    62,  2733, 15481, 16765])\n",
            "\n",
            "context_tensors:  tensor([ 3476,    62,  5614, 15481, 16765,  2371])context_tensors: \n",
            " context_tensors: tensor([20396, 24409, 16686,  3476, 28115, 12756])\n",
            " tensor([   62,  5614,  2733, 16765,  2371, 15481])\n",
            "context_tensors: context_tensors:  tensor([24409, 16686, 10866, 28115, 12756,    79])\n",
            " tensor([ 5614,  2733, 15481,  2371, 15481, 10688])context_tensors: \n",
            " tensor([16686, 10866,  3476, 12756,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 23615, 24468, 26232, 13448,  3675]) \n",
            "tensor([ 2733, 15481, 16765, 15481, 10688, 13448])context_tensors: \n",
            " context_tensors: tensor([23615, 24468, 17546, 13448,  3675,  3017]) tensor([15481, 16765,  2371, 10688, 13448,  2604])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24468, 17546, 26232,  3675,  3017, 12862])\n",
            "tensor([16765,  2371, 15481, 13448,  2604,    76])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 15481, 10688,  2604,    76,  8830])tensor([17546, 26232, 13448,  3017, 12862,  2329])\n",
            "context_tensors: \n",
            " context_tensors: tensor([15481, 10688, 13448,    76,  8830, 19522])\n",
            " tensor([26232, 13448,  3675, 12862,  2329, 12648])context_tensors: \n",
            " tensor([10688, 13448,  2604,  8830, 19522, 26285])\n",
            "context_tensors: context_tensors:  tensor([13448,  2604,    76, 19522, 26285,  1800]) \n",
            "tensor([13448,  3675,  3017,  2329, 12648, 28356])context_tensors: \n",
            " context_tensors: tensor([ 2604,    76,  8830, 26285,  1800, 13448]) \n",
            "tensor([ 3675,  3017, 12862, 12648, 28356, 19079])\n",
            "context_tensors:  context_tensors: tensor([   76,  8830, 19522,  1800, 13448, 20513]) tensor([ 3017, 12862,  2329, 28356, 19079,  4246])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([12862,  2329, 12648, 19079,  4246,  2371])\n",
            " context_tensors: tensor([ 8830, 19522, 26285, 13448, 20513, 25840]) tensor([ 2329, 12648, 28356,  4246,  2371,  1423])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([19522, 26285,  1800, 20513, 25840,    79])\n",
            " context_tensors:  tensor([26285,  1800, 13448, 25840,    79,  1409])tensor([12648, 28356, 19079,  2371,  1423, 18361])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  3476, 25096, 28356,  2334,  2349])\n",
            "tensor([28356, 19079,  4246,  1423, 18361, 15548])\n",
            "context_tensors: context_tensors:   tensor([ 3476, 25096, 10778,  2334,  2349, 10106])\n",
            "tensor([19079,  4246,  2371, 18361, 15548, 26023])\n",
            "context_tensors: context_tensors:  tensor([25096, 10778, 28356,  2349, 10106,  2371])\n",
            " tensor([ 4246,  2371,  1423, 15548, 26023, 13495])context_tensors:  tensor([10778, 28356,  2334, 10106,  2371, 27965])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2371,  1423, 18361, 26023, 13495, 26026])\n",
            "tensor([28356,  2334,  2349,  2371, 27965, 11134])\n",
            "context_tensors:  tensor([ 1423, 18361, 15548, 13495, 26026, 28449])\n",
            "context_tensors:  context_tensors: tensor([ 2334,  2349, 10106, 27965, 11134, 26285]) \n",
            "tensor([18361, 15548, 26023, 26026, 28449, 18520])context_tensors:  \n",
            "tensor([ 2349, 10106,  2371, 11134, 26285,  5614])\n",
            "context_tensors: context_tensors:   tensor([15548, 26023, 13495, 28449, 18520, 14684])tensor([10106,  2371, 27965, 26285,  5614,    62])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26023, 13495, 26026, 18520, 14684, 11928])\n",
            "tensor([ 2371, 27965, 11134,  5614,    62, 13312])\n",
            "context_tensors:  tensor([13495, 26026, 28449, 14684, 11928,  2371])\n",
            "context_tensors:  tensor([27965, 11134, 26285,    62, 13312,    76])\n",
            "context_tensors:  context_tensors: tensor([26026, 28449, 18520, 11928,  2371, 21229])\n",
            " tensor([11134, 26285,  5614, 13312,    76, 16380])context_tensors: \n",
            "context_tensors:   tensor([26285,  5614,    62,    76, 16380,  1410])tensor([28449, 18520, 14684,  2371, 21229,  4872])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5614,    62, 13312, 16380,  1410,    79])\n",
            "context_tensors:  tensor([18520, 14684, 11928, 21229,  4872, 28846])tensor([   62, 13312,    76,  1410,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14684, 11928,  2371,  4872, 28846, 26910])tensor([ 1411,  2185, 28356,    76, 13312,  2110])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2185, 28356, 11928, 13312,  2110,  3273])tensor([11928,  2371, 21229, 28846, 26910,  2851])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([28356, 11928,    76,  2110,  3273, 28422])\n",
            "tensor([ 2371, 21229,  4872, 26910,  2851, 28200])\n",
            "context_tensors: context_tensors:   tensor([21229,  4872, 28846,  2851, 28200,  9934])\n",
            "tensor([11928,    76, 13312,  3273, 28422,  2197])context_tensors: \n",
            " tensor([ 4872, 28846, 26910, 28200,  9934, 25061])context_tensors: \n",
            " context_tensors: tensor([   76, 13312,  2110, 28422,  2197, 13666])\n",
            " context_tensors: tensor([28846, 26910,  2851,  9934, 25061, 13667]) tensor([13312,  2110,  3273,  2197, 13666,  3476])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2110,  3273, 28422, 13666,  3476,    62])\n",
            " tensor([26910,  2851, 28200, 25061, 13667, 18605])\n",
            "context_tensors: context_tensors:   tensor([ 3273, 28422,  2197,  3476,    62, 28438])tensor([ 2851, 28200,  9934, 13667, 18605, 12600])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28422,  2197, 13666,    62, 28438,    79]) \n",
            "tensor([28200,  9934, 25061, 18605, 12600, 15261])\n",
            "context_tensors: context_tensors:   tensor([ 9934, 25061, 13667, 12600, 15261,  2833])tensor([ 2197, 13666,  3476, 28438,    79,  1409])\n",
            "\n",
            "context_tensors:  tensor([25061, 13667, 18605, 15261,  2833,    79])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026, 20296,  1410, 28115,  1423])\n",
            " tensor([13667, 18605, 12600,  2833,    79,  1409])context_tensors: \n",
            "context_tensors:   tensor([26026, 20296,  1416, 28115,  1423, 25061])tensor([ 1411,  3476, 26353,  6992, 13448,  2833])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3476, 26353,  6888, 13448,  2833,    76])tensor([20296,  1416,  1410,  1423, 25061,    76])\n",
            "context_tensors: \n",
            " context_tensors: tensor([26353,  6888,  6992,  2833,    76, 20540]) \n",
            "tensor([ 1416,  1410, 28115, 25061,    76, 15571])\n",
            "context_tensors: context_tensors:   tensor([ 1410, 28115,  1423,    76, 15571, 13665])tensor([ 6888,  6992, 13448,    76, 20540, 27255])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28115,  1423, 25061, 15571, 13665, 18605])tensor([ 6992, 13448,  2833, 20540, 27255,  1497])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([ 1423, 25061,    76, 13665, 18605,  3476]) tensor([13448,  2833,    76, 27255,  1497,   687])\n",
            "\n",
            "context_tensors:  tensor([25061,    76, 15571, 18605,  3476,    79])context_tensors:  \n",
            "tensor([ 2833,    76, 20540,  1497,   687,    79])context_tensors: \n",
            " context_tensors: tensor([   76, 15571, 13665,  3476,    79,  1409]) tensor([   76, 20540, 27255,   687,    79,  1409])\n",
            "\n",
            "context_tensors:  tensor([ 1411, 13448,   675,   280, 28614,    76])context_tensors:  tensor([ 1411, 23615, 18606,    76,     1, 13179])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([13448,   675,  3017, 28614,    76, 23615])\n",
            "tensor([23615, 18606, 13559,     1, 13179,  2232])\n",
            "context_tensors:  context_tensors:  tensor([  675,  3017,   280,    76, 23615,  9517])\n",
            "tensor([18606, 13559,    76, 13179,  2232, 26285])\n",
            "context_tensors: context_tensors:  tensor([ 3017,   280, 28614, 23615,  9517,  2334])\n",
            " context_tensors:  tensor([13559,    76,     1,  2232, 26285, 24258])\n",
            "tensor([  280, 28614,    76,  9517,  2334,  9802])\n",
            "context_tensors:  context_tensors: tensor([   76,     1, 13179, 26285, 24258, 10080]) \n",
            "tensor([28614,    76, 23615,  2334,  9802,  5822])context_tensors: \n",
            " context_tensors: tensor([    1, 13179,  2232, 24258, 10080, 13666]) \n",
            "tensor([   76, 23615,  9517,  9802,  5822,  3017])context_tensors: \n",
            " context_tensors: tensor([13179,  2232, 26285, 10080, 13666,  4787]) \n",
            "tensor([23615,  9517,  2334,  5822,  3017, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 2232, 26285, 24258, 13666,  4787, 26042])tensor([ 9517,  2334,  9802,  3017, 26026,  7203])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2334,  9802,  5822, 26026,  7203, 23094]) \n",
            "tensor([26285, 24258, 10080,  4787, 26042, 28847])context_tensors: \n",
            " context_tensors:  tensor([ 9802,  5822,  3017,  7203, 23094, 18520])tensor([24258, 10080, 13666, 26042, 28847, 18253])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10080, 13666,  4787, 28847, 18253, 13448])tensor([ 5822,  3017, 26026, 23094, 18520,  2833])\n",
            "\n",
            "context_tensors:  tensor([ 3017, 26026,  7203, 18520,  2833,    76])\n",
            "context_tensors: context_tensors:   tensor([13666,  4787, 26042, 18253, 13448,  2553])tensor([26026,  7203, 23094,  2833,    76,  2371])\n",
            "\n",
            "context_tensors:  tensor([ 7203, 23094, 18520,    76,  2371,  3077])context_tensors: \n",
            " tensor([ 4787, 26042, 28847, 13448,  2553, 25832])context_tensors: \n",
            " tensor([23094, 18520,  2833,  2371,  3077, 26026])context_tensors: \n",
            " tensor([26042, 28847, 18253,  2553, 25832, 23394])context_tensors:  tensor([18520,  2833,    76,  3077, 26026, 23094])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2833,    76,  2371, 26026, 23094, 14014]) \n",
            "context_tensors: tensor([28847, 18253, 13448, 25832, 23394,    76]) \n",
            "context_tensors: tensor([   76,  2371,  3077, 23094, 14014, 26026]) tensor([18253, 13448,  2553, 23394,    76,  4767])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371,  3077, 26026, 14014, 26026,   714])tensor([13448,  2553, 25832,    76,  4767, 13448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3077, 26026, 23094, 26026,   714,    79]) tensor([ 2553, 25832, 23394,  4767, 13448, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([25832, 23394,    76, 13448, 26026,  5638]) \n",
            "tensor([26026, 23094, 14014,   714,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([23394,    76,  4767, 26026,  5638, 18520])tensor([ 1411, 13448, 26232, 23615, 21439,  1423])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76,  4767, 13448,  5638, 18520, 25152]) \n",
            "tensor([13448, 26232,    76, 21439,  1423, 25817])\n",
            "context_tensors: context_tensors:   tensor([26232,    76, 23615,  1423, 25817, 20176])tensor([ 4767, 13448, 26026, 18520, 25152, 16570])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 23615, 21439, 25817, 20176,    79])\n",
            "tensor([13448, 26026,  5638, 25152, 16570,  2371])\n",
            "context_tensors:  tensor([23615, 21439,  1423, 20176,    79,  1409])\n",
            "context_tensors:  tensor([ 1411, 13448,   679, 21261, 26804,     5])\n",
            "context_tensors: context_tensors:  tensor([13448,   679,    76, 26804,     5, 24285])\n",
            " tensor([26026,  5638, 18520, 16570,  2371, 26026])\n",
            "context_tensors:  context_tensors:  tensor([  679,    76, 21261,     5, 24285,  4313])tensor([ 5638, 18520, 25152,  2371, 26026, 10368])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18520, 25152, 16570, 26026, 10368,  2371]) tensor([   76, 21261, 26804, 24285,  4313, 10996])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([21261, 26804,     5,  4313, 10996, 18520])\n",
            "tensor([25152, 16570,  2371, 10368,  2371,  3042])\n",
            "context_tensors:  context_tensors: tensor([26804,     5, 24285, 10996, 18520,  3476]) \n",
            "tensor([16570,  2371, 26026,  2371,  3042, 26083])\n",
            "context_tensors:  tensor([    5, 24285,  4313, 18520,  3476,    62])\n",
            "context_tensors:  tensor([ 2371, 26026, 10368,  3042, 26083,  6942])context_tensors:  \n",
            "context_tensors: tensor([24285,  4313, 10996,  3476,    62,     1]) \n",
            "context_tensors: tensor([26026, 10368,  2371, 26083,  6942,  1622])\n",
            " tensor([ 4313, 10996, 18520,    62,     1, 15729])\n",
            "context_tensors:  tensor([10368,  2371,  3042,  6942,  1622,    79])\n",
            "context_tensors:  context_tensors: tensor([10996, 18520,  3476,     1, 15729,  8719]) tensor([ 2371,  3042, 26083,  1622,    79,     1])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3042, 26083,  6942,    79,     1,  1409])\n",
            "context_tensors:   tensor([18520,  3476,    62, 15729,  8719,     1])tensor([ 1411, 23615,  1767, 10844, 10866, 26026])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 3476,    62,     1,  8719,     1, 10866])tensor([23615,  1767,  1423, 10866, 26026,  8958])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1767,  1423, 10844, 26026,  8958, 19080])tensor([   62,     1, 15729,     1, 10866, 12192])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1423, 10844, 10866,  8958, 19080, 18520]) \n",
            "tensor([    1, 15729,  8719, 10866, 12192,  1423])\n",
            "context_tensors: context_tensors:   tensor([15729,  8719,     1, 12192,  1423, 24354])tensor([10844, 10866, 26026, 19080, 18520, 14442])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 8719,     1, 10866,  1423, 24354,    76]) \n",
            "tensor([10866, 26026,  8958, 18520, 14442,  9811])context_tensors: \n",
            " context_tensors: tensor([    1, 10866, 12192, 24354,    76,  2371]) \n",
            "tensor([26026,  8958, 19080, 14442,  9811, 17033])context_tensors: \n",
            " tensor([10866, 12192,  1423,    76,  2371, 20849])\n",
            "context_tensors:  tensor([ 8958, 19080, 18520,  9811, 17033,  2371])context_tensors: \n",
            " context_tensors: tensor([12192,  1423, 24354,  2371, 20849, 26042]) tensor([19080, 18520, 14442, 17033,  2371,     1])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([ 1423, 24354,    76, 20849, 26042,  2858])tensor([18520, 14442,  9811,  2371,     1, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14442,  9811, 17033,     1, 26026, 28403])tensor([24354,    76,  2371, 26042,  2858, 20199])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76,  2371, 20849,  2858, 20199,    79])\n",
            " tensor([ 9811, 17033,  2371, 26026, 28403, 26099])\n",
            "context_tensors:  tensor([ 2371, 20849, 26042, 20199,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 13448, 18499,    76, 23615, 28400])\n",
            " context_tensors:  tensor([13448, 18499,   679, 23615, 28400, 23265])\n",
            "tensor([17033,  2371,     1, 28403, 26099,     1])\n",
            "context_tensors: context_tensors:  tensor([18499,   679,    76, 28400, 23265, 20533])\n",
            " tensor([ 2371,     1, 26026, 26099,     1, 18520])\n",
            "context_tensors:  context_tensors: tensor([  679,    76, 23615, 23265, 20533, 13448])\n",
            " tensor([    1, 26026, 28403,     1, 18520,  9086])\n",
            "context_tensors:  context_tensors: tensor([   76, 23615, 28400, 20533, 13448, 26026]) \n",
            "tensor([26026, 28403, 26099, 18520,  9086,  1410])context_tensors: \n",
            " context_tensors: tensor([23615, 28400, 23265, 13448, 26026,  7203]) \n",
            "tensor([28403, 26099,     1,  9086,  1410,  1416])\n",
            "context_tensors: context_tensors:   tensor([28400, 23265, 20533, 26026,  7203,  2833])tensor([26099,     1, 18520,  1410,  1416, 14467])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([    1, 18520,  9086,  1416, 14467,    79]) \n",
            "tensor([23265, 20533, 13448,  7203,  2833, 24189])context_tensors: \n",
            " tensor([18520,  9086,  1410, 14467,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([1411, 3476,   62,   76, 8719,   76])tensor([20533, 13448, 26026,  2833, 24189,    62])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3476,    62, 24013,  8719,    76,  2371]) tensor([13448, 26026,  7203, 24189,    62, 20201])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([   62, 24013,    76,    76,  2371, 19080])\n",
            "tensor([26026,  7203,  2833,    62, 20201,  6297])context_tensors: \n",
            " tensor([24013,    76,  8719,  2371, 19080, 18520])\n",
            "context_tensors: context_tensors:   tensor([ 7203,  2833, 24189, 20201,  6297,    76])\n",
            "tensor([   76,  8719,    76, 19080, 18520,  5614])context_tensors: \n",
            " context_tensors: tensor([ 2833, 24189,    62,  6297,    76,  2371]) \n",
            "tensor([ 8719,    76,  2371, 18520,  5614, 28115])\n",
            "context_tensors: context_tensors:  tensor([24189,    62, 20201,    76,  2371, 23746]) \n",
            "context_tensors: tensor([   76,  2371, 19080,  5614, 28115, 11653]) \n",
            "tensor([   62, 20201,  6297,  2371, 23746,  1906])\n",
            "context_tensors: context_tensors:   tensor([20201,  6297,    76, 23746,  1906, 27965])tensor([ 2371, 19080, 18520, 28115, 11653, 26285])\n",
            "\n",
            "context_tensors:  tensor([19080, 18520,  5614, 11653, 26285, 11138])context_tensors: \n",
            " tensor([ 6297,    76,  2371,  1906, 27965,  9157])\n",
            "context_tensors:  tensor([18520,  5614, 28115, 26285, 11138, 18691])\n",
            "context_tensors:  tensor([   76,  2371, 23746, 27965,  9157, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 23746,  1906,  9157, 26026, 28663])tensor([ 5614, 28115, 11653, 11138, 18691, 26285])\n",
            "\n",
            "context_tensors:  tensor([23746,  1906, 27965, 26026, 28663, 16783])context_tensors:  tensor([28115, 11653, 26285, 18691, 26285, 26026])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1906, 27965,  9157, 28663, 16783, 18520])\n",
            "tensor([11653, 26285, 11138, 26285, 26026, 19210])\n",
            "context_tensors:  context_tensors:  tensor([27965,  9157, 26026, 16783, 18520, 26026])\n",
            "tensor([26285, 11138, 18691, 26026, 19210, 18520])\n",
            "context_tensors: context_tensors:  tensor([ 9157, 26026, 28663, 18520, 26026, 24189]) tensor([11138, 18691, 26285, 19210, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 28663, 16783, 26026, 24189,    79])tensor([18691, 26285, 26026, 18520, 26026, 25154])\n",
            "\n",
            "context_tensors:  tensor([28663, 16783, 18520, 24189,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([26285, 26026, 19210, 26026, 25154,    76]) \n",
            "tensor([ 1411, 26026,  2833, 10866, 26026,  7203])context_tensors: \n",
            " tensor([26026, 19210, 18520, 25154,    76,  8586])\n",
            "context_tensors:  context_tensors: tensor([26026,  2833,  7149, 26026,  7203,  1818]) \n",
            "context_tensors: tensor([19210, 18520, 26026,    76,  8586, 26285]) \n",
            "tensor([ 2833,  7149, 10866,  7203,  1818, 21817])context_tensors: \n",
            "context_tensors:  tensor([18520, 26026, 25154,  8586, 26285,  5495]) \n",
            "tensor([ 7149, 10866, 26026,  1818, 21817,    76])\n",
            "context_tensors: context_tensors:   tensor([26026, 25154,    76, 26285,  5495, 13840])tensor([10866, 26026,  7203, 21817,    76,     1])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,  7203,  1818,    76,     1, 12600]) \n",
            "context_tensors: tensor([25154,    76,  8586,  5495, 13840,  2371]) \n",
            "tensor([ 7203,  1818, 21817,     1, 12600,  8719])context_tensors: \n",
            " tensor([   76,  8586, 26285, 13840,  2371,  5715])context_tensors: \n",
            " context_tensors:  tensor([ 1818, 21817,    76, 12600,  8719, 23765])\n",
            "tensor([ 8586, 26285,  5495,  2371,  5715, 24546])\n",
            "context_tensors: context_tensors:   tensor([26285,  5495, 13840,  5715, 24546,  9807])tensor([21817,    76,     1,  8719, 23765,  1423])\n",
            "\n",
            "context_tensors:  tensor([   76,     1, 12600, 23765,  1423, 21815])context_tensors: \n",
            " tensor([ 5495, 13840,  2371, 24546,  9807,    76])context_tensors:  \n",
            "context_tensors: tensor([    1, 12600,  8719,  1423, 21815, 11077])\n",
            " tensor([13840,  2371,  5715,  9807,    76, 18691])context_tensors:  \n",
            "tensor([12600,  8719, 23765, 21815, 11077, 18520])\n",
            "context_tensors:  tensor([ 8719, 23765,  1423, 11077, 18520, 24508])\n",
            "context_tensors:  context_tensors:  tensor([ 2371,  5715, 24546,    76, 18691,  9944])tensor([23765,  1423, 21815, 18520, 24508,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 21815, 11077, 24508,    79,  1409])\n",
            "tensor([ 5715, 24546,  9807, 18691,  9944, 26169])context_tensors: \n",
            " context_tensors:  tensor([ 1411, 23615, 12380, 20649,    79,     1])\n",
            "context_tensors: tensor([24546,  9807,    76,  9944, 26169, 27468])\n",
            " tensor([23615, 12380,  8412,    79,     1,  1409])context_tensors:  \n",
            "tensor([ 9807,    76, 18691, 26169, 27468,  2833])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 10839, 12600, 28849, 22750,  7548])\n",
            "tensor([   76, 18691,  9944, 27468,  2833, 18748])\n",
            "context_tensors: context_tensors:   tensor([10839, 12600, 10290, 22750,  7548, 13448])tensor([18691,  9944, 26169,  2833, 18748,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12600, 10290, 28849,  7548, 13448, 14553])\n",
            "tensor([ 9944, 26169, 27468, 18748,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([10290, 28849, 22750, 13448, 14553,   680])\n",
            " tensor([ 1411, 23615, 13307,  7019,    76,  8892])context_tensors:  \n",
            "tensor([28849, 22750,  7548, 14553,   680,    76])context_tensors:  \n",
            "tensor([23615, 13307, 16121,    76,  8892, 14252])context_tensors: \n",
            " tensor([22750,  7548, 13448,   680,    76, 26026])\n",
            "context_tensors:  context_tensors: tensor([13307, 16121,  7019,  8892, 14252,    76]) tensor([ 7548, 13448, 14553,    76, 26026, 23502])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448, 14553,   680, 26026, 23502,  1416]) tensor([16121,  7019,    76, 14252,    76,  2371])\n",
            "context_tensors:  \n",
            "tensor([14553,   680,    76, 23502,  1416, 28612])context_tensors:  \n",
            "tensor([ 7019,    76,  8892,    76,  2371, 20574])context_tensors: \n",
            " context_tensors: tensor([  680,    76, 26026,  1416, 28612,  1416]) tensor([   76,  8892, 14252,  2371, 20574, 23457])\n",
            "context_tensors: \n",
            " tensor([ 8892, 14252,    76, 20574, 23457, 18520])context_tensors: \n",
            "context_tensors:   tensor([   76, 26026, 23502, 28612,  1416, 18572])tensor([14252,    76,  2371, 23457, 18520, 20199])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  2371, 20574, 18520, 20199, 10866])tensor([26026, 23502,  1416,  1416, 18572,  3476])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 20574, 23457, 20199, 10866, 21261]) \n",
            "tensor([23502,  1416, 28612, 18572,  3476, 25164])\n",
            "context_tensors:  context_tensors: tensor([ 1416, 28612,  1416,  3476, 25164,  2833]) tensor([20574, 23457, 18520, 10866, 21261, 26804])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28612,  1416, 18572, 25164,  2833,  2371]) tensor([23457, 18520, 20199, 21261, 26804,  2371])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([18520, 20199, 10866, 26804,  2371, 18832])tensor([ 1416, 18572,  3476,  2833,  2371, 20006])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18572,  3476, 25164,  2371, 20006, 26285])tensor([20199, 10866, 21261,  2371, 18832, 20851])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3476, 25164,  2833, 20006, 26285, 17668]) \n",
            "tensor([10866, 21261, 26804, 18832, 20851, 25230])context_tensors: \n",
            " context_tensors:  tensor([25164,  2833,  2371, 26285, 17668, 16121])tensor([21261, 26804,  2371, 20851, 25230,  2858])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26804,  2371, 18832, 25230,  2858,  1410]) tensor([ 2833,  2371, 20006, 17668, 16121,    76])\n",
            "\n",
            "context_tensors:  tensor([ 2371, 18832, 20851,  2858,  1410,  5614])\n",
            "context_tensors: context_tensors:  tensor([18832, 20851, 25230,  1410,  5614, 18520])\n",
            " tensor([ 2371, 20006, 26285, 16121,    76,  5608])\n",
            "context_tensors:  context_tensors:  tensor([20851, 25230,  2858,  5614, 18520, 26026])tensor([20006, 26285, 17668,    76,  5608, 28849])\n",
            "\n",
            "context_tensors:  tensor([25230,  2858,  1410, 18520, 26026,  2151])\n",
            "context_tensors:  context_tensors:  tensor([ 2858,  1410,  5614, 26026,  2151,    72])\n",
            "tensor([26285, 17668, 16121,  5608, 28849, 22750])\n",
            "context_tensors:  context_tensors: tensor([ 1410,  5614, 18520,  2151,    72,   683]) tensor([17668, 16121,    76, 28849, 22750, 18997])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 5614, 18520, 26026,    72,   683,    73]) tensor([16121,    76,  5608, 22750, 18997,    76])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18520, 26026,  2151,   683,    73,    76])\n",
            " context_tensors: tensor([   76,  5608, 28849, 18997,    76, 15342]) tensor([26026,  2151,    72,    73,    76, 23243])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5608, 28849, 22750,    76, 15342,  1410])tensor([ 2151,    72,   683,    76, 23243,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28849, 22750, 18997, 15342,  1410,    76])tensor([   72,   683,    73, 23243,  1410,    72])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 683,   73,   76, 1410,   72,  686])tensor([22750, 18997,    76,  1410,    76,  2371])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([18997,    76, 15342,    76,  2371, 21261])\n",
            " tensor([   73,    76, 23243,    72,   686,    73])\n",
            "context_tensors: context_tensors:   tensor([   76, 15342,  1410,  2371, 21261, 26804])\n",
            "tensor([   76, 23243,  1410,   686,    73,    76])context_tensors: \n",
            " context_tensors: tensor([15342,  1410,    76, 21261, 26804,  1410]) tensor([23243,  1410,    72,    73,    76,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410,    76,  2371, 26804,  1410, 13448])tensor([ 1410,    72,   686,    76,  2371, 23556])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  2371, 21261,  1410, 13448,  2334])\n",
            "tensor([   72,   686,    73,  2371, 23556,    62])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 21261, 26804, 13448,  2334,  9106])tensor([  686,    73,    76, 23556,    62,  4359])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([  73,   76, 2371,   62, 4359, 2371])\n",
            " tensor([21261, 26804,  1410,  2334,  9106, 26285])context_tensors: \n",
            " tensor([   76,  2371, 23556,  4359,  2371, 11645])\n",
            "context_tensors: context_tensors:   tensor([26804,  1410, 13448,  9106, 26285, 25376])tensor([ 2371, 23556,    62,  2371, 11645,  5483])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23556,    62,  4359, 11645,  5483,    72])tensor([ 1410, 13448,  2334, 26285, 25376,  4304])\n",
            "\n",
            "context_tensors:  tensor([  62, 4359, 2371, 5483,   72,  685])context_tensors: \n",
            " context_tensors:  tensor([13448,  2334,  9106, 25376,  4304, 12600])tensor([ 4359,  2371, 11645,    72,   685,    76])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2334,  9106, 26285,  4304, 12600, 17455]) \n",
            "tensor([ 2371, 11645,  5483,   685,    76,   689])\n",
            "context_tensors: context_tensors:  tensor([ 9106, 26285, 25376, 12600, 17455,  2371]) \n",
            "tensor([11645,  5483,    72,    76,   689,    73])\n",
            "context_tensors: context_tensors:  tensor([26285, 25376,  4304, 17455,  2371, 23970]) \n",
            "tensor([5483,   72,  685,  689,   73,   79])\n",
            "context_tensors: context_tensors:   tensor([25376,  4304, 12600,  2371, 23970,    79])tensor([  72,  685,   76,   73,   79, 1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4304, 12600, 17455, 23970,    79,  1409])tensor([ 1411, 12600, 18997, 22275, 10866,  2128])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12600, 18997, 18572, 10866,  2128, 26237])tensor([ 1411, 12600, 23970, 25788, 14860, 13448])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18997, 18572, 22275,  2128, 26237,    72]) \n",
            "tensor([12600, 23970,  8627, 14860, 13448, 26910])\n",
            "context_tensors:  tensor([18572, 22275, 10866, 26237,    72,   698])\n",
            "context_tensors:  context_tensors: tensor([23970,  8627, 25788, 13448, 26910, 20526]) \n",
            "tensor([22275, 10866,  2128,    72,   698,    73])\n",
            "context_tensors: context_tensors:   tensor([ 8627, 25788, 14860, 26910, 20526, 23101])tensor([10866,  2128, 26237,   698,    73,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2128, 26237,    72,    73,  2371, 26026])tensor([25788, 14860, 13448, 20526, 23101,  3698])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26237,    72,   698,  2371, 26026, 15873]) \n",
            "tensor([14860, 13448, 26910, 23101,  3698, 18635])\n",
            "context_tensors: context_tensors:   tensor([   72,   698,    73, 26026, 15873, 18520])\n",
            "tensor([13448, 26910, 20526,  3698, 18635,  1423])\n",
            "context_tensors:  tensor([  698,    73,  2371, 15873, 18520, 26026])\n",
            "context_tensors:  tensor([26910, 20526, 23101, 18635,  1423, 14860])context_tensors:  \n",
            "context_tensors: tensor([   73,  2371, 26026, 18520, 26026, 22715]) \n",
            "tensor([20526, 23101,  3698,  1423, 14860,  3017])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26026, 15873, 26026, 22715, 22404])tensor([23101,  3698, 18635, 14860,  3017, 12862])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026, 15873, 18520, 22715, 22404,    72]) \n",
            "tensor([ 3698, 18635,  1423,  3017, 12862,    79])\n",
            "context_tensors: context_tensors:   tensor([18635,  1423, 14860, 12862,    79,  1409])tensor([15873, 18520, 26026, 22404,    72,   710])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18520, 26026, 22715,    72,   710,    73]) \n",
            "tensor([ 1411, 23615,  4593, 24258, 17297, 10866])\n",
            "context_tensors:  context_tensors: tensor([26026, 22715, 22404,   710,    73,    76]) \n",
            "tensor([23615,  4593, 13448, 17297, 10866, 26026])\n",
            "context_tensors:  context_tensors: tensor([22715, 22404,    72,    73,    76,  1423]) \n",
            "tensor([ 4593, 13448, 24258, 10866, 26026, 10217])context_tensors: \n",
            "context_tensors:  tensor([22404,    72,   710,    76,  1423, 25697]) \n",
            "tensor([13448, 24258, 17297, 26026, 10217,    62])context_tensors: \n",
            " tensor([   72,   710,    73,  1423, 25697,  1497])context_tensors: \n",
            " context_tensors: tensor([24258, 17297, 10866, 10217,    62, 25376]) \n",
            "tensor([  710,    73,    76, 25697,  1497,  1423])context_tensors: \n",
            " tensor([17297, 10866, 26026,    62, 25376, 28179])\n",
            "context_tensors:  context_tensors:  tensor([   73,    76,  1423,  1497,  1423, 11645])tensor([10866, 26026, 10217, 25376, 28179, 25357])\n",
            "\n",
            "context_tensors:  tensor([   76,  1423, 25697,  1423, 11645, 28200])context_tensors: \n",
            " tensor([26026, 10217,    62, 28179, 25357, 26026])context_tensors: \n",
            " tensor([ 1423, 25697,  1497, 11645, 28200, 15739])\n",
            "context_tensors: context_tensors:   tensor([25697,  1497,  1423, 28200, 15739,  2304])tensor([10217,    62, 25376, 25357, 26026, 12993])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1497,  1423, 11645, 15739,  2304,  1410])tensor([   62, 25376, 28179, 26026, 12993,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1423, 11645, 28200,  2304,  1410, 18605]) \n",
            "tensor([25376, 28179, 25357, 12993,    79,  1409])context_tensors: \n",
            " tensor([11645, 28200, 15739,  1410, 18605,  1423])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 10179,  3666, 20119, 26045, 13448])\n",
            "context_tensors:   tensor([28200, 15739,  2304, 18605,  1423,  1410])tensor([10179,  3666,  1423, 26045, 13448,  2833])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3666,  1423, 20119, 13448,  2833,  2371]) tensor([15739,  2304,  1410,  1423,  1410,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 20119, 26045,  2833,  2371, 15715])tensor([ 2304,  1410, 18605,  1410,    76, 28115])\n",
            "context_tensors:  \n",
            "tensor([ 1410, 18605,  1423,    76, 28115,  7151])context_tensors: \n",
            " context_tensors: tensor([20119, 26045, 13448,  2371, 15715, 13448]) \n",
            "tensor([18605,  1423,  1410, 28115,  7151, 28102])\n",
            "context_tensors:  context_tensors: tensor([ 1423,  1410,    76,  7151, 28102, 21439]) \n",
            "tensor([26045, 13448,  2833, 15715, 13448, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 1410,    76, 28115, 28102, 21439,    79])tensor([13448,  2833,  2371, 13448, 26026,  8958])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 28115,  7151, 21439,    79,  1409])\n",
            "context_tensors:  tensor([ 1411, 23483,  1497,    76, 11999,  2371])\n",
            " context_tensors:  tensor([ 2833,  2371, 15715, 26026,  8958,   830])tensor([23483,  1497,   544, 11999,  2371, 17895])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 15715, 13448,  8958,   830,  5356])tensor([ 1497,   544,    76,  2371, 17895,    72])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([15715, 13448, 26026,   830,  5356, 10839]) \n",
            "tensor([  544,    76, 11999, 17895,    72,   717])\n",
            "context_tensors: context_tensors:   tensor([   76, 11999,  2371,    72,   717,    73])tensor([13448, 26026,  8958,  5356, 10839, 26026])\n",
            "context_tensors: \n",
            " context_tensors: tensor([11999,  2371, 17895,   717,    73, 25876]) \n",
            "tensor([26026,  8958,   830, 10839, 26026, 21764])context_tensors: \n",
            " context_tensors:  tensor([ 8958,   830,  5356, 26026, 21764, 18520])tensor([ 2371, 17895,    72,    73, 25876, 18520])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  830,  5356, 10839, 21764, 18520, 26026])tensor([17895,    72,   717, 25876, 18520,  1423])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   72,   717,    73, 18520,  1423, 11645]) \n",
            "tensor([ 5356, 10839, 26026, 18520, 26026,  6181])context_tensors: \n",
            " tensor([  717,    73, 25876,  1423, 11645, 17741])context_tensors: \n",
            " context_tensors: tensor([10839, 26026, 21764, 26026,  6181, 18520]) \n",
            "tensor([   73, 25876, 18520, 11645, 17741, 14358])\n",
            "context_tensors:  context_tensors: tensor([26026, 21764, 18520,  6181, 18520, 26026]) \n",
            "tensor([25876, 18520,  1423, 17741, 14358, 28200])context_tensors: \n",
            "context_tensors:  tensor([21764, 18520, 26026, 18520, 26026, 10179])\n",
            " tensor([18520,  1423, 11645, 14358, 28200, 22008])context_tensors:  \n",
            "tensor([18520, 26026,  6181, 26026, 10179,  4787])context_tensors: \n",
            " tensor([ 1423, 11645, 17741, 28200, 22008, 12600])\n",
            "context_tensors: context_tensors:  tensor([26026,  6181, 18520, 10179,  4787, 23963]) \n",
            "tensor([11645, 17741, 14358, 22008, 12600, 10217])\n",
            "context_tensors:  context_tensors: tensor([ 6181, 18520, 26026,  4787, 23963,  2836]) \n",
            "tensor([17741, 14358, 28200, 12600, 10217, 11158])context_tensors: \n",
            " context_tensors: tensor([18520, 26026, 10179, 23963,  2836,  6378])\n",
            " context_tensors: tensor([14358, 28200, 22008, 10217, 11158, 20245]) \n",
            "context_tensors:  tensor([26026, 10179,  4787,  2836,  6378,  8675])tensor([28200, 22008, 12600, 11158, 20245, 26169])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([10179,  4787, 23963,  6378,  8675,    76])\n",
            " context_tensors:  tensor([22008, 12600, 10217, 20245, 26169, 26026])\n",
            "tensor([ 4787, 23963,  2836,  8675,    76, 19612])context_tensors: \n",
            "context_tensors:   tensor([23963,  2836,  6378,    76, 19612, 19132])\n",
            "tensor([12600, 10217, 11158, 26169, 26026,  1922])context_tensors:  \n",
            "tensor([ 2836,  6378,  8675, 19612, 19132,  4787])\n",
            "context_tensors:  tensor([ 6378,  8675,    76, 19132,  4787,  1410])\n",
            "context_tensors:  context_tensors:  tensor([10217, 11158, 20245, 26026,  1922, 18520])tensor([ 8675,    76, 19612,  4787,  1410,  1410])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 19612, 19132,  1410,  1410,    76]) tensor([11158, 20245, 26169,  1922, 18520, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([19612, 19132,  4787,  1410,    76,  2371])\n",
            "context_tensors:  \n",
            "tensor([19132,  4787,  1410,    76,  2371, 26026]) context_tensors: tensor([20245, 26169, 26026, 18520, 26026, 10179]) tensor([ 4787,  1410,  1410,  2371, 26026, 10182])\n",
            "context_tensors:  \n",
            "tensor([ 1410,  1410,    76, 26026, 10182,  1416])\n",
            "context_tensors:  context_tensors: tensor([ 1410,    76,  2371, 10182,  1416, 26046]) \n",
            "tensor([26169, 26026,  1922, 26026, 10179,    79])\n",
            "context_tensors: context_tensors:   tensor([   76,  2371, 26026,  1416, 26046, 28438])tensor([26026,  1922, 18520, 10179,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2371, 26026, 10182, 26046, 28438, 18520]) \n",
            "tensor([ 1411, 26026, 24955,  2334, 18572,  1410])context_tensors: \n",
            " context_tensors: tensor([26026, 10182,  1416, 28438, 18520,  3150])\n",
            " tensor([26026, 24955, 10352, 18572,  1410,  1416])\n",
            "context_tensors:  context_tensors: tensor([24955, 10352,  2334,  1410,  1416, 15606])\n",
            "context_tensors:  tensor([10182,  1416, 26046, 18520,  3150, 13225]) tensor([10352,  2334, 18572,  1416, 15606, 16246])\n",
            "\n",
            "context_tensors:  tensor([ 1416, 26046, 28438,  3150, 13225,  1410])\n",
            "context_tensors: context_tensors:   tensor([ 2334, 18572,  1410, 15606, 16246,  4890])tensor([26046, 28438, 18520, 13225,  1410,  1410])\n",
            "\n",
            "context_tensors:  tensor([18572,  1410,  1416, 16246,  4890, 17531])\n",
            "context_tensors: context_tensors:  tensor([28438, 18520,  3150,  1410,  1410,    79])\n",
            "context_tensors:   tensor([18520,  3150, 13225,  1410,    79,  1409])\n",
            "tensor([ 1410,  1416, 15606,  4890, 17531,  1410])\n",
            "context_tensors: context_tensors:   tensor([ 1416, 15606, 16246, 17531,  1410,  2371])\n",
            "tensor([ 1411, 21036, 16479, 25230, 26047,  9801])\n",
            "context_tensors:  tensor([15606, 16246,  4890,  1410,  2371,  1410])\n",
            "context_tensors: context_tensors:   tensor([21036, 16479, 16104, 26047,  9801, 17392])tensor([16246,  4890, 17531,  2371,  1410, 25263])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 4890, 17531,  1410,  1410, 25263,  1423])\n",
            " context_tensors: tensor([16479, 16104, 25230,  9801, 17392, 20119]) \n",
            "tensor([17531,  1410,  2371, 25263,  1423,  1410])\n",
            "context_tensors: context_tensors:   tensor([16104, 25230, 26047, 17392, 20119,  4787])\n",
            "tensor([ 1410,  2371,  1410,  1423,  1410, 24182])context_tensors: \n",
            "  tensor([25230, 26047,  9801, 20119,  4787, 23381])\n",
            "context_tensors:  tensor([26047,  9801, 17392,  4787, 23381,  1410])\n",
            "context_tensors: context_tensors:  tensor([ 9801, 17392, 20119, 23381,  1410, 20199])\n",
            "tensor([ 2371,  1410, 25263,  1410, 24182,  6553])\n",
            "context_tensors: context_tensors:   tensor([17392, 20119,  4787,  1410, 20199, 26285])tensor([ 1410, 25263,  1423, 24182,  6553,    79])\n",
            "\n",
            "context_tensors: context_tensors:  \n",
            "tensor([20119,  4787, 23381, 20199, 26285, 11138]) context_tensors:  tensor([25263,  1423,  1410,  6553,    79,  1409])tensor([ 4787, 23381,  1410, 26285, 11138,  8889])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([23381,  1410, 20199, 11138,  8889, 26026])\n",
            " context_tensors: tensor([ 1411, 23910, 26026,    76, 13888,  2858])\n",
            " context_tensors: tensor([ 1410, 20199, 26285,  8889, 26026,   690])\n",
            " context_tensors: tensor([23910, 26026, 25500, 13888,  2858,  1423]) \n",
            "tensor([20199, 26285, 11138, 26026,   690,    79])context_tensors: \n",
            " tensor([26026, 25500,    76,  2858,  1423, 23433])\n",
            "context_tensors: context_tensors:   tensor([26285, 11138,  8889,   690,    79,  1409])\n",
            "tensor([25500,    76, 13888,  1423, 23433, 26285])context_tensors: \n",
            " context_tensors: tensor([ 1411, 13448,   686,  3476, 20574,  1423]) tensor([   76, 13888,  2858, 23433, 26285, 22715])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448,   686,    76, 20574,  1423,  1410])tensor([13888,  2858,  1423, 26285, 22715, 22404])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([  686,    76,  3476,  1423,  1410, 23457]) \n",
            "tensor([ 2858,  1423, 23433, 22715, 22404, 27965])context_tensors: \n",
            " context_tensors: tensor([   76,  3476, 20574,  1410, 23457,  7849]) \n",
            "tensor([ 1423, 23433, 26285, 22404, 27965, 18887])context_tensors: \n",
            " tensor([ 3476, 20574,  1423, 23457,  7849,  9250])\n",
            "context_tensors: context_tensors:   tensor([20574,  1423,  1410,  7849,  9250,  2371])\n",
            "tensor([23433, 26285, 22715, 27965, 18887, 13448])\n",
            "context_tensors:  tensor([ 1423,  1410, 23457,  9250,  2371, 10179])\n",
            "context_tensors: context_tensors:   tensor([ 1410, 23457,  7849,  2371, 10179,    79])tensor([26285, 22715, 22404, 18887, 13448,   717])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([23457,  7849,  9250, 10179,    79,  1409])\n",
            " context_tensors:  tensor([ 1411, 13448,   693,  3476, 23407, 12600])tensor([22715, 22404, 27965, 13448,   717, 28356])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448,   693,    76, 23407, 12600, 10776]) \n",
            "context_tensors: tensor([22404, 27965, 18887,   717, 28356, 11999]) tensor([  693,    76,  3476, 12600, 10776, 10182])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76,  3476, 23407, 10776, 10182, 19080])\n",
            " tensor([27965, 18887, 13448, 28356, 11999,    76])context_tensors: \n",
            "context_tensors:   tensor([18887, 13448,   717, 11999,    76,  4767])tensor([ 3476, 23407, 12600, 10182, 19080, 26285])\n",
            "\n",
            "context_tensors:  tensor([13448,   717, 28356,    76,  4767, 18616])context_tensors:  \n",
            "tensor([23407, 12600, 10776, 19080, 26285, 27468])context_tensors: \n",
            " tensor([  717, 28356, 11999,  4767, 18616,  8012])context_tensors: \n",
            " context_tensors: tensor([12600, 10776, 10182, 26285, 27468, 20851])\n",
            " context_tensors: tensor([28356, 11999,    76, 18616,  8012, 13448])\n",
            " tensor([10776, 10182, 19080, 27468, 20851,    79])context_tensors: \n",
            " tensor([11999,    76,  4767,  8012, 13448,   732])context_tensors:  tensor([10182, 19080, 26285, 20851,    79,  1409])\n",
            "context_tensors: \n",
            " tensor([   76,  4767, 18616, 13448,   732,    79])context_tensors: \n",
            " context_tensors: tensor([ 1411,  4030, 19069,   879, 10866,   869]) \n",
            "tensor([ 4767, 18616,  8012,   732,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 14210, 27965, 20205, 13448,   773])\n",
            " tensor([ 4030, 19069, 28775, 10866,   869, 19080])context_tensors:  \n",
            "tensor([14210, 27965, 20849, 13448,   773,  2371])\n",
            "context_tensors:  context_tensors:  tensor([27965, 20849, 20205,   773,  2371, 14156])tensor([19069, 28775,   879,   869, 19080, 28356])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([20849, 20205, 13448,  2371, 14156,  7151]) tensor([28775,   879, 10866, 19080, 28356,  1583])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([20205, 13448,   773, 14156,  7151,  6578]) \n",
            "tensor([  879, 10866,   869, 28356,  1583, 27570])context_tensors:  \n",
            "context_tensors: tensor([13448,   773,  2371,  7151,  6578, 15481]) \n",
            "tensor([10866,   869, 19080,  1583, 27570,    76])context_tensors: \n",
            " tensor([  773,  2371, 14156,  6578, 15481, 25221])\n",
            "context_tensors: context_tensors:  tensor([  869, 19080, 28356, 27570,    76,  4767])\n",
            " tensor([ 2371, 14156,  7151, 15481, 25221, 26015])\n",
            "context_tensors: context_tensors:   tensor([19080, 28356,  1583,    76,  4767, 14210])\n",
            "tensor([14156,  7151,  6578, 25221, 26015, 11999])\n",
            "context_tensors: context_tensors:   tensor([ 7151,  6578, 15481, 26015, 11999,    79])\n",
            "tensor([28356,  1583, 27570,  4767, 14210, 27969])context_tensors:  \n",
            "tensor([ 6578, 15481, 25221, 11999,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 1583, 27570,    76, 14210, 27969,    64])\n",
            " tensor([ 1411,  3476, 27965,  8043,  5671,    76])context_tensors:  tensor([27570,    76,  4767, 27969,    64, 27255])\n",
            "context_tensors: \n",
            " tensor([   76,  4767, 14210,    64, 27255, 20840])context_tensors: \n",
            " tensor([ 3476, 27965,  1423,  5671,    76,  2371])\n",
            "context_tensors: context_tensors:   tensor([ 4767, 14210, 27969, 27255, 20840, 18520])\n",
            "tensor([27965,  1423,  8043,    76,  2371, 20574])context_tensors: \n",
            " context_tensors: tensor([14210, 27969,    64, 20840, 18520, 10776]) \n",
            "tensor([ 1423,  8043,  5671,  2371, 20574, 21789])\n",
            "context_tensors:  context_tensors: tensor([ 8043,  5671,    76, 20574, 21789,  1416])\n",
            " tensor([27969,    64, 27255, 18520, 10776, 10179])\n",
            "context_tensors: context_tensors:   tensor([ 5671,    76,  2371, 21789,  1416, 26046])tensor([   64, 27255, 20840, 10776, 10179, 18520])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76,  2371, 20574,  1416, 26046, 28449])\n",
            " tensor([27255, 20840, 18520, 10179, 18520, 26026])context_tensors: \n",
            "context_tensors:  tensor([ 2371, 20574, 21789, 26046, 28449, 26170]) \n",
            "tensor([20840, 18520, 10776, 18520, 26026, 25294])\n",
            "context_tensors:  context_tensors:  tensor([20574, 21789,  1416, 28449, 26170, 12600])tensor([18520, 10776, 10179, 26026, 25294, 13448])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([21789,  1416, 26046, 26170, 12600, 15567])\n",
            "tensor([10776, 10179, 18520, 25294, 13448,   695])\n",
            "context_tensors:  context_tensors: tensor([ 1416, 26046, 28449, 12600, 15567,    79]) \n",
            "tensor([10179, 18520, 26026, 13448,   695, 26023])\n",
            "context_tensors: context_tensors:   tensor([26046, 28449, 26170, 15567,    79,  1409])\n",
            "tensor([18520, 26026, 25294,   695, 26023,  3476])context_tensors: \n",
            " context_tensors: tensor([ 1411, 23615, 20849, 20199,  2371, 10648])\n",
            "context_tensors:   tensor([26026, 25294, 13448, 26023,  3476, 21439])tensor([23615, 20849,  9124,  2371, 10648, 12037])\n",
            "\n",
            "context_tensors:  tensor([25294, 13448,   695,  3476, 21439, 22638])context_tensors: \n",
            " tensor([20849,  9124, 20199, 10648, 12037,  2398])\n",
            "context_tensors:  context_tensors:  tensor([ 9124, 20199,  2371, 12037,  2398,  4000])tensor([13448,   695, 26023, 21439, 22638, 10866])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([20199,  2371, 10648,  2398,  4000,  5072])tensor([  695, 26023,  3476, 22638, 10866, 12600])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 10648, 12037,  4000,  5072, 10866]) \n",
            "tensor([26023,  3476, 21439, 10866, 12600, 28438])\n",
            "context_tensors:  tensor([10648, 12037,  2398,  5072, 10866, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 3476, 21439, 22638, 12600, 28438,    79])tensor([12037,  2398,  4000, 10866, 26026, 24189])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2398,  4000,  5072, 26026, 24189, 10866])tensor([21439, 22638, 10866, 28438,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4000,  5072, 10866, 24189, 10866,  1410])tensor([ 1411, 16479,  1410,  4902,    76, 28243])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16479,  1410,  5847,    76, 28243, 18520])tensor([ 5072, 10866, 26026, 10866,  1410,  5671])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410,  5847,  4902, 28243, 18520,  3158])tensor([10866, 26026, 24189,  1410,  5671, 14956])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5847,  4902,    76, 18520,  3158,  8180])\n",
            "tensor([26026, 24189, 10866,  5671, 14956, 13448])\n",
            "context_tensors:  context_tensors:  tensor([ 4902,    76, 28243,  3158,  8180,  5847])\n",
            "tensor([24189, 10866,  1410, 14956, 13448,   684])\n",
            "context_tensors: context_tensors:  tensor([   76, 28243, 18520,  8180,  5847,  4902])\n",
            " context_tensors:  tensor([28243, 18520,  3158,  5847,  4902,    76])\n",
            "context_tensors: tensor([10866,  1410,  5671, 13448,   684,  2371]) \n",
            "context_tensors: tensor([18520,  3158,  8180,  4902,    76, 28520]) \n",
            "context_tensors: tensor([ 1410,  5671, 14956,   684,  2371, 13448]) \n",
            "tensor([ 3158,  8180,  5847,    76, 28520, 13448])context_tensors: \n",
            "context_tensors:   tensor([ 5671, 14956, 13448,  2371, 13448,   693])tensor([ 8180,  5847,  4902, 28520, 13448,  2661])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14956, 13448,   684, 13448,   693, 22079])tensor([ 5847,  4902,    76, 13448,  2661,   695])\n",
            "context_tensors:  \n",
            "tensor([13448,   684,  2371,   693, 22079,    79])context_tensors: \n",
            " tensor([ 4902,    76, 28520,  2661,   695,  1497])\n",
            "context_tensors: context_tensors:  tensor([   76, 28520, 13448,   695,  1497,  3476])\n",
            " tensor([  684,  2371, 13448, 22079,    79,  1409])context_tensors:  \n",
            "context_tensors: tensor([28520, 13448,  2661,  1497,  3476,  2371]) tensor([ 1411,  5681,  5072,  7929, 10866, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448,  2661,   695,  3476,  2371, 10776])\n",
            " context_tensors:  tensor([ 5681,  5072, 28115, 10866, 26026, 11649])tensor([ 2661,   695,  1497,  2371, 10776, 10179])\n",
            "context_tensors:  \n",
            "tensor([  695,  1497,  3476, 10776, 10179, 18520])context_tensors: \n",
            " tensor([ 5072, 28115,  7929, 26026, 11649,     6])context_tensors: \n",
            " tensor([ 1497,  3476,  2371, 10179, 18520, 26026])\n",
            "context_tensors: context_tensors:  tensor([28115,  7929, 10866, 11649,     6, 11137])\n",
            " tensor([ 3476,  2371, 10776, 18520, 26026, 24589])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 10776, 10179, 26026, 24589,  1406])\n",
            "tensor([ 7929, 10866, 26026,     6, 11137, 24189])\n",
            "context_tensors:  context_tensors: tensor([10776, 10179, 18520, 24589,  1406,     1]) tensor([10866, 26026, 11649, 11137, 24189, 18921])\n",
            "\n",
            "context_tensors:  tensor([10179, 18520, 26026,  1406,     1, 23615])context_tensors:  \n",
            "tensor([26026, 11649,     6, 24189, 18921,  1423])context_tensors: \n",
            " context_tensors: tensor([18520, 26026, 24589,     1, 23615, 12380])\n",
            " tensor([11649,     6, 11137, 18921,  1423,   794])\n",
            "context_tensors: context_tensors:   tensor([26026, 24589,  1406, 23615, 12380, 25230])\n",
            "tensor([    6, 11137, 24189,  1423,   794,  1416])\n",
            "context_tensors: context_tensors:   tensor([11137, 24189, 18921,   794,  1416, 28612])\n",
            "tensor([24589,  1406,     1, 12380, 25230, 10069])\n",
            "context_tensors:  context_tensors: tensor([24189, 18921,  1423,  1416, 28612, 19528]) \n",
            "tensor([ 1406,     1, 23615, 25230, 10069, 25776])\n",
            "context_tensors: context_tensors:   tensor([18921,  1423,   794, 28612, 19528,    76])tensor([    1, 23615, 12380, 10069, 25776,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23615, 12380, 25230, 25776,    76,  3857])tensor([ 1423,   794,  1416, 19528,    76,  2371])\n",
            "context_tensors: \n",
            " tensor([12380, 25230, 10069,    76,  3857,  1410])context_tensors: \n",
            " tensor([  794,  1416, 28612,    76,  2371, 26026])\n",
            "context_tensors:  tensor([ 1416, 28612, 19528,  2371, 26026, 10609])\n",
            "context_tensors: context_tensors:   tensor([25230, 10069, 25776,  3857,  1410,    79])tensor([28612, 19528,    76, 26026, 10609, 26151])\n",
            "\n",
            "context_tensors:  tensor([19528,    76,  2371, 10609, 26151,  7933])context_tensors:  tensor([10069, 25776,    76,  1410,    79,     1])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  2371, 26026, 26151,  7933, 24212])\n",
            "tensor([25776,    76,  3857,    79,     1,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 2371, 26026, 10609,  7933, 24212, 18854])\n",
            " context_tensors: tensor([ 1411, 13448,   694, 26026, 10217, 17511]) \n",
            "context_tensors: tensor([26026, 10609, 26151, 24212, 18854,  1423]) \n",
            "context_tensors: tensor([13448,   694,    76, 10217, 17511, 14014])\n",
            " context_tensors: tensor([10609, 26151,  7933, 18854,  1423,  6158]) \n",
            "tensor([  694,    76, 26026, 17511, 14014,  1423])context_tensors: \n",
            "context_tensors:  tensor([26151,  7933, 24212,  1423,  6158, 20513]) tensor([   76, 26026, 10217, 14014,  1423, 10996])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 7933, 24212, 18854,  6158, 20513, 18520])\n",
            "tensor([26026, 10217, 17511,  1423, 10996,  1416])context_tensors: \n",
            " context_tensors:  tensor([10217, 17511, 14014, 10996,  1416, 15503])tensor([24212, 18854,  1423, 20513, 18520,  1080])\n",
            "context_tensors: \n",
            " tensor([18854,  1423,  6158, 18520,  1080,  1415])context_tensors: \n",
            " context_tensors:  tensor([17511, 14014,  1423,  1416, 15503,    76])\n",
            "tensor([ 1423,  6158, 20513,  1080,  1415,  1110])context_tensors: \n",
            " tensor([14014,  1423, 10996, 15503,    76, 23367])\n",
            "context_tensors: context_tensors:   tensor([ 6158, 20513, 18520,  1415,  1110, 13448])\n",
            "tensor([ 1423, 10996,  1416,    76, 23367,  1416])context_tensors: \n",
            " context_tensors: tensor([20513, 18520,  1080,  1110, 13448,   693]) \n",
            "tensor([10996,  1416, 15503, 23367,  1416,  7967])\n",
            "context_tensors:  tensor([ 1416, 15503,    76,  1416,  7967, 27629])\n",
            "context_tensors: context_tensors:   tensor([18520,  1080,  1415, 13448,   693,    79])tensor([15503,    76, 23367,  7967, 27629, 12990])\n",
            "context_tensors: \n",
            " context_tensors: tensor([1080, 1415, 1110,  693,   79, 1409])\n",
            " context_tensors: tensor([   76, 23367,  1416, 27629, 12990,  3017])\n",
            "context_tensors:   tensor([23367,  1416,  7967, 12990,  3017,   855])tensor([ 1411,  2334, 18766, 10866, 26026, 24189])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2334, 18766,  7923, 26026, 24189,  4890])\n",
            "tensor([ 1416,  7967, 27629,  3017,   855, 26026])context_tensors: \n",
            " tensor([18766,  7923, 10866, 24189,  4890, 26026])context_tensors: \n",
            " tensor([ 7967, 27629, 12990,   855, 26026, 27881])context_tensors:  \n",
            "tensor([ 7923, 10866, 26026,  4890, 26026,  7473])\n",
            "context_tensors: context_tensors:  tensor([27629, 12990,  3017, 26026, 27881,    79]) \n",
            "tensor([10866, 26026, 24189, 26026,  7473, 18520])context_tensors: \n",
            " context_tensors: tensor([12990,  3017,   855, 27881,    79,  1409])\n",
            "context_tensors:   tensor([26026, 24189,  4890,  7473, 18520, 26026])\n",
            "tensor([ 1411,  3476, 12153, 25098,  4670, 13448])\n",
            "context_tensors: context_tensors:   tensor([24189,  4890, 26026, 18520, 26026, 28452])\n",
            "tensor([ 3476, 12153,  1423,  4670, 13448, 26026])context_tensors: \n",
            "context_tensors:  tensor([ 4890, 26026,  7473, 26026, 28452, 12380])\n",
            " context_tensors: tensor([12153,  1423, 25098, 13448, 26026, 11405]) tensor([26026,  7473, 18520, 28452, 12380,  6164])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 25098,  4670, 26026, 11405,  2371])\n",
            "tensor([ 7473, 18520, 26026, 12380,  6164, 27965])context_tensors: \n",
            " tensor([25098,  4670, 13448, 11405,  2371, 12600])\n",
            "context_tensors:  tensor([18520, 26026, 28452,  6164, 27965, 20919])context_tensors:  \n",
            "tensor([ 4670, 13448, 26026,  2371, 12600, 23970])context_tensors:  \n",
            "tensor([26026, 28452, 12380, 27965, 20919,  4787])\n",
            "context_tensors: context_tensors:   tensor([28452, 12380,  6164, 20919,  4787, 21036])tensor([13448, 26026, 11405, 12600, 23970,  6443])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12380,  6164, 27965,  4787, 21036, 16479])\n",
            "tensor([26026, 11405,  2371, 23970,  6443,  1423])\n",
            "context_tensors: context_tensors:   tensor([ 6164, 27965, 20919, 21036, 16479, 10866])tensor([11405,  2371, 12600,  6443,  1423, 14860])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([27965, 20919,  4787, 16479, 10866, 28858])\n",
            "tensor([ 2371, 12600, 23970,  1423, 14860, 13448])\n",
            "context_tensors:  context_tensors: tensor([20919,  4787, 21036, 10866, 28858,  1108]) \n",
            "context_tensors: tensor([12600, 23970,  6443, 14860, 13448,  1423]) \n",
            "tensor([ 4787, 21036, 16479, 28858,  1108,  1417])context_tensors: \n",
            " tensor([23970,  6443,  1423, 13448,  1423, 22541])\n",
            "context_tensors: context_tensors:  tensor([21036, 16479, 10866,  1108,  1417,  1108])\n",
            " tensor([ 6443,  1423, 14860,  1423, 22541,  3017])context_tensors:  \n",
            "tensor([16479, 10866, 28858,  1417,  1108,  1417])context_tensors: \n",
            " context_tensors:  tensor([ 1423, 14860, 13448, 22541,  3017, 26026])\n",
            "tensor([10866, 28858,  1108,  1108,  1417,    86])\n",
            "context_tensors: context_tensors:  tensor([14860, 13448,  1423,  3017, 26026,  3293]) \n",
            "tensor([28858,  1108,  1417,  1417,    86, 13448])\n",
            "context_tensors: context_tensors:   tensor([13448,  1423, 22541, 26026,  3293, 18520])\n",
            "tensor([ 1108,  1417,  1108,    86, 13448,   696])\n",
            "context_tensors: context_tensors:  tensor([ 1417,  1108,  1417, 13448,   696,    79])\n",
            "context_tensors:   tensor([1108, 1417,   86,  696,   79, 1409])tensor([ 1423, 22541,  3017,  3293, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22541,  3017, 26026, 18520, 26026, 12990])tensor([ 1411, 26026,  7203, 24189, 13087,  3476])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3017, 26026,  3293, 26026, 12990,    79])\n",
            "context_tensors:   tensor([26026,  7203,  2833, 13087,  3476,    62])\n",
            "tensor([26026,  3293, 18520, 12990,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([ 7203,  2833, 24189,  3476,    62,  4245])\n",
            " tensor([ 1411, 26026, 10217,  1410,  2371,  3077])\n",
            "context_tensors: context_tensors:   tensor([26026, 10217, 15733,  2371,  3077,  4304])\n",
            "tensor([ 2833, 24189, 13087,    62,  4245,  7015])\n",
            "context_tensors:  context_tensors: tensor([10217, 15733,  1410,  3077,  4304, 24637]) \n",
            "context_tensors: tensor([24189, 13087,  3476,  4245,  7015,  7923])\n",
            " context_tensors: tensor([15733,  1410,  2371,  4304, 24637,  9075])\n",
            " context_tensors: tensor([13087,  3476,    62,  7015,  7923, 10866]) tensor([ 1410,  2371,  3077, 24637,  9075,    62])\n",
            "context_tensors: \n",
            " tensor([2371, 3077, 4304, 9075,   62, 2371])\n",
            "context_tensors: context_tensors:   tensor([ 3476,    62,  4245,  7923, 10866, 26026])tensor([ 3077,  4304, 24637,    62,  2371, 24637])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([   62,  4245,  7015, 10866, 26026, 24189])tensor([ 4304, 24637,  9075,  2371, 24637,  2385])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([24637,  9075,    62, 24637,  2385,    62])\n",
            " context_tensors: tensor([ 4245,  7015,  7923, 26026, 24189, 10866])\n",
            " context_tensors:  tensor([ 9075,    62,  2371,  2385,    62, 13448])\n",
            "tensor([ 7015,  7923, 10866, 24189, 10866, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 7923, 10866, 26026, 10866, 26026,  1410])\n",
            "tensor([   62,  2371, 24637,    62, 13448,  7203])context_tensors:  tensor([10866, 26026, 24189, 26026,  1410, 18520])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([26026, 24189, 10866,  1410, 18520, 26026]) \n",
            "tensor([ 2371, 24637,  2385, 13448,  7203, 28846])\n",
            "context_tensors: context_tensors:   tensor([24189, 10866, 26026, 18520, 26026, 11791])tensor([24637,  2385,    62,  7203, 28846,     1])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10866, 26026,  1410, 26026, 11791, 13448])tensor([ 2385,    62, 13448, 28846,     1, 15921])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,  1410, 18520, 11791, 13448, 14227])\n",
            " context_tensors: tensor([   62, 13448,  7203,     1, 15921,     1])\n",
            " tensor([ 1410, 18520, 26026, 13448, 14227, 18300])context_tensors:  tensor([13448,  7203, 28846, 15921,     1,  5716])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 7203, 28846,     1,     1,  5716, 10866])\n",
            " tensor([18520, 26026, 11791, 14227, 18300,   687])context_tensors: \n",
            " tensor([28846,     1, 15921,  5716, 10866, 26026])\n",
            "context_tensors: context_tensors:   tensor([    1, 15921,     1, 10866, 26026, 15481])\n",
            "tensor([26026, 11791, 13448, 18300,   687,  9946])context_tensors:  \n",
            "tensor([15921,     1,  5716, 26026, 15481, 20529])\n",
            "context_tensors:  context_tensors: tensor([11791, 13448, 14227,   687,  9946,    79])\n",
            "context_tensors:  tensor([13448, 14227, 18300,  9946,    79,  1409]) \n",
            "tensor([13494, 26026,  1410, 18559,    76, 26026])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 21789,  1416,  4246, 13494, 26026])\n",
            " tensor([26026,  1410, 13448,    76, 26026, 10365])\n",
            "context_tensors:  context_tensors: tensor([21789,  1416, 26046, 13494, 26026,  5614]) tensor([ 1410, 13448, 18559, 26026, 10365, 18520])\n",
            "\n",
            "context_tensors:  tensor([ 1416, 26046,  4246, 26026,  5614,    62])context_tensors: \n",
            " context_tensors:  tensor([13448, 18559,    76, 10365, 18520, 26026])tensor([26046,  4246, 13494,  5614,    62,  4240])\n",
            "\n",
            "context_tensors:  tensor([18559,    76, 26026, 18520, 26026, 10648])\n",
            "context_tensors: context_tensors:  tensor([ 4246, 13494, 26026,    62,  4240, 18520]) \n",
            "tensor([   76, 26026, 10365, 26026, 10648, 26138])context_tensors: \n",
            " tensor([13494, 26026,  5614,  4240, 18520, 13156])context_tensors: \n",
            " context_tensors: tensor([26026, 10365, 18520, 10648, 26138,    72])\n",
            " tensor([26026,  5614,    62, 18520, 13156,    72])context_tensors: \n",
            " context_tensors:  tensor([ 5614,    62,  4240, 13156,    72,   699])\n",
            "tensor([10365, 18520, 26026, 26138,    72,   699])context_tensors:  tensor([   62,  4240, 18520,    72,   699,    73])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([18520, 26026, 10648,    72,   699,    73])\n",
            "tensor([ 4240, 18520, 13156,   699,    73,  2371])context_tensors: \n",
            "context_tensors:   tensor([26026, 10648, 26138,   699,    73,    76])tensor([18520, 13156,    72,    73,  2371, 12451])\n",
            "context_tensors:  \n",
            "tensor([13156,    72,   699,  2371, 12451, 15341])\n",
            "context_tensors: context_tensors:   tensor([   72,   699,    73, 12451, 15341, 16681])\n",
            "tensor([10648, 26138,    72,    73,    76, 10866])\n",
            "context_tensors: context_tensors:   tensor([26138,    72,   699,    76, 10866, 26026])tensor([  699,    73,  2371, 15341, 16681,    72])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   72,   699,    73, 10866, 26026,  5467])tensor([   73,  2371, 12451, 16681,    72,   705])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  699,    73,    76, 26026,  5467, 13448])\n",
            "tensor([ 2371, 12451, 15341,    72,   705,    73])\n",
            "context_tensors:  tensor([   73,    76, 10866,  5467, 13448, 15750])context_tensors: \n",
            " context_tensors: tensor([12451, 15341, 16681,   705,    73,    76]) tensor([   76, 10866, 26026, 13448, 15750, 12990])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15341, 16681,    72,    73,    76, 26026])tensor([10866, 26026,  5467, 15750, 12990,    76])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([26026,  5467, 13448, 12990,    76,  1423])tensor([16681,    72,   705,    76, 26026, 15272])\n",
            "\n",
            "context_tensors:  tensor([ 5467, 13448, 15750,    76,  1423, 12862])\n",
            "context_tensors:  context_tensors:  tensor([13448, 15750, 12990,  1423, 12862, 10866])tensor([   72,   705,    73, 26026, 15272, 28516])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  705,    73,    76, 15272, 28516, 13448])\n",
            "tensor([15750, 12990,    76, 12862, 10866,  7956])context_tensors: \n",
            " context_tensors: tensor([   73,    76, 26026, 28516, 13448,  6063]) tensor([12990,    76,  1423, 10866,  7956, 28399])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76,  1423, 12862,  7956, 28399,  3017])tensor([   76, 26026, 15272, 13448,  6063, 28356])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 12862, 10866, 28399,  3017, 19451])\n",
            "tensor([26026, 15272, 28516,  6063, 28356, 12600])\n",
            "context_tensors:  context_tensors: tensor([12862, 10866,  7956,  3017, 19451,    76]) \n",
            "tensor([15272, 28516, 13448, 28356, 12600, 23970])\n",
            "context_tensors: context_tensors:   tensor([28516, 13448,  6063, 12600, 23970,    79])tensor([10866,  7956, 28399, 19451,    76, 27882])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 7956, 28399,  3017,    76, 27882,    76])\n",
            "context_tensors:   tensor([13448,  6063, 28356, 23970,    79,  1409])tensor([28399,  3017, 19451, 27882,    76,  2371])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3017, 19451,    76,    76,  2371, 26026]) \n",
            "tensor([ 1411, 16187, 21789, 13494, 26026,  1410])context_tensors:  \n",
            "tensor([19451,    76, 27882,  2371, 26026, 19167])\n",
            "context_tensors:  context_tensors:  \n",
            "tensor([16187, 21789, 28449, 26026,  1410, 13448])tensor([   76, 27882,    76, 26026, 19167, 18520])\n",
            "context_tensors: context_tensors:   tensor([27882,    76,  2371, 19167, 18520, 26026])\n",
            "tensor([21789, 28449, 13494,  1410, 13448, 18559])context_tensors: \n",
            " tensor([   76,  2371, 26026, 18520, 26026, 11914])context_tensors: \n",
            " context_tensors: tensor([28449, 13494, 26026, 13448, 18559,    76])\n",
            " tensor([ 2371, 26026, 19167, 26026, 11914, 25364])context_tensors: \n",
            " tensor([13448, 26026, 11543,    76, 18273, 26023])context_tensors: \n",
            " context_tensors: tensor([26026, 19167, 18520, 11914, 25364,    72])\n",
            " context_tensors:  tensor([19167, 18520, 26026, 25364,    72,   706])tensor([26026, 11543,  7490, 18273, 26023, 14210])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18520, 26026, 11914,    72,   706,    73])\n",
            "context_tensors: tensor([11543,  7490,    76, 26023, 14210,  3761]) \n",
            "tensor([26026, 11914, 25364,   706,    73, 10866])\n",
            "context_tensors: context_tensors:   tensor([11914, 25364,    72,    73, 10866, 24637])\n",
            "context_tensors: tensor([ 7490,    76, 18273, 14210,  3761, 26285]) \n",
            "context_tensors: tensor([25364,    72,   706, 10866, 24637, 11559])\n",
            "context_tensors:   tensor([   72,   706,    73, 24637, 11559,    62])tensor([   76, 18273, 26023,  3761, 26285, 26026])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([  706,    73, 10866, 11559,    62,  5467])\n",
            "tensor([18273, 26023, 14210, 26285, 26026,     1])context_tensors: \n",
            " tensor([   73, 10866, 24637,    62,  5467,    76])context_tensors: \n",
            "context_tensors:  tensor([26023, 14210,  3761, 26026,     1, 16501]) \n",
            "tensor([10866, 24637, 11559,  5467,    76, 27849])\n",
            "context_tensors: context_tensors:   tensor([24637, 11559,    62,    76, 27849,    79])tensor([14210,  3761, 26285,     1, 16501,     1])\n",
            "\n",
            "context_tensors:  tensor([11559,    62,  5467, 27849,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 3761, 26285, 26026, 16501,     1, 24420]) \n",
            "tensor([ 1411, 26026, 10365, 23934,  8228,    76])context_tensors:  tensor([26285, 26026,     1,     1, 24420, 12002])\n",
            "\n",
            "context_tensors:  tensor([26026,     1, 16501, 24420, 12002, 26023])\n",
            "context_tensors: context_tensors:   tensor([26026, 10365, 12380,  8228,    76,  2371])tensor([    1, 16501,     1, 12002, 26023,  2197])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([10365, 12380, 23934,    76,  2371, 18616]) tensor([16501,     1, 24420, 26023,  2197, 13495])\n",
            "context_tensors:  tensor([12380, 23934,  8228,  2371, 18616,  1423])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([    1, 24420, 12002,  2197, 13495, 26026])tensor([23934,  8228,    76, 18616,  1423,  4027])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([24420, 12002, 26023, 13495, 26026,  1410]) \n",
            "tensor([8228,   76, 2371, 1423, 4027, 1416])\n",
            "context_tensors: context_tensors:  tensor([   76,  2371, 18616,  4027,  1416,  2371]) tensor([12002, 26023,  2197, 26026,  1410, 24898])\n",
            "\n",
            "context_tensors:  tensor([ 2371, 18616,  1423,  1416,  2371,  1416])context_tensors:  tensor([26023,  2197, 13495,  1410, 24898,    72])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18616,  1423,  4027,  2371,  1416, 28190])\n",
            " tensor([ 2197, 13495, 26026, 24898,    72, 26049])\n",
            "context_tensors: context_tensors:   tensor([ 1423,  4027,  1416,  1416, 28190, 19698])tensor([13495, 26026,  1410,    72, 26049,  7490])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  1410, 24898, 26049,  7490,  1410])tensor([ 4027,  1416,  2371, 28190, 19698,  7495])\n",
            "\n",
            "context_tensors:  tensor([ 1410, 24898,    72,  7490,  1410,    73])context_tensors:  \n",
            "tensor([ 1416,  2371,  1416, 19698,  7495,   699])\n",
            "context_tensors: context_tensors:   tensor([24898,    72, 26049,  1410,    73,    79])tensor([ 2371,  1416, 28190,  7495,   699,  1410])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   72, 26049,  7490,    73,    79,  1409]) tensor([ 1416, 28190, 19698,   699,  1410, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 13448,   805, 15252,  2371, 28278]) \n",
            "context_tensors: tensor([28190, 19698,  7495,  1410, 26026, 28438])\n",
            " context_tensors:  tensor([13448,   805,    76,  2371, 28278, 28190])tensor([19698,  7495,   699, 26026, 28438,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 7495,   699,  1410, 28438,    79,  1409])tensor([  805,    76, 15252, 28278, 28190,  9195])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 13448,   715, 23615,  6320, 18559]) \n",
            "tensor([   76, 15252,  2371, 28190,  9195, 26026])context_tensors: \n",
            "context_tensors:   tensor([15252,  2371, 28278,  9195, 26026,  1410])tensor([13448,   715,    76,  6320, 18559, 19140])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([  715,    76, 23615, 18559, 19140, 18605]) tensor([ 2371, 28278, 28190, 26026,  1410, 12002])\n",
            "\n",
            "context_tensors:  tensor([   76, 23615,  6320, 19140, 18605, 26026])\n",
            "context_tensors:  tensor([28278, 28190,  9195,  1410, 12002, 26285])\n",
            "context_tensors:  tensor([23615,  6320, 18559, 18605, 26026, 25152])context_tensors: \n",
            " context_tensors:  tensor([28190,  9195, 26026, 12002, 26285, 26026])\n",
            "tensor([ 6320, 18559, 19140, 26026, 25152, 18520])context_tensors: \n",
            " tensor([ 9195, 26026,  1410, 26285, 26026, 21244])\n",
            "context_tensors: context_tensors:   tensor([18559, 19140, 18605, 25152, 18520, 26026])\n",
            "tensor([26026,  1410, 12002, 26026, 21244, 18520])context_tensors: \n",
            " tensor([19140, 18605, 26026, 18520, 26026, 23501])\n",
            "context_tensors:  tensor([ 1410, 12002, 26285, 21244, 18520, 11207])\n",
            "context_tensors:  tensor([18605, 26026, 25152, 26026, 23501, 22773])\n",
            "context_tensors: context_tensors:  tensor([12002, 26285, 26026, 18520, 11207, 11543])\n",
            " context_tensors: tensor([26026, 25152, 18520, 23501, 22773, 10866])\n",
            " tensor([26285, 26026, 21244, 11207, 11543,  2858])\n",
            "context_tensors:  tensor([25152, 18520, 26026, 22773, 10866, 26026])context_tensors:  \n",
            "tensor([26026, 21244, 18520, 11543,  2858, 17955])\n",
            "context_tensors: context_tensors:  tensor([18520, 26026, 23501, 10866, 26026,  3438])\n",
            " tensor([21244, 18520, 11207,  2858, 17955,    76])\n",
            "context_tensors: context_tensors:   tensor([18520, 11207, 11543, 17955,    76, 18605])tensor([26026, 23501, 22773, 26026,  3438, 10845])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23501, 22773, 10866,  3438, 10845,  3017])\n",
            "tensor([11207, 11543,  2858,    76, 18605, 26026])\n",
            "context_tensors:  context_tensors: tensor([11543,  2858, 17955, 18605, 26026,  3543]) \n",
            "tensor([22773, 10866, 26026, 10845,  3017, 24637])context_tensors: \n",
            " tensor([ 2858, 17955,    76, 26026,  3543, 18520])\n",
            "context_tensors:  tensor([10866, 26026,  3438,  3017, 24637,  2385])context_tensors: \n",
            " context_tensors: tensor([17955,    76, 18605,  3543, 18520, 17416]) \n",
            "tensor([26026,  3438, 10845, 24637,  2385,    62])context_tensors:  tensor([ 3438, 10845,  3017,  2385,    62,    76])\n",
            "\n",
            "tensor([10845,  3017, 24637,    62,    76, 24336])context_tensors:  \n",
            "context_tensors:  context_tensors: tensor([   76, 18605, 26026, 18520, 17416,  2371]) \n",
            "tensor([ 3017, 24637,  2385,    76, 24336,  7203])\n",
            "context_tensors:  context_tensors: tensor([24637,  2385,    62, 24336,  7203,    79]) \n",
            "context_tensors:  tensor([18605, 26026,  3543, 17416,  2371, 17262])tensor([2385,   62,   76, 7203,   79, 1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 23615,  7929, 22506, 10866, 26026])tensor([26026,  3543, 18520,  2371, 17262, 19714])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 3543, 18520, 17416, 17262, 19714,  9826]) \n",
            "tensor([23615,  7929,  3438, 10866, 26026, 27890])\n",
            "context_tensors:  context_tensors:  tensor([18520, 17416,  2371, 19714,  9826,    79])\n",
            "tensor([ 7929,  3438, 22506, 26026, 27890,  3725])context_tensors: \n",
            " tensor([17416,  2371, 17262,  9826,    79,  1409])context_tensors: \n",
            " tensor([ 3438, 22506, 10866, 27890,  3725, 26026])\n",
            "context_tensors:  tensor([ 1411, 13448,  1423, 19714,  2346,  3526])context_tensors: \n",
            " context_tensors:  tensor([22506, 10866, 26026,  3725, 26026, 10845])tensor([13448,  1423,   813,  2346,  3526, 18605])\n",
            "\n",
            "context_tensors:  tensor([ 1423,   813, 19714,  3526, 18605, 17175])context_tensors: \n",
            " context_tensors:  tensor([  813, 19714,  2346, 18605, 17175,  2371])tensor([10866, 26026, 27890, 26026, 10845, 13448])\n",
            "\n",
            "context_tensors:  tensor([19714,  2346,  3526, 17175,  2371, 18328])\n",
            "context_tensors: context_tensors:  tensor([ 2346,  3526, 18605,  2371, 18328,  8503])\n",
            " context_tensors: tensor([26026, 27890,  3725, 10845, 13448,   722]) \n",
            "tensor([ 3526, 18605, 17175, 18328,  8503,    76])\n",
            "context_tensors: context_tensors:  tensor([27890,  3725, 26026, 13448,   722,  2371]) \n",
            "tensor([18605, 17175,  2371,  8503,    76, 26026])\n",
            "context_tensors: context_tensors:  tensor([ 3725, 26026, 10845,   722,  2371,   743])\n",
            " tensor([17175,  2371, 18328,    76, 26026, 19866])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 18328,  8503, 26026, 19866, 16501])tensor([26026, 10845, 13448,  2371,   743,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18328,  8503,    76, 19866, 16501,  2371])\n",
            " tensor([10845, 13448,   722,   743,    79,  1409])context_tensors: \n",
            " tensor([ 8503,    76, 26026, 16501,  2371, 26026])context_tensors: \n",
            "context_tensors:   tensor([ 1411, 13448,   720, 23615,  6320, 26026])\n",
            "tensor([   76, 26026, 19866,  2371, 26026,  1410])\n",
            "context_tensors: context_tensors:   tensor([26026, 19866, 16501, 26026,  1410, 16501])tensor([13448,   720,    76,  6320, 26026,  1038])\n",
            "context_tensors: \n",
            " tensor([19866, 16501,  2371,  1410, 16501,    72])context_tensors:  tensor([  720,    76, 23615, 26026,  1038, 28544])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 23615,  6320,  1038, 28544,  1234]) \n",
            "tensor([16501,  2371, 26026, 16501,    72, 17711])\n",
            "context_tensors:  context_tensors: tensor([ 2371, 26026,  1410,    72, 17711,  1410])\n",
            " tensor([23615,  6320, 26026, 28544,  1234,  1410])\n",
            "context_tensors: context_tensors:   tensor([26026,  1410, 16501, 17711,  1410,    73])\n",
            "tensor([ 6320, 26026,  1038,  1234,  1410, 18559])\n",
            "context_tensors:  tensor([ 1410, 16501,    72,  1410,    73, 28115])context_tensors: \n",
            " tensor([26026,  1038, 28544,  1410, 18559, 19079])\n",
            "context_tensors:  context_tensors: tensor([16501,    72, 17711,    73, 28115, 10987])\n",
            " context_tensors: tensor([ 1038, 28544,  1234, 18559, 19079,    76]) \n",
            "tensor([   72, 17711,  1410, 28115, 10987, 26285])context_tensors: \n",
            " context_tensors: tensor([28544,  1234,  1410, 19079,    76, 18854]) \n",
            "tensor([17711,  1410,    73, 10987, 26285,  3623])context_tensors: \n",
            " context_tensors: tensor([ 1234,  1410, 18559,    76, 18854, 18520]) \n",
            "context_tensors: tensor([ 1410,    73, 28115, 26285,  3623, 26026]) \n",
            "tensor([ 1410, 18559, 19079, 18854, 18520, 11914])context_tensors:  \n",
            "tensor([   73, 28115, 10987,  3623, 26026, 17451])context_tensors: \n",
            " tensor([18559, 19079,    76, 18520, 11914,  1410])\n",
            "context_tensors: context_tensors:   tensor([19079,    76, 18854, 11914,  1410,    76])tensor([28115, 10987, 26285, 26026, 17451,  3519])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10987, 26285,  3623, 17451,  3519, 16785])\n",
            "tensor([   76, 18854, 18520,  1410,    76, 10866])\n",
            "context_tensors: context_tensors:   tensor([18854, 18520, 11914,    76, 10866, 26026])\n",
            "tensor([26285,  3623, 26026,  3519, 16785, 18520])context_tensors: \n",
            " tensor([18520, 11914,  1410, 10866, 26026, 16794])\n",
            "context_tensors: context_tensors:  tensor([11914,  1410,    76, 26026, 16794,  5467]) tensor([ 3623, 26026, 17451, 16785, 18520, 17955])\n",
            "context_tensors: \n",
            " tensor([ 1410,    76, 10866, 16794,  5467, 18520])\n",
            "context_tensors: context_tensors:   tensor([26026, 17451,  3519, 18520, 17955,    79])tensor([   76, 10866, 26026,  5467, 18520,  1410])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([17451,  3519, 16785, 17955,    79,  1409]) \n",
            "tensor([10866, 26026, 16794, 18520,  1410, 16905])context_tensors: \n",
            "context_tensors:  \n",
            "tensor([ 1411, 26026,  8459, 26026, 17711,  2454]) tensor([26026, 16794,  5467,  1410, 16905,  5715])context_tensors: \n",
            " context_tensors: tensor([26026,  8459, 18520, 17711,  2454, 15649]) tensor([16794,  5467, 18520, 16905,  5715,    79])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([ 8459, 18520, 26026,  2454, 15649, 27965])\n",
            "tensor([ 5467, 18520,  1410,  5715,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([18520, 26026, 17711, 15649, 27965,  9719]) \n",
            "tensor([ 1411, 10839, 26026, 18520, 12600, 23970])context_tensors: \n",
            " tensor([26026, 17711,  2454, 27965,  9719, 26285])context_tensors:  \n",
            "tensor([10839, 26026,  7548, 12600, 23970, 13448])\n",
            "context_tensors: context_tensors:  tensor([26026,  7548, 18520, 23970, 13448,   733]) \n",
            "tensor([17711,  2454, 15649,  9719, 26285, 12418])context_tensors:  tensor([ 7548, 18520, 12600, 13448,   733,    76])\n",
            "\n",
            "context_tensors:  tensor([18520, 12600, 23970,   733,    76,  3476])\n",
            "context_tensors: context_tensors:  tensor([ 2454, 15649, 27965, 26285, 12418, 18482])\n",
            " context_tensors: tensor([12600, 23970, 13448,    76,  3476,  3705])\n",
            "context_tensors:   tensor([23970, 13448,   733,  3476,  3705,  7933])tensor([15649, 27965,  9719, 12418, 18482, 28773])\n",
            "context_tensors: \n",
            " tensor([13448,   733,    76,  3705,  7933, 10866])context_tensors:  tensor([27965,  9719, 26285, 18482, 28773,  1142])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([ 9719, 26285, 12418, 28773,  1142, 16060]) tensor([  733,    76,  3476,  7933, 10866,  1423])\n",
            "\n",
            "context_tensors:  tensor([   76,  3476,  3705, 10866,  1423, 24671])context_tensors: \n",
            "context_tensors:   tensor([26285, 12418, 18482,  1142, 16060,    79])\n",
            "tensor([ 3476,  3705,  7933,  1423, 24671, 11676])\n",
            "context_tensors:  tensor([ 3705,  7933, 10866, 24671, 11676, 16794])\n",
            "context_tensors: context_tensors:  tensor([12418, 18482, 28773, 16060,    79,  1409]) tensor([ 7933, 10866,  1423, 11676, 16794, 28302])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([ 1411, 11258,    76, 13585, 23436, 13448])tensor([10866,  1423, 24671, 16794, 28302,  7849])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1423, 24671, 11676, 28302,  7849,  5667])tensor([11258,    76, 26026, 23436, 13448, 26026])\n",
            "context_tensors: \n",
            " context_tensors: tensor([24671, 11676, 16794,  7849,  5667, 20400])\n",
            " tensor([   76, 26026, 13585, 13448, 26026, 25101])context_tensors:  tensor([11676, 16794, 28302,  5667, 20400, 26285])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 13585, 23436, 26026, 25101, 24306])\n",
            " context_tensors: tensor([16794, 28302,  7849, 20400, 26285, 27966])\n",
            " context_tensors: tensor([13585, 23436, 13448, 25101, 24306, 14014]) \n",
            "tensor([28302,  7849,  5667, 26285, 27966, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 7849,  5667, 20400, 27966, 26026, 10372])\n",
            "tensor([23436, 13448, 26026, 24306, 14014, 26910])\n",
            "context_tensors: context_tensors:   tensor([ 5667, 20400, 26285, 26026, 10372, 18520])tensor([13448, 26026, 25101, 14014, 26910, 11522])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([20400, 26285, 27966, 10372, 18520, 12762]) \n",
            "tensor([26026, 25101, 24306, 26910, 11522,  8412])\n",
            "context_tensors:  context_tensors: tensor([26285, 27966, 26026, 18520, 12762,  8253]) tensor([25101, 24306, 14014, 11522,  8412,  5787])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([27966, 26026, 10372, 12762,  8253,    79]) \n",
            " \n",
            "context_tensors: tensor([24306, 14014, 26910,  8412,  5787,    76])tensor([26026, 10372, 18520,  8253,    79,  1409])context_tensors:  \n",
            "tensor([14014, 26910, 11522,  5787,    76, 25260])context_tensors: \n",
            " tensor([ 1411, 12600, 15252,  1416, 26046, 28438])context_tensors: \n",
            " tensor([26910, 11522,  8412,    76, 25260, 26023])context_tensors:  tensor([12600, 15252, 21789, 26046, 28438,    76])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([11522,  8412,  5787, 25260, 26023, 17711])\n",
            " context_tensors: tensor([15252, 21789,  1416, 28438,    76, 14210])\n",
            " tensor([ 8412,  5787,    76, 26023, 17711,  2454])\n",
            "context_tensors: context_tensors:  tensor([21789,  1416, 26046,    76, 14210, 27965])\n",
            " context_tensors: tensor([ 5787,    76, 25260, 17711,  2454, 14156]) tensor([ 1416, 26046, 28438, 14210, 27965, 13816])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26046, 28438,    76, 27965, 13816, 13448])\n",
            "tensor([   76, 25260, 26023,  2454, 14156,  1423])context_tensors:  \n",
            "context_tensors: tensor([28438,    76, 14210, 13816, 13448, 24637]) \n",
            "tensor([25260, 26023, 17711, 14156,  1423,  7235])context_tensors: \n",
            " context_tensors: tensor([   76, 14210, 27965, 13448, 24637,  9075])\n",
            " tensor([26023, 17711,  2454,  1423,  7235, 24420])context_tensors: \n",
            " context_tensors: tensor([14210, 27965, 13816, 24637,  9075,    62]) \n",
            "tensor([17711,  2454, 14156,  7235, 24420,  6326])context_tensors: \n",
            " context_tensors: tensor([27965, 13816, 13448,  9075,    62,    76]) tensor([ 2454, 14156,  1423, 24420,  6326,    79])\n",
            "context_tensors:  \n",
            "tensor([14156,  1423,  7235,  6326,    79,  1409])context_tensors:  tensor([13816, 13448, 24637,    62,    76, 19838])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 24637,  9075,    76, 19838,    76])\n",
            "tensor([ 1411, 26026, 26910, 24420, 28115,  9719])\n",
            "context_tensors:  context_tensors: tensor([24637,  9075,    62, 19838,    76, 13448]) tensor([26026, 26910,  1410, 28115,  9719, 26285])\n",
            "context_tensors: \n",
            " tensor([ 9075,    62,    76,    76, 13448,   743])context_tensors:  \n",
            "tensor([26910,  1410, 24420,  9719, 26285, 12418])\n",
            "context_tensors: context_tensors:   tensor([   62,    76, 19838, 13448,   743,    79])\n",
            "context_tensors:  tensor([ 1410, 24420, 28115, 26285, 12418,  8458])tensor([   76, 19838,    76,   743,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([24420, 28115,  9719, 12418,  8458, 28773])\n",
            "tensor([ 1411, 26026,  5614, 22750,  4240, 18520])\n",
            "context_tensors: context_tensors:  tensor([28115,  9719, 26285,  8458, 28773,  1038])\n",
            " tensor([26026,  5614, 28849,  4240, 18520, 13156])context_tensors: \n",
            " tensor([ 9719, 26285, 12418, 28773,  1038,  1417])context_tensors: \n",
            " context_tensors: tensor([ 5614, 28849, 22750, 18520, 13156,  1407]) \n",
            "tensor([26285, 12418,  8458,  1038,  1417,  1350])context_tensors: \n",
            " context_tensors:  tensor([28849, 22750,  4240, 13156,  1407,  4030])\n",
            "tensor([12418,  8458, 28773,  1417,  1350, 16060])\n",
            "context_tensors: context_tensors:   tensor([ 8458, 28773,  1038,  1350, 16060,  1407])\n",
            "tensor([22750,  4240, 18520,  1407,  4030,    76])\n",
            "context_tensors:  context_tensors: tensor([28773,  1038,  1417, 16060,  1407, 26026]) tensor([ 4240, 18520, 13156,  4030,    76,   699])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18520, 13156,  1407,    76,   699,  1407])tensor([ 1038,  1417,  1350,  1407, 26026,  1410])\n",
            "context_tensors: \n",
            " context_tensors: tensor([13156,  1407,  4030,   699,  1407,  1410]) \n",
            "tensor([ 1417,  1350, 16060, 26026,  1410,  9805])context_tensors:  tensor([1407, 4030,   76, 1407, 1410,   79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1350, 16060,  1407,  1410,  9805, 27965])tensor([4030,   76,  699, 1410,   79, 1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([16060,  1407, 26026,  9805, 27965, 15610])\n",
            " tensor([ 1411, 15736, 28435, 16094,    76,   742])context_tensors: \n",
            " context_tensors: tensor([ 1407, 26026,  1410, 27965, 15610, 26026]) tensor([15736, 28435,  1407,    76,   742,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28435,  1407, 16094,   742,    79,  1409])\n",
            "context_tensors:  tensor([26026,  1410,  9805, 15610, 26026, 24535]) \n",
            "tensor([ 1411, 26026, 11359,    62, 17809, 10856])context_tensors: \n",
            " tensor([ 1410,  9805, 27965, 26026, 24535, 18520])\n",
            "context_tensors:  context_tensors: tensor([ 9805, 27965, 15610, 24535, 18520, 26026]) tensor([26026, 11359, 28399, 17809, 10856, 25819])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11359, 28399,    62, 10856, 25819, 21961])tensor([27965, 15610, 26026, 18520, 26026,  2360])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([15610, 26026, 24535, 26026,  2360, 20128])\n",
            " tensor([28399,    62, 17809, 25819, 21961, 26026])\n",
            "context_tensors: context_tensors:   tensor([   62, 17809, 10856, 21961, 26026, 11359])\n",
            "tensor([26026, 24535, 18520,  2360, 20128,  4787])context_tensors: \n",
            " context_tensors: tensor([17809, 10856, 25819, 26026, 11359, 13448])\n",
            " tensor([24535, 18520, 26026, 20128,  4787,  5976])context_tensors:  \n",
            "tensor([10856, 25819, 21961, 11359, 13448, 13952])context_tensors:  tensor([18520, 26026,  2360,  4787,  5976,  5448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,  2360, 20128,  5976,  5448,    79])\n",
            " tensor([25819, 21961, 26026, 13448, 13952, 10856])\n",
            "context_tensors: context_tensors:   tensor([ 2360, 20128,  4787,  5448,    79,  1409])\n",
            "tensor([21961, 26026, 11359, 13952, 10856,  6297])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26026, 19420,  8244, 18520, 26026]) \n",
            "tensor([26026, 11359, 13448, 10856,  6297,    79])\n",
            "context_tensors:  tensor([11359, 13448, 13952,  6297,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 25819, 13007,    76, 12380])tensor([26026, 19420, 10538, 18520, 26026, 19866])\n",
            "context_tensors: \n",
            " context_tensors: tensor([26026, 25819,    76,    76, 12380, 18253]) tensor([19420, 10538,  8244, 26026, 19866, 16501])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([25819,    76, 13007, 12380, 18253,  6292]) \n",
            "tensor([10538,  8244, 18520, 19866, 16501, 14156])context_tensors:  \n",
            "tensor([   76, 13007,    76, 18253,  6292, 13448])context_tensors: \n",
            " context_tensors: tensor([ 8244, 18520, 26026, 16501, 14156, 26097])\n",
            " tensor([13007,    76, 12380,  6292, 13448,  1423])\n",
            "context_tensors: context_tensors:   tensor([   76, 12380, 18253, 13448,  1423, 16537])\n",
            "tensor([18520, 26026, 19866, 14156, 26097,  2371])\n",
            "context_tensors:  context_tensors: tensor([12380, 18253,  6292,  1423, 16537, 21473]) \n",
            "tensor([26026, 19866, 16501, 26097,  2371,  8080])context_tensors:  \n",
            "tensor([18253,  6292, 13448, 16537, 21473,  4787])context_tensors:  \n",
            "tensor([19866, 16501, 14156,  2371,  8080,  1416])context_tensors:  \n",
            "tensor([ 6292, 13448,  1423, 21473,  4787, 10484])context_tensors: \n",
            " tensor([16501, 14156, 26097,  8080,  1416, 23586])context_tensors:  \n",
            "tensor([13448,  1423, 16537,  4787, 10484,    76])\n",
            "context_tensors: context_tensors:   tensor([14156, 26097,  2371,  1416, 23586, 28356])tensor([ 1423, 16537, 21473, 10484,    76, 26026])\n",
            "\n",
            "context_tensors:  tensor([16537, 21473,  4787,    76, 26026, 24560])\n",
            "context_tensors:  tensor([26097,  2371,  8080, 23586, 28356, 17784])context_tensors: \n",
            " context_tensors:  tensor([21473,  4787, 10484, 26026, 24560,    62])tensor([ 2371,  8080,  1416, 28356, 17784, 22603])\n",
            "\n",
            "context_tensors:  tensor([ 4787, 10484,    76, 24560,    62, 13952])\n",
            "context_tensors: context_tensors:  tensor([ 8080,  1416, 23586, 17784, 22603, 18867]) \n",
            "tensor([10484,    76, 26026,    62, 13952, 11806])\n",
            "context_tensors: context_tensors:   tensor([ 1416, 23586, 28356, 22603, 18867,  6856])tensor([   76, 26026, 24560, 13952, 11806,  4164])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 24560,    62, 11806,  4164,    76])\n",
            "tensor([23586, 28356, 17784, 18867,  6856,    76])context_tensors:  tensor([24560,    62, 13952,  4164,    76,  7949])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   62, 13952, 11806,    76,  7949, 26023])tensor([28356, 17784, 22603,  6856,    76, 16704])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13952, 11806,  4164,  7949, 26023, 18741]) \n",
            "tensor([17784, 22603, 18867,    76, 16704,   117])context_tensors: \n",
            " context_tensors: tensor([11806,  4164,    76, 26023, 18741, 28399]) \n",
            "tensor([22603, 18867,  6856, 16704,   117,  1417])\n",
            "context_tensors: context_tensors:   tensor([ 4164,    76,  7949, 18741, 28399,    62])tensor([18867,  6856,    76,   117,  1417,   117])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6856,    76, 16704,  1417,   117, 28846])tensor([   76,  7949, 26023, 28399,    62, 10856])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 16704,   117,   117, 28846,   117]) \n",
            "tensor([ 7949, 26023, 18741,    62, 10856, 12380])context_tensors: \n",
            " tensor([16704,   117,  1417, 28846,   117,  1417])context_tensors:  \n",
            "tensor([26023, 18741, 28399, 10856, 12380,  3686])context_tensors: \n",
            " context_tensors: tensor([ 117, 1417,  117,  117, 1417,  942])\n",
            " tensor([18741, 28399,    62, 12380,  3686, 19921])context_tensors: \n",
            " context_tensors: tensor([ 1417,   117, 28846,  1417,   942, 26237]) \n",
            "context_tensors:  tensor([28399,    62, 10856,  3686, 19921, 13448])tensor([  117, 28846,   117,   942, 26237, 15839])\n",
            "\n",
            "context_tensors:  tensor([28846,   117,  1417, 26237, 15839, 26015])context_tensors: \n",
            "context_tensors:  tensor([   62, 10856, 12380, 19921, 13448, 26026]) tensor([  117,  1417,   942, 15839, 26015, 28220])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10856, 12380,  3686, 13448, 26026,  6975])\n",
            "tensor([ 1417,   942, 26237, 26015, 28220,    79])\n",
            "context_tensors:  context_tensors:  tensor([12380,  3686, 19921, 26026,  6975, 23934])tensor([  942, 26237, 15839, 28220,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3686, 19921, 13448,  6975, 23934,   785])\n",
            " tensor([ 1411, 26026, 15342, 18520, 26026,  8244])context_tensors:  \n",
            "tensor([19921, 13448, 26026, 23934,   785,    79])\n",
            "context_tensors: context_tensors:   tensor([13448, 26026,  6975,   785,    79,  1409])tensor([26026, 15342, 16388, 26026,  8244,  2733])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([15342, 16388, 18520,  8244,  2733, 11540])tensor([ 1411, 26026, 11359, 26910, 28668, 25824])\n",
            "\n",
            "context_tensors:  tensor([26026, 11359, 12380, 28668, 25824,    76])\n",
            "context_tensors: context_tensors:   tensor([11359, 12380, 26910, 25824,    76,  2334])tensor([16388, 18520, 26026,  2733, 11540,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12380, 26910, 28668,    76,  2334, 27053])tensor([18520, 26026,  8244, 11540,  1410,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  8244,  2733,  1410,  2371,  6759])\n",
            "tensor([26910, 28668, 25824,  2334, 27053,  1416])context_tensors: \n",
            " context_tensors: tensor([ 8244,  2733, 11540,  2371,  6759,  3017]) \n",
            "tensor([28668, 25824,    76, 27053,  1416,   460])context_tensors: \n",
            " context_tensors: tensor([ 2733, 11540,  1410,  6759,  3017,  1423]) \n",
            "tensor([25824,    76,  2334,  1416,   460, 23836])context_tensors: \n",
            " tensor([11540,  1410,  2371,  3017,  1423,  4537])context_tensors: \n",
            " context_tensors: tensor([   76,  2334, 27053,   460, 23836, 26023]) \n",
            "tensor([1410, 2371, 6759, 1423, 4537, 2408])\n",
            "context_tensors: context_tensors:  tensor([ 2371,  6759,  3017,  4537,  2408, 26285]) \n",
            "tensor([ 2334, 27053,  1416, 23836, 26023, 12380])context_tensors: \n",
            " context_tensors:  tensor([ 6759,  3017,  1423,  2408, 26285, 26026])tensor([27053,  1416,   460, 26023, 12380,  6292])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3017,  1423,  4537, 26285, 26026, 20011])tensor([ 1416,   460, 23836, 12380,  6292, 13448])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423,  4537,  2408, 26026, 20011, 26253])tensor([  460, 23836, 26023,  6292, 13448, 10484])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4537,  2408, 26285, 20011, 26253, 18520])tensor([23836, 26023, 12380, 13448, 10484, 26943])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26023, 12380,  6292, 10484, 26943,  1416])tensor([ 2408, 26285, 26026, 26253, 18520, 26026])\n",
            "\n",
            "context_tensors:  tensor([12380,  6292, 13448, 26943,  1416,   460])\n",
            "context_tensors: context_tensors:   tensor([26285, 26026, 20011, 18520, 26026, 24164])tensor([ 6292, 13448, 10484,  1416,   460, 28399])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([13448, 10484, 26943,   460, 28399,    62]) \n",
            "tensor([26026, 20011, 26253, 26026, 24164,    79])context_tensors: \n",
            " context_tensors: tensor([10484, 26943,  1416, 28399,    62, 28452]) \n",
            "tensor([20011, 26253, 18520, 24164,    79,  1409])context_tensors: \n",
            " tensor([26943,  1416,   460,    62, 28452,  7287])context_tensors: \n",
            " tensor([ 1411, 26026, 24115,  2733, 19855,  5917])context_tensors: \n",
            " context_tensors:  tensor([ 1416,   460, 28399, 28452,  7287, 21005])tensor([26026, 24115, 10110, 19855,  5917, 26301])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24115, 10110,  2733,  5917, 26301,    76])tensor([  460, 28399,    62,  7287, 21005,    76])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([10110,  2733, 19855, 26301,    76,  2371]) \n",
            "tensor([28399,    62, 28452, 21005,    76,  2371])context_tensors: \n",
            " context_tensors: tensor([ 2733, 19855,  5917,    76,  2371,  3725]) \n",
            "tensor([   62, 28452,  7287,    76,  2371,  2334])context_tensors: \n",
            " context_tensors: tensor([19855,  5917, 26301,  2371,  3725, 26042]) \n",
            "tensor([28452,  7287, 21005,  2371,  2334, 27053])\n",
            "context_tensors:  tensor([ 5917, 26301,    76,  3725, 26042,  2733])context_tensors: \n",
            " context_tensors:  tensor([26301,    76,  2371, 26042,  2733, 26026])tensor([ 7287, 21005,    76,  2334, 27053,  1416])\n",
            "\n",
            "context_tensors:  tensor([21005,    76,  2371, 27053,  1416,   664])\n",
            "context_tensors: context_tensors:   tensor([   76,  2371,  2334,  1416,   664, 23836])tensor([   76,  2371,  3725,  2733, 26026, 24505])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2371,  3725, 26042, 26026, 24505,    79])\n",
            "context_tensors: tensor([ 2371,  2334, 27053,   664, 23836, 26023]) tensor([ 3725, 26042,  2733, 24505,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 2334, 27053,  1416, 23836, 26023, 28362])\n",
            "context_tensors:  tensor([27053,  1416,   664, 26023, 28362, 11158])\n",
            "context_tensors:  tensor([ 1411, 26026, 18251,  9242,  2371, 12418])\n",
            "tensor([ 1416,   664, 23836, 28362, 11158, 21666])\n",
            "context_tensors: context_tensors:  tensor([  664, 23836, 26023, 11158, 21666, 21005])\n",
            " tensor([26026, 18251,  2733,  2371, 12418,  1423])context_tensors:  tensor([23836, 26023, 28362, 21666, 21005, 10866])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26023, 28362, 11158, 21005, 10866,  2334]) \n",
            "context_tensors:  tensor([28362, 11158, 21666, 10866,  2334, 27053])\n",
            "tensor([18251,  2733,  9242, 12418,  1423, 24027])\n",
            "context_tensors: context_tensors:  tensor([11158, 21666, 21005,  2334, 27053,  1416]) \n",
            "tensor([ 2733,  9242,  2371,  1423, 24027,  1416])context_tensors: \n",
            " context_tensors:  tensor([21666, 21005, 10866, 27053,  1416,   664])tensor([ 9242,  2371, 12418, 24027,  1416, 23586])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2371, 12418,  1423,  1416, 23586, 10677]) tensor([21005, 10866,  2334,  1416,   664, 28452])\n",
            "\n",
            "context_tensors:  tensor([10866,  2334, 27053,   664, 28452,  7287])\n",
            "context_tensors: context_tensors:   tensor([ 2334, 27053,  1416, 28452,  7287,    79])\n",
            "tensor([12418,  1423, 24027, 23586, 10677, 18520])context_tensors: \n",
            " context_tensors: tensor([27053,  1416,   664,  7287,    79,  1409])\n",
            " tensor([ 1423, 24027,  1416, 10677, 18520, 24022])\n",
            "context_tensors:  tensor([ 1411, 26026,  8016,  1423, 17809, 25819])\n",
            "context_tensors: context_tensors:   tensor([24027,  1416, 23586, 18520, 24022,  3886])\n",
            "tensor([26026,  8016, 18520, 17809, 25819, 10138])\n",
            "context_tensors: context_tensors:  tensor([ 8016, 18520,  1423, 25819, 10138,  5417]) \n",
            "tensor([ 1416, 23586, 10677, 24022,  3886, 26042])\n",
            "context_tensors:  context_tensors:  tensor([23586, 10677, 18520,  3886, 26042,    79])tensor([18520,  1423, 17809, 10138,  5417, 23904])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([10677, 18520, 24022, 26042,    79,  1409]) \n",
            "tensor([ 1423, 17809, 25819,  5417, 23904, 26285])\n",
            "context_tensors:  context_tensors:  tensor([ 1411, 26026, 24115,  3645, 20645,  1410])tensor([17809, 25819, 10138, 23904, 26285, 26131])\n",
            "context_tensors:  \n",
            "tensor([26026, 24115, 17507, 20645,  1410,  3017])context_tensors:  \n",
            "context_tensors: tensor([25819, 10138,  5417, 26285, 26131,  1657]) \n",
            "tensor([24115, 17507,  3645,  1410,  3017, 26026])context_tensors: \n",
            " context_tensors: tensor([10138,  5417, 23904, 26131,  1657,  1891]) \n",
            "tensor([17507,  3645, 20645,  3017, 26026,  6856])context_tensors: \n",
            " context_tensors: tensor([ 5417, 23904, 26285,  1657,  1891,    76])\n",
            " tensor([ 3645, 20645,  1410, 26026,  6856,  2371])\n",
            "context_tensors:  tensor([20645,  1410,  3017,  6856,  2371,  6660])\n",
            "context_tensors: context_tensors:  tensor([ 1410,  3017, 26026,  2371,  6660, 26910])\n",
            " tensor([23904, 26285, 26131,  1891,    76,  2217])context_tensors: \n",
            " tensor([ 3017, 26026,  6856,  6660, 26910, 24065])context_tensors:  \n",
            "tensor([26285, 26131,  1657,    76,  2217, 26026])context_tensors: \n",
            " context_tensors: tensor([26026,  6856,  2371, 26910, 24065, 19161]) tensor([26131,  1657,  1891,  2217, 26026, 17809])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 6856,  2371,  6660, 24065, 19161, 18605]) tensor([ 1657,  1891,    76, 26026, 17809, 10856])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1891,    76,  2217, 17809, 10856,  2966])tensor([ 2371,  6660, 26910, 19161, 18605, 26026])\n",
            "\n",
            "context_tensors:  tensor([   76,  2217, 26026, 10856,  2966, 12380])context_tensors: \n",
            " context_tensors: tensor([ 6660, 26910, 24065, 18605, 26026, 10758]) \n",
            "tensor([ 2217, 26026, 17809,  2966, 12380, 10996])\n",
            "context_tensors: context_tensors:  tensor([26910, 24065, 19161, 26026, 10758,    79]) tensor([26026, 17809, 10856, 12380, 10996, 24656])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17809, 10856,  2966, 10996, 24656, 16785])\n",
            "tensor([24065, 19161, 18605, 10758,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 24115, 19161,  2197, 10987,  2806])\n",
            "tensor([10856,  2966, 12380, 24656, 16785, 10817])\n",
            "context_tensors: context_tensors:   tensor([24115, 19161,  2733, 10987,  2806, 26026])tensor([ 2966, 12380, 10996, 16785, 10817, 18605])\n",
            "\n",
            "context_tensors:  tensor([19161,  2733,  2197,  2806, 26026, 18904])context_tensors: \n",
            " tensor([12380, 10996, 24656, 10817, 18605, 28399])context_tensors: \n",
            " tensor([ 2733,  2197, 10987, 26026, 18904, 18520])context_tensors: \n",
            " tensor([10996, 24656, 16785, 18605, 28399,    62])context_tensors: \n",
            " tensor([ 2197, 10987,  2806, 18904, 18520, 26026])context_tensors:  tensor([24656, 16785, 10817, 28399,    62, 10856])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16785, 10817, 18605,    62, 10856,    79])\n",
            "tensor([10987,  2806, 26026, 18520, 26026, 17507])\n",
            "context_tensors: context_tensors:  tensor([10817, 18605, 28399, 10856,    79,  1409]) \n",
            "context_tensors: tensor([ 2806, 26026, 18904, 26026, 17507,    79]) \n",
            "tensor([ 1411, 13448,   770, 10446,  6974, 12153])context_tensors: \n",
            " context_tensors: tensor([26026, 18904, 18520, 17507,    79,  1409])\n",
            " tensor([13448,   770,    76,  6974, 12153, 28399])\n",
            "context_tensors:  tensor([ 1411, 26069,  2733, 19085, 18520, 11629])\n",
            "context_tensors: context_tensors:  tensor([  770,    76, 10446, 12153, 28399,    62])\n",
            " tensor([26069,  2733, 10648, 18520, 11629, 24086])context_tensors: \n",
            " context_tensors:  tensor([   76, 10446,  6974, 28399,    62, 17809])tensor([ 2733, 10648, 19085, 11629, 24086,    79])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([10648, 19085, 18520, 24086,    79,  1409])tensor([10446,  6974, 12153,    62, 17809, 10856])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26026, 19440,  2733, 10180, 15230]) \n",
            "tensor([ 6974, 12153, 28399, 17809, 10856, 25824])\n",
            "context_tensors: context_tensors:  tensor([26026, 19440, 10586, 10180, 15230,  2371])\n",
            " tensor([12153, 28399,    62, 10856, 25824,    79])context_tensors: \n",
            " tensor([19440, 10586,  2733, 15230,  2371, 20011])\n",
            "context_tensors: context_tensors:   tensor([10586,  2733, 10180,  2371, 20011,    79])tensor([28399,    62, 17809, 25824,    79,  1409])\n",
            "\n",
            "context_tensors:  tensor([ 2733, 10180, 15230, 20011,    79,  1409])\n",
            "context_tensors:  tensor([ 1411, 28179, 26026, 11313, 20123, 28455])\n",
            "context_tensors:  tensor([ 1411, 26026, 25674, 23735,    76,  3468])\n",
            "context_tensors:  tensor([26026, 25674, 14156,    76,  3468,  9871])\n",
            "context_tensors: context_tensors:   tensor([28179, 26026, 24560, 20123, 28455, 13448])tensor([25674, 14156, 23735,  3468,  9871, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([14156, 23735,    76,  9871, 26026, 15447]) \n",
            "tensor([26026, 24560, 11313, 28455, 13448, 15261])\n",
            "context_tensors: context_tensors:   tensor([24560, 11313, 20123, 13448, 15261,  7567])tensor([23735,    76,  3468, 26026, 15447, 18520])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11313, 20123, 28455, 15261,  7567,    76])tensor([   76,  3468,  9871, 15447, 18520, 26026])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([ 3468,  9871, 26026, 18520, 26026,  8244])tensor([20123, 28455, 13448,  7567,    76, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 9871, 26026, 15447, 26026,  8244, 28165]) \n",
            "tensor([28455, 13448, 15261,    76, 26026, 11359])\n",
            "context_tensors:  context_tensors: tensor([26026, 15447, 18520,  8244, 28165, 13871])\n",
            " tensor([13448, 15261,  7567, 26026, 11359,    62])context_tensors: \n",
            " context_tensors:  tensor([15447, 18520, 26026, 28165, 13871,    76])\n",
            "tensor([15261,  7567,    76, 11359,    62, 17809])\n",
            "context_tensors: context_tensors:   tensor([ 7567,    76, 26026,    62, 17809, 25819])tensor([18520, 26026,  8244, 13871,    76,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  8244, 28165,    76,  2371, 12380])\n",
            "tensor([   76, 26026, 11359, 17809, 25819, 18616])context_tensors: \n",
            " tensor([ 8244, 28165, 13871,  2371, 12380,  1423])context_tensors: \n",
            " context_tensors: tensor([26026, 11359,    62, 25819, 18616, 19921]) \n",
            "tensor([28165, 13871,    76, 12380,  1423,  4537])context_tensors:  \n",
            "tensor([11359,    62, 17809, 18616, 19921, 14227])context_tensors: \n",
            " tensor([13871,    76,  2371,  1423,  4537,  2371])context_tensors: \n",
            " context_tensors:  tensor([   62, 17809, 25819, 19921, 14227, 10609])tensor([   76,  2371, 12380,  4537,  2371, 10691])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2371, 12380,  1423,  2371, 10691,  3524])\n",
            " context_tensors:  tensor([12380,  1423,  4537, 10691,  3524, 15342])\n",
            "tensor([17809, 25819, 18616, 14227, 10609, 11365])\n",
            "context_tensors:  context_tensors:  tensor([25819, 18616, 19921, 10609, 11365, 13448])\n",
            "tensor([ 1423,  4537,  2371,  3524, 15342, 26285])context_tensors: \n",
            " context_tensors:  tensor([ 4537,  2371, 10691, 15342, 26285, 27365])\n",
            "tensor([18616, 19921, 14227, 11365, 13448,   804])context_tensors: \n",
            "context_tensors:  tensor([ 2371, 10691,  3524, 26285, 27365, 26910]) \n",
            "tensor([19921, 14227, 10609, 13448,   804,    79])context_tensors: context_tensors: \n",
            " tensor([14227, 10609, 11365,   804,    79,  1409]) \n",
            "tensor([10691,  3524, 15342, 27365, 26910,  1410])context_tensors: \n",
            " tensor([ 1411, 26023, 11365, 18253, 10484,  1416])context_tensors: \n",
            " tensor([ 3524, 15342, 26285, 26910,  1410, 24497])context_tensors:  tensor([26023, 11365, 27965, 10484,  1416, 21473])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([11365, 27965, 18253,  1416, 21473,    79])tensor([15342, 26285, 27365,  1410, 24497,    79])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([27965, 18253, 10484, 21473,    79,  1409])\n",
            "context_tensors: tensor([26285, 27365, 26910, 24497,    79,  1409]) \n",
            "tensor([ 1411,  2858, 18520,   813,    76, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 1411,  1900, 26026,    76, 26026, 25674])tensor([ 2858, 18520, 16366,    76, 26026, 25819])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1900, 26026, 24900, 26026, 25674,  3673]) \n",
            "tensor([18520, 16366,   813, 26026, 25819, 27965])\n",
            "context_tensors: context_tensors:   tensor([16366,   813,    76, 25819, 27965, 27224])tensor([26026, 24900,    76, 25674,  3673, 24065])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([  813,    76, 26026, 27965, 27224,  4787]) \n",
            "tensor([24900,    76, 26026,  3673, 24065,  2371])\n",
            "context_tensors: context_tensors:   tensor([   76, 26026, 25819, 27224,  4787, 10484])\n",
            "tensor([   76, 26026, 25674, 24065,  2371,  3645])context_tensors:  \n",
            "tensor([26026, 25819, 27965,  4787, 10484,    76])\n",
            "context_tensors: context_tensors:  tensor([25819, 27965, 27224, 10484,    76,  2371]) \n",
            "tensor([26026, 25674,  3673,  2371,  3645,  1423])context_tensors: \n",
            " context_tensors: tensor([27965, 27224,  4787,    76,  2371,  2858]) tensor([25674,  3673, 24065,  3645,  1423, 15837])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3673, 24065,  2371,  1423, 15837, 27537])\n",
            "tensor([27224,  4787, 10484,  2371,  2858, 18520])\n",
            "context_tensors: context_tensors:   tensor([24065,  2371,  3645, 15837, 27537, 10538])tensor([ 4787, 10484,    76,  2858, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371,  3645,  1423, 27537, 10538, 10823])tensor([10484,    76,  2371, 18520, 26026, 10839])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3645,  1423, 15837, 10538, 10823,  2371])tensor([   76,  2371,  2858, 26026, 10839, 17352])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2371,  2858, 18520, 10839, 17352, 26026]) \n",
            "tensor([ 1423, 15837, 27537, 10823,  2371,  1423])\n",
            "context_tensors: context_tensors:  tensor([15837, 27537, 10538,  2371,  1423, 17546])\n",
            " tensor([ 2858, 18520, 26026, 17352, 26026, 11359])context_tensors:  \n",
            "tensor([27537, 10538, 10823,  1423, 17546, 23741])context_tensors:  \n",
            "tensor([18520, 26026, 10839, 26026, 11359, 12153])context_tensors: \n",
            " context_tensors: tensor([10538, 10823,  2371, 17546, 23741,    76])\n",
            " context_tensors: tensor([26026, 10839, 17352, 11359, 12153, 18253]) tensor([10823,  2371,  1423, 23741,    76, 15925])\n",
            "context_tensors:  tensor([ 2371,  1423, 17546,    76, 15925,  8628])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 1423, 17546, 23741, 15925,  8628, 10538])tensor([10839, 17352, 26026, 12153, 18253, 19921])\n",
            "context_tensors: \n",
            " context_tensors: tensor([17546, 23741,    76,  8628, 10538, 10823]) \n",
            "tensor([17352, 26026, 11359, 18253, 19921, 13448])\n",
            "context_tensors:   \n",
            "context_tensors: tensor([23741,    76, 15925, 10538, 10823,    79])tensor([26026, 11359, 12153, 19921, 13448,  1423])context_tensors: \n",
            " context_tensors:  tensor([   76, 15925,  8628, 10823,    79,  1409])\n",
            "tensor([11359, 12153, 18253, 13448,  1423, 10484]) context_tensors: tensor([ 1411, 17451, 18520,  4164, 15122,  7895])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17451, 18520, 26026, 15122,  7895,  7818])tensor([12153, 18253, 19921,  1423, 10484,  1416])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18253, 19921, 13448, 10484,  1416, 22888])tensor([18520, 26026,  4164,  7895,  7818,  1407])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([19921, 13448,  1423,  1416, 22888, 16537])tensor([26026,  4164, 15122,  7818,  1407,  1423])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 4164, 15122,  7895,  1407,  1423, 16979])\n",
            "context_tensors: tensor([13448,  1423, 10484, 22888, 16537,    79])\n",
            " context_tensors: tensor([15122,  7895,  7818,  1423, 16979, 22618]) \n",
            "tensor([ 1423, 10484,  1416, 16537,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([ 7895,  7818,  1407, 16979, 22618, 18520])\n",
            " context_tensors:  tensor([ 1411, 26026, 25819, 18253, 19251, 13448])\n",
            "tensor([ 7818,  1407,  1423, 22618, 18520,  1038])context_tensors: \n",
            "context_tensors:   tensor([26026, 25819, 12380, 19251, 13448, 16187])tensor([ 1407,  1423, 16979, 18520,  1038, 28846])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 16979, 22618,  1038, 28846,   280])\n",
            "tensor([25819, 12380, 18253, 13448, 16187, 21666])context_tensors:  tensor([16979, 22618, 18520, 28846,   280, 24115])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([22618, 18520,  1038,   280, 24115,    76]) \n",
            "context_tensors: tensor([12380, 18253, 19251, 16187, 21666,  2371])\n",
            " context_tensors:  tensor([18253, 19251, 13448, 21666,  2371, 13952])tensor([18520,  1038, 28846, 24115,    76,  5919])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 1038, 28846,   280,    76,  5919, 24367])\n",
            " tensor([19251, 13448, 16187,  2371, 13952, 26432])context_tensors:  \n",
            "tensor([28846,   280, 24115,  5919, 24367, 26125])\n",
            "context_tensors: context_tensors:   tensor([13448, 16187, 21666, 13952, 26432,    76])tensor([  280, 24115,    76, 24367, 26125, 14156])\n",
            "\n",
            "context_tensors:  tensor([16187, 21666,  2371, 26432,    76, 13497])context_tensors:  \n",
            "tensor([24115,    76,  5919, 26125, 14156, 20414])\n",
            "context_tensors:  tensor([21666,  2371, 13952,    76, 13497, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 13952, 26432, 13497, 26026, 28399])tensor([   76,  5919, 24367, 14156, 20414,  3725])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13952, 26432,    76, 26026, 28399,    62])tensor([ 5919, 24367, 26125, 20414,  3725, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([24367, 26125, 14156,  3725, 26026, 24505]) \n",
            "tensor([26432,    76, 13497, 28399,    62, 28452])context_tensors:  \n",
            "tensor([26125, 14156, 20414, 26026, 24505,    76])\n",
            "context_tensors:  context_tensors: tensor([14156, 20414,  3725, 24505,    76,  2371]) tensor([   76, 13497, 26026,    62, 28452,  7287])\n",
            "\n",
            "context_tensors:  tensor([20414,  3725, 26026,    76,  2371,  2475])\n",
            "context_tensors: context_tensors:   tensor([ 3725, 26026, 24505,  2371,  2475, 22618])tensor([13497, 26026, 28399, 28452,  7287,    76])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 24505,    76,  2475, 22618, 18520])\n",
            " tensor([26026, 28399,    62,  7287,    76, 26026])context_tensors: \n",
            " tensor([24505,    76,  2371, 22618, 18520,    86])\n",
            "context_tensors:  tensor([   76,  2371,  2475, 18520,    86, 28846])\n",
            "context_tensors: context_tensors:   tensor([28399,    62, 28452,    76, 26026,   810])tensor([ 2371,  2475, 22618,    86, 28846,  1038])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   62, 28452,  7287, 26026,   810,  1893])\n",
            "tensor([ 2475, 22618, 18520, 28846,  1038, 26125])context_tensors:  tensor([28452,  7287,    76,   810,  1893, 28399])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 7287,    76, 26026,  1893, 28399,    62]) \n",
            "tensor([22618, 18520,    86,  1038, 26125,  3698])context_tensors: \n",
            " tensor([   76, 26026,   810, 28399,    62,  5430])\n",
            "context_tensors:  context_tensors:  tensor([18520,    86, 28846, 26125,  3698, 26026])tensor([26026,   810,  1893,    62,  5430, 18691])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   86, 28846,  1038,  3698, 26026, 24900])\n",
            "tensor([  810,  1893, 28399,  5430, 18691, 26026])context_tensors: \n",
            " tensor([28846,  1038, 26125, 26026, 24900,    79])\n",
            "context_tensors:  context_tensors: tensor([ 1893, 28399,    62, 18691, 26026,   812]) \n",
            "context_tensors: tensor([ 1038, 26125,  3698, 24900,    79,  1409]) \n",
            "tensor([28399,    62,  5430, 26026,   812,  2128])\n",
            "context_tensors: context_tensors:   tensor([   62,  5430, 18691,   812,  2128,  1416])\n",
            "tensor([ 1411, 26026,  8628, 14156, 11908, 11927])context_tensors:  tensor([ 5430, 18691, 26026,  2128,  1416,  1891])\n",
            "context_tensors: \n",
            "context_tensors:  tensor([18691, 26026,   812,  1416,  1891, 11372])\n",
            "context_tensors:  tensor([26026,  8628,  6117, 11908, 11927,    76])\n",
            " context_tensors: tensor([26026,   812,  2128,  1891, 11372,    79])\n",
            " context_tensors:  tensor([  812,  2128,  1416, 11372,    79,  1409])\n",
            "tensor([ 8628,  6117, 14156, 11927,    76,  3674])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026,  6975, 18253, 12418,  1423])\n",
            " context_tensors: tensor([ 6117, 14156, 11908,    76,  3674, 19796]) tensor([26026,  6975,  8109, 12418,  1423, 10484])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 6975,  8109, 18253,  1423, 10484,  1416])\n",
            " tensor([14156, 11908, 11927,  3674, 19796, 26438])context_tensors:  tensor([ 8109, 18253, 12418, 10484,  1416, 21473])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([18253, 12418,  1423,  1416, 21473, 28668])\n",
            "context_tensors: tensor([11908, 11927,    76, 19796, 26438, 26026])\n",
            " tensor([12418,  1423, 10484, 21473, 28668, 17809])\n",
            "context_tensors: context_tensors:   tensor([11927,    76,  3674, 26438, 26026,  8244])tensor([ 1423, 10484,  1416, 28668, 17809, 25819])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([   76,  3674, 19796, 26026,  8244, 16388])\n",
            "context_tensors: tensor([10484,  1416, 21473, 17809, 25819, 27255]) tensor([ 3674, 19796, 26438,  8244, 16388,  1407])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1416, 21473, 28668, 25819, 27255,   813])tensor([19796, 26438, 26026, 16388,  1407, 26069])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([21473, 28668, 17809, 27255,   813,    76])tensor([26438, 26026,  8244,  1407, 26069, 14156])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28668, 17809, 25819,   813,    76, 28165])\n",
            "tensor([26026,  8244, 16388, 26069, 14156,  1423])\n",
            "context_tensors:  context_tensors:  tensor([ 8244, 16388,  1407, 14156,  1423,  7468])tensor([17809, 25819, 27255,    76, 28165, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16388,  1407, 26069,  1423,  7468, 16499])tensor([25819, 27255,   813, 28165, 26026, 11359])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([27255,   813,    76, 26026, 11359, 27053])\n",
            "tensor([ 1407, 26069, 14156,  7468, 16499,  1416])context_tensors: \n",
            " tensor([  813,    76, 28165, 11359, 27053,  1416])\n",
            "context_tensors:  tensor([26069, 14156,  1423, 16499,  1416, 15606])\n",
            "context_tensors:  tensor([   76, 28165, 26026, 27053,  1416,   460])context_tensors: \n",
            " context_tensors: tensor([14156,  1423,  7468,  1416, 15606, 23585]) \n",
            "tensor([28165, 26026, 11359,  1416,   460, 28399])\n",
            "context_tensors:  tensor([ 1423,  7468, 16499, 15606, 23585,  2806])\n",
            "context_tensors:  context_tensors: tensor([26026, 11359, 27053,   460, 28399,    62])\n",
            " tensor([ 7468, 16499,  1416, 23585,  2806, 26026])\n",
            "context_tensors: context_tensors:   tensor([16499,  1416, 15606,  2806, 26026, 10110])tensor([11359, 27053,  1416, 28399,    62, 25819])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1416, 15606, 23585, 26026, 10110,  2371]) tensor([27053,  1416,   460,    62, 25819,  6292])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15606, 23585,  2806, 10110,  2371,  1423])\n",
            "tensor([ 1416,   460, 28399, 25819,  6292, 13448])\n",
            "context_tensors: context_tensors:   tensor([23585,  2806, 26026,  2371,  1423, 19082])tensor([  460, 28399,    62,  6292, 13448,  6452])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28399,    62, 25819, 13448,  6452, 18520]) tensor([ 2806, 26026, 10110,  1423, 19082, 18520])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   62, 25819,  6292,  6452, 18520,  1893]) \n",
            "tensor([26026, 10110,  2371, 19082, 18520, 24115])\n",
            "context_tensors:  tensor([25819,  6292, 13448, 18520,  1893, 10856])context_tensors:  \n",
            "context_tensors: tensor([10110,  2371,  1423, 18520, 24115,  7468]) \n",
            "context_tensors: tensor([ 6292, 13448,  6452,  1893, 10856, 21005])\n",
            " tensor([ 2371,  1423, 19082, 24115,  7468,  4118])context_tensors:  \n",
            "tensor([13448,  6452, 18520, 10856, 21005, 10866])\n",
            "context_tensors: context_tensors:  tensor([ 6452, 18520,  1893, 21005, 10866, 26026]) \n",
            "context_tensors: tensor([ 1423, 19082, 18520,  7468,  4118,  3725]) \n",
            "context_tensors: tensor([18520,  1893, 10856, 10866, 26026, 10484]) \n",
            "tensor([19082, 18520, 24115,  4118,  3725, 26026])\n",
            "context_tensors:  tensor([ 1893, 10856, 21005, 26026, 10484, 26943])\n",
            "context_tensors: context_tensors:   tensor([18520, 24115,  7468,  3725, 26026, 24505])\n",
            "tensor([10856, 21005, 10866, 10484, 26943,  1416])\n",
            "context_tensors: context_tensors:   tensor([24115,  7468,  4118, 26026, 24505,    79])tensor([21005, 10866, 26026, 26943,  1416,   460])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 7468,  4118,  3725, 24505,    79,  1409])\n",
            " tensor([10866, 26026, 10484,  1416,   460, 28452])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26026, 25674, 26026, 24900, 12380])\n",
            " tensor([26026, 10484, 26943,   460, 28452,  7287])context_tensors: \n",
            " context_tensors: tensor([26026, 25674,  3725, 24900, 12380,  2213])\n",
            " tensor([10484, 26943,  1416, 28452,  7287,    76])context_tensors: \n",
            " context_tensors: tensor([25674,  3725, 26026, 12380,  2213,  4027]) tensor([26943,  1416,   460,  7287,    76, 26285])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 3725, 26026, 24900,  2213,  4027,  2371])tensor([ 1416,   460, 28452,    76, 26285,  3623])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 24900, 12380,  4027,  2371, 28190])tensor([  460, 28452,  7287, 26285,  3623, 12540])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24900, 12380,  2213,  2371, 28190,  3403])tensor([28452,  7287,    76,  3623, 12540, 13448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 7287,    76, 26285, 12540, 13448,  3264])\n",
            " tensor([12380,  2213,  4027, 28190,  3403, 18520])\n",
            "context_tensors: context_tensors:   tensor([ 2213,  4027,  2371,  3403, 18520, 27457])tensor([   76, 26285,  3623, 13448,  3264, 13448])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285,  3623, 12540,  3264, 13448, 23429])tensor([ 4027,  2371, 28190, 18520, 27457, 28234])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3623, 12540, 13448, 13448, 23429,   813]) tensor([ 2371, 28190,  3403, 27457, 28234,    76])\n",
            "\n",
            "context_tensors:  tensor([28190,  3403, 18520, 28234,    76,  9414])\n",
            "context_tensors: context_tensors:   tensor([12540, 13448,  3264, 23429,   813,    79])\n",
            "tensor([ 3403, 18520, 27457,    76,  9414, 28356])\n",
            "context_tensors:  context_tensors: tensor([13448,  3264, 13448,   813,    79,  1409])\n",
            " tensor([18520, 27457, 28234,  9414, 28356,  4027])\n",
            "context_tensors:  tensor([27457, 28234,    76, 28356,  4027,  3017])\n",
            "context_tensors:  tensor([28234,    76,  9414,  4027,  3017, 26026])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026, 11359, 10473,  2334, 27053])\n",
            " tensor([   76,  9414, 28356,  3017, 26026, 26253])\n",
            "context_tensors: context_tensors:   tensor([26026, 11359, 12153,  2334, 27053,  1416])tensor([ 9414, 28356,  4027, 26026, 26253,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28356,  4027,  3017, 26253,    79,  1409])\n",
            "tensor([11359, 12153, 10473, 27053,  1416,   460])\n",
            "context_tensors: context_tensors:  tensor([12153, 10473,  2334,  1416,   460, 25819]) tensor([ 1411, 26026, 27072, 19866, 28190,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10473,  2334, 27053,   460, 25819, 18520])tensor([26026, 27072, 14156, 28190,  2371, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2334, 27053,  1416, 25819, 18520,   869])tensor([27072, 14156, 19866,  2371, 26026, 27537])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([14156, 19866, 28190, 26026, 27537, 10538])tensor([27053,  1416,   460, 18520,   869, 19923])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19866, 28190,  2371, 27537, 10538, 10823])tensor([ 1416,   460, 25819,   869, 19923,    76])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([  460, 25819, 18520, 19923,    76, 17781])\n",
            " context_tensors: tensor([28190,  2371, 26026, 10538, 10823, 14156])\n",
            " tensor([25819, 18520,   869,    76, 17781, 11158])context_tensors: \n",
            "context_tensors:  tensor([ 2371, 26026, 27537, 10823, 14156, 15589])\n",
            " context_tensors:  tensor([26026, 27537, 10538, 14156, 15589, 11908])\n",
            "context_tensors: tensor([18520,   869, 19923, 17781, 11158,  2334]) tensor([27537, 10538, 10823, 15589, 11908, 13448])\n",
            "\n",
            "context_tensors:  tensor([10538, 10823, 14156, 11908, 13448,  6115])context_tensors: \n",
            "context_tensors:   tensor([10823, 14156, 15589, 13448,  6115,    79])tensor([  869, 19923,    76, 11158,  2334, 13724])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14156, 15589, 11908,  6115,    79,  1409])\n",
            "tensor([19923,    76, 17781,  2334, 13724, 20101])\n",
            "context_tensors: context_tensors:  tensor([   76, 17781, 11158, 13724, 20101, 18520]) \n",
            "tensor([ 1411, 26115, 24420, 26285,   869,  5953])\n",
            "context_tensors:  tensor([17781, 11158,  2334, 20101, 18520,  1098])\n",
            "context_tensors:  context_tensors: tensor([26115, 24420, 12015,   869,  5953,    72])\n",
            " context_tensors: tensor([11158,  2334, 13724, 18520,  1098, 28661]) \n",
            "tensor([24420, 12015, 26285,  5953,    72,  1350])\n",
            "context_tensors:  context_tensors: tensor([12015, 26285,   869,    72,  1350,  1417])\n",
            " context_tensors:  tensor([26285,   869,  5953,  1350,  1417,  1038])tensor([ 2334, 13724, 20101,  1098, 28661, 28399])\n",
            "\n",
            "context_tensors:  tensor([  869,  5953,    72,  1417,  1038, 13448])\n",
            "context_tensors:  tensor([ 5953,    72,  1350,  1038, 13448,    73])\n",
            "context_tensors:  tensor([   72,  1350,  1417, 13448,    73,  1657])\n",
            "context_tensors:  tensor([1350, 1417, 1038,   73, 1657, 2371])\n",
            "context_tensors: context_tensors:   tensor([ 1417,  1038, 13448,  1657,  2371,  1074])\n",
            "context_tensors: tensor([13724, 20101, 18520, 28661, 28399,    79]) \n",
            "tensor([ 1038, 13448,    73,  2371,  1074,  5953])\n",
            "context_tensors:  tensor([13448,    73,  1657,  1074,  5953,    72])\n",
            "context_tensors:  context_tensors: tensor([20101, 18520,  1098, 28399,    79,  1409])\n",
            " tensor([  73, 1657, 2371, 5953,   72,  541])context_tensors: \n",
            " context_tensors:  tensor([ 1411, 26910, 11649, 26026, 24312,  5614])tensor([ 1657,  2371,  1074,    72,   541, 13448])\n",
            "context_tensors: \n",
            " tensor([ 2371,  1074,  5953,   541, 13448,    73])\n",
            "context_tensors:  tensor([26910, 11649, 11158, 24312,  5614, 28849])context_tensors:  tensor([ 1074,  5953,    72, 13448,    73, 15837])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 5953,    72,   541,    73, 15837,    79]) \n",
            "tensor([11649, 11158, 26026,  5614, 28849, 22750])\n",
            "context_tensors:  tensor([   72,   541, 13448, 15837,    79,  1409])context_tensors: \n",
            " tensor([11158, 26026, 24312, 28849, 22750, 27671])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 26026, 19866, 13707, 26026,  6692]) tensor([26026, 24312,  5614, 22750, 27671,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24312,  5614, 28849, 27671,  1410, 28115])\n",
            "tensor([26026, 19866, 16501, 26026,  6692, 23634])\n",
            "context_tensors: context_tensors:  tensor([19866, 16501, 13707,  6692, 23634, 18520]) \n",
            "tensor([ 5614, 28849, 22750,  1410, 28115,  5663])context_tensors:  \n",
            "tensor([16501, 13707, 26026, 23634, 18520, 18229])context_tensors: \n",
            " tensor([28849, 22750, 27671, 28115,  5663,  2858])\n",
            "context_tensors: context_tensors:   tensor([22750, 27671,  1410,  5663,  2858,  1423])\n",
            "tensor([13707, 26026,  6692, 18520, 18229,  3149])\n",
            "context_tensors:  context_tensors:  tensor([27671,  1410, 28115,  2858,  1423, 16785])\n",
            "tensor([26026,  6692, 23634, 18229,  3149, 11158])context_tensors:  \n",
            "context_tensors: tensor([ 1410, 28115,  5663,  1423, 16785, 18520])\n",
            " context_tensors: tensor([ 6692, 23634, 18520,  3149, 11158, 26026]) \n",
            "tensor([28115,  5663,  2858, 16785, 18520, 26026])\n",
            "context_tensors: context_tensors:  tensor([ 5663,  2858,  1423, 18520, 26026, 25819]) \n",
            "tensor([23634, 18520, 18229, 11158, 26026,  1410])\n",
            "context_tensors: context_tensors:   tensor([ 2858,  1423, 16785, 26026, 25819,    79])\n",
            "context_tensors: tensor([18520, 18229,  3149, 26026,  1410, 14180])\n",
            " tensor([ 1423, 16785, 18520, 25819,    79,  1409])context_tensors: \n",
            " context_tensors:  tensor([ 1411, 26026, 11359, 19921, 23850, 15465])\n",
            "context_tensors:  tensor([26026, 11359, 10609, 23850, 15465, 13448])\n",
            "tensor([18229,  3149, 11158,  1410, 14180, 13448])\n",
            "context_tensors:  context_tensors: tensor([11359, 10609, 19921, 15465, 13448,  1423])\n",
            "context_tensors:  \n",
            "tensor([ 3149, 11158, 26026, 14180, 13448, 21039]) context_tensors: tensor([10609, 19921, 23850, 13448,  1423, 19082]) \n",
            "tensor([11158, 26026,  1410, 13448, 21039, 26285])context_tensors: \n",
            " context_tensors: tensor([19921, 23850, 15465,  1423, 19082, 18520]) \n",
            "tensor([26026,  1410, 14180, 21039, 26285, 26026])context_tensors: \n",
            " tensor([23850, 15465, 13448, 19082, 18520, 21008])\n",
            "context_tensors: context_tensors:   tensor([15465, 13448,  1423, 18520, 21008, 16539])tensor([ 1410, 14180, 13448, 26285, 26026,  4219])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([14180, 13448, 21039, 26026,  4219,  2718])\n",
            " tensor([13448,  1423, 19082, 21008, 16539, 10866])\n",
            "context_tensors: context_tensors:  tensor([13448, 21039, 26285,  4219,  2718, 13448])\n",
            " tensor([ 1423, 19082, 18520, 16539, 10866, 26026])context_tensors: \n",
            " tensor([21039, 26285, 26026,  2718, 13448, 28126])context_tensors: \n",
            " context_tensors: tensor([19082, 18520, 21008, 10866, 26026, 26431]) \n",
            "tensor([26285, 26026,  4219, 13448, 28126,  3149])\n",
            "context_tensors:  context_tensors: tensor([26026,  4219,  2718, 28126,  3149,    76]) \n",
            "tensor([18520, 21008, 16539, 26026, 26431,    79])\n",
            "context_tensors: context_tensors:   tensor([21008, 16539, 10866, 26431,    79,  1409])tensor([ 4219,  2718, 13448,  3149,    76, 13497])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 11359, 28400, 10609, 16537,   942])tensor([ 2718, 13448, 28126,    76, 13497, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([11359, 28400, 26026, 16537,   942,  1416]) \n",
            "tensor([13448, 28126,  3149, 13497, 26026, 12081])context_tensors:  \n",
            "tensor([28400, 26026, 10609,   942,  1416,    86])\n",
            "context_tensors: context_tensors:   tensor([26026, 10609, 16537,  1416,    86, 13448])tensor([28126,  3149,    76, 26026, 12081, 18520])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 3149,    76, 13497, 12081, 18520,  1410]) tensor([10609, 16537,   942,    86, 13448,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 13497, 26026, 18520,  1410,  2371])tensor([16537,   942,  1416, 13448,  1410,    76])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([13497, 26026, 12081,  1410,  2371, 26026])tensor([  942,  1416,    86,  1410,    76, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1416,    86, 13448,    76, 26026, 11359]) \n",
            "tensor([26026, 12081, 18520,  2371, 26026, 26243])context_tensors: \n",
            " tensor([   86, 13448,  1410, 26026, 11359,    62])\n",
            "context_tensors:  context_tensors:  tensor([13448,  1410,    76, 11359,    62,  5016])tensor([12081, 18520,  1410, 26026, 26243,  2371])\n",
            "\n",
            "context_tensors:  tensor([ 1410,    76, 26026,    62,  5016,    79])\n",
            "context_tensors:  tensor([   76, 26026, 11359,  5016,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 26026, 22172, 27965,  7719, 13448])\n",
            "context_tensors:   tensor([18520,  1410,  2371, 26243,  2371,  1410])tensor([26026, 22172, 16537,  7719, 13448, 10866])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22172, 16537, 27965, 13448, 10866,   869])tensor([ 1410,  2371, 26026,  2371,  1410, 23242])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26026, 26243,  1410, 23242,    79])\n",
            "tensor([16537, 27965,  7719, 10866,   869, 12989])context_tensors:  \n",
            "tensor([26026, 26243,  2371, 23242,    79,  1409])context_tensors: \n",
            "context_tensors:   tensor([27965,  7719, 13448,   869, 12989,  2371])tensor([ 1411, 26069,  2733, 21953, 26023, 14227])\n",
            "\n",
            "context_tensors: context_tensors:  \n",
            "tensor([ 7719, 13448, 10866, 12989,  2371, 19921]) tensor([26069,  2733,  1410, 26023, 14227, 21235])\n",
            "context_tensors:  context_tensors:  tensor([13448, 10866,   869,  2371, 19921, 13448])tensor([ 2733,  1410, 21953, 14227, 21235, 10075])\n",
            "context_tensors: \n",
            " context_tensors: tensor([10866,   869, 12989, 19921, 13448,  1410]) \n",
            "tensor([ 1410, 21953, 26023, 21235, 10075, 26285])context_tensors:  \n",
            "tensor([  869, 12989,  2371, 13448,  1410,    79])\n",
            "context_tensors:  context_tensors:  tensor([21953, 26023, 14227, 10075, 26285, 24344])tensor([12989,  2371, 19921,  1410,    79,  1409])\n",
            "context_tensors: \n",
            " tensor([ 1411, 26026, 11359, 23850, 15465,  1038])\n",
            "context_tensors: context_tensors:   tensor([26023, 14227, 21235, 26285, 24344, 19162])tensor([26026, 11359,  3647, 15465,  1038,  1416])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([11359,  3647, 23850,  1038,  1416,   942]) \n",
            "tensor([14227, 21235, 10075, 24344, 19162, 18008])context_tensors: \n",
            " context_tensors: tensor([ 3647, 23850, 15465,  1416,   942, 26285]) tensor([21235, 10075, 26285, 19162, 18008, 12071])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([10075, 26285, 24344, 18008, 12071,    79]) tensor([23850, 15465,  1038,   942, 26285, 21007])\n",
            "context_tensors: \n",
            " context_tensors: tensor([15465,  1038,  1416, 26285, 21007, 10866])\n",
            "context_tensors:   tensor([ 1038,  1416,   942, 21007, 10866, 26026])tensor([26285, 24344, 19162, 12071,    79,  1409])\n",
            "context_tensors: \n",
            " tensor([ 1411, 14210, 14156, 15372,  6240, 18520])\n",
            "context_tensors:  tensor([14210, 14156, 26026,  6240, 18520, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 1416,   942, 26285, 10866, 26026, 10539])\n",
            "tensor([14156, 26026, 15372, 18520, 26026, 23506])\n",
            "context_tensors:  context_tensors: tensor([  942, 26285, 21007, 26026, 10539, 22600]) \n",
            "tensor([26026, 15372,  6240, 26026, 23506, 16501])\n",
            "context_tensors: context_tensors:  tensor([26285, 21007, 10866, 10539, 22600,    79]) \n",
            "tensor([15372,  6240, 18520, 23506, 16501, 24420])context_tensors: \n",
            " tensor([21007, 10866, 26026, 22600,    79,  1409])context_tensors: \n",
            " tensor([ 6240, 18520, 26026, 16501, 24420, 17818])\n",
            "context_tensors:  tensor([ 1411, 26026, 11359,  3647, 26831,   117])\n",
            "context_tensors: context_tensors:  tensor([18520, 26026, 23506, 24420, 17818, 26285])\n",
            " context_tensors: tensor([26026, 11359, 26049, 26831,   117,  1416]) tensor([26026, 23506, 16501, 17818, 26285, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([11359, 26049,  3647,   117,  1416,    86]) tensor([23506, 16501, 24420, 26285, 26026, 21665])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26049,  3647, 26831,  1416,    86,  3017])\n",
            "tensor([16501, 24420, 17818, 26026, 21665,    79])\n",
            "context_tensors:  tensor([ 3647, 26831,   117,    86,  3017, 12862])\n",
            "context_tensors: context_tensors:  tensor([24420, 17818, 26285, 21665,    79,  1409])\n",
            " tensor([26831,   117,  1416,  3017, 12862,  2371])context_tensors: \n",
            " tensor([ 1411, 26115, 24420,  1423,  4310,  1416])\n",
            "context_tensors: context_tensors:   tensor([  117,  1416,    86, 12862,  2371, 28400])tensor([26115, 24420, 14156,  4310,  1416,  8908])\n",
            "context_tensors:  \n",
            "tensor([ 1416,    86,  3017,  2371, 28400,   792])\n",
            "context_tensors: context_tensors:   tensor([24420, 14156,  1423,  1416,  8908, 26023])tensor([   86,  3017, 12862, 28400,   792,  1416])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3017, 12862,  2371,   792,  1416,   117]) \n",
            "tensor([14156,  1423,  4310,  8908, 26023, 20363])context_tensors: \n",
            " tensor([12862,  2371, 28400,  1416,   117, 13448])context_tensors: \n",
            " context_tensors:  tensor([ 1423,  4310,  1416, 26023, 20363, 12142])tensor([ 2371, 28400,   792,   117, 13448, 26831])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28400,   792,  1416, 13448, 26831,    79]) tensor([ 4310,  1416,  8908, 20363, 12142, 28356])\n",
            "context_tensors: \n",
            " tensor([  792,  1416,   117, 26831,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1416,  8908, 26023, 12142, 28356, 10561])tensor([ 1411,  1410, 25716,  1410,  1410, 23134])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 8908, 26023, 20363, 28356, 10561, 23296])\n",
            " context_tensors: tensor([ 1410, 25716,  2371,  1410, 23134, 26026])\n",
            " context_tensors:  tensor([25716,  2371,  1410, 23134, 26026, 11359])\n",
            "tensor([26023, 20363, 12142, 10561, 23296,    79])context_tensors:  \n",
            "tensor([ 2371,  1410,  1410, 26026, 11359,    62])\n",
            "context_tensors:  tensor([20363, 12142, 28356, 23296,    79,  1409])context_tensors:  \n",
            "tensor([ 1410,  1410, 23134, 11359,    62, 11726])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 14210, 12380, 21503, 11158,  3886]) \n",
            "tensor([ 1410, 23134, 26026,    62, 11726,    79])context_tensors: \n",
            " tensor([14210, 12380,  3686, 11158,  3886,   222])context_tensors: \n",
            "context_tensors:   tensor([23134, 26026, 11359, 11726,    79,  1409])tensor([12380,  3686, 21503,  3886,   222,  2371])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26831,    62, 11723, 27965,  1423]) \n",
            "tensor([ 3686, 21503, 11158,   222,  2371,  1190])\n",
            "context_tensors:  tensor([26831,    62, 18616, 27965,  1423,  1410])\n",
            "context_tensors: context_tensors:   tensor([21503, 11158,  3886,  2371,  1190, 16052])tensor([   62, 18616, 11723,  1423,  1410, 18997])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18616, 11723, 27965,  1410, 18997, 11723])\n",
            " tensor([11158,  3886,   222,  1190, 16052,    72])context_tensors: \n",
            " context_tensors: tensor([11723, 27965,  1423, 18997, 11723,    79])\n",
            " context_tensors:  tensor([ 3886,   222,  2371, 16052,    72,  1027])tensor([27965,  1423,  1410, 11723,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 222, 2371, 1190,   72, 1027, 2371])tensor([ 1411, 26026, 28295, 11359, 10866, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 28295, 21004, 10866, 26026,   813])tensor([ 2371,  1190, 16052,  1027,  2371,   823])\n",
            "context_tensors: \n",
            " tensor([28295, 21004, 11359, 26026,   813,  3264])\n",
            "context_tensors:  context_tensors: tensor([ 1190, 16052,    72,  2371,   823, 11187]) \n",
            "context_tensors: tensor([21004, 11359, 10866,   813,  3264, 28452]) \n",
            "tensor([16052,    72,  1027,   823, 11187,    73])context_tensors: \n",
            " context_tensors: tensor([11359, 10866, 26026,  3264, 28452,  7287]) tensor([   72,  1027,  2371, 11187,    73,  7643])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([1027, 2371,  823,   73, 7643,   76])\n",
            "tensor([10866, 26026,   813, 28452,  7287,    79])\n",
            "context_tensors: context_tensors:  tensor([ 2371,   823, 11187,  7643,    76,  2371]) \n",
            "tensor([26026,   813,  3264,  7287,    79,  1409])context_tensors: \n",
            " tensor([  823, 11187,    73,    76,  2371, 25911])context_tensors: \n",
            " tensor([ 1411, 26026, 11359, 12380,  2334, 27053])\n",
            "context_tensors: context_tensors:   tensor([26026, 11359,  2197,  2334, 27053,  1416])\n",
            "tensor([11187,    73,  7643,  2371, 25911, 26285])context_tensors: \n",
            " tensor([11359,  2197, 12380, 27053,  1416,   664])context_tensors: \n",
            " context_tensors: tensor([   73,  7643,    76, 25911, 26285,  3623]) \n",
            "tensor([ 2197, 12380,  2334,  1416,   664, 25819])\n",
            "context_tensors:  context_tensors: tensor([ 7643,    76,  2371, 26285,  3623, 10987])\n",
            " tensor([12380,  2334, 27053,   664, 25819, 26023])context_tensors: \n",
            " tensor([   76,  2371, 25911,  3623, 10987, 10265])context_tensors: \n",
            " tensor([ 2334, 27053,  1416, 25819, 26023, 27965])context_tensors: \n",
            " tensor([ 2371, 25911, 26285, 10987, 10265,  3243])context_tensors: \n",
            " context_tensors: tensor([27053,  1416,   664, 26023, 27965, 26285]) \n",
            "tensor([25911, 26285,  3623, 10265,  3243, 11158])\n",
            "context_tensors: context_tensors:   tensor([ 1416,   664, 25819, 27965, 26285, 19917])tensor([26285,  3623, 10987,  3243, 11158, 23731])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  664, 25819, 26023, 26285, 19917, 13448])tensor([ 3623, 10987, 10265, 11158, 23731, 26015])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([25819, 26023, 27965, 19917, 13448, 26026])tensor([10987, 10265,  3243, 23731, 26015, 18832])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10265,  3243, 11158, 26015, 18832, 16502])tensor([26023, 27965, 26285, 13448, 26026,  1893])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3243, 11158, 23731, 18832, 16502, 13448])tensor([27965, 26285, 19917, 26026,  1893, 28399])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11158, 23731, 26015, 16502, 13448, 14227])tensor([26285, 19917, 13448,  1893, 28399,    62])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19917, 13448, 26026, 28399,    62, 26943])tensor([23731, 26015, 18832, 13448, 14227, 21235])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26015, 18832, 16502, 14227, 21235,    79])tensor([13448, 26026,  1893,    62, 26943,  1416])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  1893, 28399, 26943,  1416,   664])\n",
            "tensor([18832, 16502, 13448, 21235,    79,  1409])context_tensors:  \n",
            "tensor([ 1893, 28399,    62,  1416,   664,  5430])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026, 19866, 11506, 13101,  3017]) \n",
            "tensor([28399,    62, 26943,   664,  5430, 13448])\n",
            "context_tensors: context_tensors:   tensor([26026, 19866, 16501, 13101,  3017, 26026])tensor([   62, 26943,  1416,  5430, 13448,   799])\n",
            "context_tensors: \n",
            " tensor([26943,  1416,   664, 13448,   799,    79])\n",
            "context_tensors: context_tensors:   tensor([19866, 16501, 11506,  3017, 26026, 25397])tensor([1416,  664, 5430,  799,   79, 1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 11359, 10609, 16537, 27965])tensor([16501, 11506, 13101, 26026, 25397, 18520])\n",
            "\n",
            "context_tensors:  tensor([11506, 13101,  3017, 25397, 18520, 26026])\n",
            "context_tensors:  tensor([26026, 11359,    62, 16537, 27965,  1910])\n",
            "context_tensors: context_tensors:  tensor([13101,  3017, 26026, 18520, 26026,  4310]) \n",
            "tensor([11359,    62, 10609, 27965,  1910, 17414])context_tensors: \n",
            "context_tensors:   tensor([   62, 10609, 16537,  1910, 17414,    76])\n",
            "tensor([ 3017, 26026, 25397, 26026,  4310, 25198])context_tensors: \n",
            "context_tensors:  tensor([10609, 16537, 27965, 17414,    76,  4767]) \n",
            "tensor([26026, 25397, 18520,  4310, 25198,    76])context_tensors: \n",
            " tensor([16537, 27965,  1910,    76,  4767, 26026])\n",
            "context_tensors:  context_tensors: tensor([25397, 18520, 26026, 25198,    76, 21288])\n",
            " tensor([27965,  1910, 17414,  4767, 26026, 25819])\n",
            "context_tensors: context_tensors:   tensor([ 1910, 17414,    76, 26026, 25819, 28362])\n",
            "tensor([18520, 26026,  4310,    76, 21288, 26015])\n",
            "context_tensors: context_tensors:   tensor([17414,    76,  4767, 25819, 28362, 11158])\n",
            "tensor([26026,  4310, 25198, 21288, 26015,  8141])context_tensors: \n",
            " context_tensors: tensor([   76,  4767, 26026, 28362, 11158, 26026]) tensor([ 4310, 25198,    76, 26015,  8141, 10866])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([25198,    76, 21288,  8141, 10866, 20473])tensor([ 4767, 26026, 25819, 11158, 26026,  6297])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76, 21288, 26015, 10866, 20473,    79])\n",
            " context_tensors: tensor([26026, 25819, 28362, 26026,  6297,    79]) tensor([21288, 26015,  8141, 20473,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 14227,  8117, 20346, 18520,  1410])tensor([25819, 28362, 11158,  6297,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([14227,  8117,  6588, 18520,  1410, 23788])tensor([ 1411, 26026,  8016, 28399,    62, 10856])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 8117,  6588, 20346,  1410, 23788,  2371]) tensor([26026,  8016, 18520,    62, 10856, 13448])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6588, 20346, 18520, 23788,  2371, 20065])tensor([ 8016, 18520, 28399, 10856, 13448,  1891])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([20346, 18520,  1410,  2371, 20065, 28457])tensor([18520, 28399,    62, 13448,  1891, 10138])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28399,    62, 10856,  1891, 10138, 23506])tensor([18520,  1410, 23788, 20065, 28457,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   62, 10856, 13448, 10138, 23506,  5417])tensor([ 1410, 23788,  2371, 28457,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10856, 13448,  1891, 23506,  5417,    76])tensor([ 1411, 24115,  4235,  2733,  2197,  8996])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448,  1891, 10138,  5417,    76, 13497])tensor([24115,  4235, 10627,  2197,  8996,    76])\n",
            "\n",
            "context_tensors:  tensor([ 4235, 10627,  2733,  8996,    76,  2185])context_tensors:  tensor([ 1891, 10138, 23506,    76, 13497, 15636])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10627,  2733,  2197,    76,  2185, 28356])\n",
            "tensor([10138, 23506,  5417, 13497, 15636,  1557])\n",
            "context_tensors: context_tensors:   tensor([ 2733,  2197,  8996,  2185, 28356, 26026])tensor([23506,  5417,    76, 15636,  1557, 26285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2197,  8996,    76, 28356, 26026, 18468])tensor([ 5417,    76, 13497,  1557, 26285,  9083])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 13497, 15636, 26285,  9083,    76])\n",
            "tensor([ 8996,    76,  2185, 26026, 18468,  1410])context_tensors:  \n",
            "tensor([13497, 15636,  1557,  9083,    76, 20245])context_tensors: \n",
            " tensor([   76,  2185, 28356, 18468,  1410,  1410])context_tensors: \n",
            " context_tensors: tensor([15636,  1557, 26285,    76, 20245,  2305])\n",
            "context_tensors:   tensor([ 2185, 28356, 26026,  1410,  1410, 18691])tensor([ 1557, 26285,  9083, 20245,  2305, 28399])\n",
            "\n",
            "context_tensors:  tensor([26285,  9083,    76,  2305, 28399,    76])context_tensors: \n",
            " tensor([28356, 26026, 18468,  1410, 18691,  1410])\n",
            "context_tensors: context_tensors:  tensor([ 9083,    76, 20245, 28399,    76,  1410])\n",
            " tensor([26026, 18468,  1410, 18691,  1410,    79])context_tensors:  \n",
            "tensor([   76, 20245,  2305,    76,  1410,  2371])context_tensors:  tensor([18468,  1410,  1410,  1410,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([20245,  2305, 28399,  1410,  2371, 13058])\n",
            "context_tensors:   tensor([ 1411, 15232, 21323,  1423, 11915, 27466])\n",
            "tensor([ 2305, 28399,    76,  2371, 13058, 22359])context_tensors: \n",
            " context_tensors: tensor([15232, 21323,  6643, 11915, 27466, 18520]) tensor([28399,    76,  1410, 13058, 22359,  1529])\n",
            "context_tensors:  \n",
            "context_tensors: tensor([21323,  6643,  1423, 27466, 18520, 20473]) tensor([   76,  1410,  2371, 22359,  1529, 25759])\n",
            "\n",
            "context_tensors:  tensor([ 6643,  1423, 11915, 18520, 20473,  2371])\n",
            "context_tensors: context_tensors:   tensor([ 1423, 11915, 27466, 20473,  2371, 21750])tensor([ 1410,  2371, 13058,  1529, 25759, 28399])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([11915, 27466, 18520,  2371, 21750, 17392]) \n",
            "tensor([ 2371, 13058, 22359, 25759, 28399,    79])\n",
            "context_tensors:  tensor([27466, 18520, 20473, 21750, 17392, 20065])\n",
            "context_tensors: context_tensors:   tensor([18520, 20473,  2371, 17392, 20065, 28457])\n",
            "tensor([13058, 22359,  1529, 28399,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([20473,  2371, 21750, 20065, 28457, 28165])\n",
            " tensor([ 1411, 11231, 14156, 14201, 13363, 26026])context_tensors:  \n",
            "context_tensors: tensor([ 2371, 21750, 17392, 28457, 28165,  6273])\n",
            " tensor([11231, 14156,  2475, 13363, 26026, 11365])\n",
            "context_tensors:  context_tensors: tensor([21750, 17392, 20065, 28165,  6273, 26285])\n",
            " tensor([14156,  2475, 14201, 26026, 11365, 13448])\n",
            "context_tensors:  tensor([17392, 20065, 28457,  6273, 26285, 24116])context_tensors:  \n",
            "tensor([ 2475, 14201, 13363, 11365, 13448,  1891])\n",
            "context_tensors: context_tensors:   tensor([14201, 13363, 26026, 13448,  1891,    76])\n",
            "tensor([20065, 28457, 28165, 26285, 24116, 21323])\n",
            "context_tensors:  tensor([13363, 26026, 11365,  1891,    76, 28167])\n",
            "context_tensors: context_tensors:   tensor([28457, 28165,  6273, 24116, 21323,    79])\n",
            "tensor([26026, 11365, 13448,    76, 28167, 17451])context_tensors: \n",
            " context_tensors:  tensor([28165,  6273, 26285, 21323,    79,  1409])tensor([11365, 13448,  1891, 28167, 17451, 10549])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([13448,  1891,    76, 17451, 10549,  2955])tensor([ 1411, 26115, 24420,  1410,  4787, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1891,    76, 28167, 10549,  2955,  6170])tensor([26115, 24420, 14156,  4787, 26026,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24420, 14156,  1410, 26026,  1410,  1410])tensor([   76, 28167, 17451,  2955,  6170, 11158])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14156,  1410,  4787,  1410,  1410,  1410])tensor([28167, 17451, 10549,  6170, 11158, 10484])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1410,  4787, 26026,  1410,  1410,    79])tensor([17451, 10549,  2955, 11158, 10484,  2371])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 4787, 26026,  1410,  1410,    79,  1409]) \n",
            "tensor([10549,  2955,  6170, 10484,  2371, 18253])context_tensors: \n",
            "context_tensors:   tensor([ 1411, 15606, 18832,    76, 26026, 19866])tensor([ 2955,  6170, 11158,  2371, 18253, 17809])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15606, 18832, 24899, 26026, 19866, 16501])tensor([ 6170, 11158, 10484, 18253, 17809, 10856])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11158, 10484,  2371, 17809, 10856,  2967])tensor([18832, 24899,    76, 19866, 16501, 14156])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10484,  2371, 18253, 10856,  2967,    79])tensor([24899,    76, 26026, 16501, 14156, 27761])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 18253, 17809,  2967,    79,  1409])\n",
            " context_tensors: tensor([   76, 26026, 19866, 14156, 27761, 28356]) \n",
            "tensor([ 1411,  2475,  5415, 26026, 22152, 18520])context_tensors: \n",
            " tensor([26026, 19866, 16501, 27761, 28356, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 2475,  5415, 14156, 22152, 18520, 10856])tensor([19866, 16501, 14156, 28356, 26026,  8015])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([16501, 14156, 27761, 26026,  8015,  9288]) \n",
            "tensor([ 5415, 14156, 26026, 18520, 10856, 19923])\n",
            "context_tensors: context_tensors:  tensor([14156, 27761, 28356,  8015,  9288, 25469]) \n",
            "tensor([14156, 26026, 22152, 10856, 19923,    79])\n",
            "context_tensors: context_tensors:   tensor([27761, 28356, 26026,  9288, 25469, 26285])\n",
            "tensor([26026, 22152, 18520, 19923,    79,  1409])context_tensors: \n",
            " tensor([28356, 26026,  8015, 25469, 26285, 25938])context_tensors:  \n",
            "tensor([ 1411, 16343, 28399, 15374, 26026,  6691])context_tensors: \n",
            " context_tensors: tensor([26026,  8015,  9288, 26285, 25938,  4787]) \n",
            "tensor([16343, 28399, 10858, 26026,  6691, 26285])\n",
            "context_tensors:  tensor([ 8015,  9288, 25469, 25938,  4787, 12778])context_tensors: \n",
            " tensor([28399, 10858, 15374,  6691, 26285, 23309])context_tensors: \n",
            " tensor([ 9288, 25469, 26285,  4787, 12778,    72])context_tensors: \n",
            " context_tensors: tensor([10858, 15374, 26026, 26285, 23309, 11915]) \n",
            "tensor([25469, 26285, 25938, 12778,    72,     1])context_tensors: \n",
            " context_tensors: tensor([15374, 26026,  6691, 23309, 11915, 18667]) \n",
            "tensor([26285, 25938,  4787,    72,     1, 27371])context_tensors: \n",
            "context_tensors:  tensor([26026,  6691, 26285, 11915, 18667, 13448]) \n",
            "tensor([25938,  4787, 12778,     1, 27371, 17029])context_tensors: \n",
            " context_tensors: tensor([ 6691, 26285, 23309, 18667, 13448,  9774]) \n",
            "tensor([ 4787, 12778,    72, 27371, 17029,     1])context_tensors: \n",
            " context_tensors: tensor([26285, 23309, 11915, 13448,  9774, 18691]) tensor([12778,    72,     1, 17029,     1,    73])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23309, 11915, 18667,  9774, 18691, 26026])tensor([   72,     1, 27371,     1,    73, 20574])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([    1, 27371, 17029,    73, 20574,  4787])tensor([11915, 18667, 13448, 18691, 26026, 27167])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([27371, 17029,     1, 20574,  4787, 26026])tensor([18667, 13448,  9774, 26026, 27167, 24759])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17029,     1,    73,  4787, 26026, 17455])tensor([13448,  9774, 18691, 27167, 24759,    79])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([    1,    73, 20574, 26026, 17455,    79]) \n",
            "tensor([ 9774, 18691, 26026, 24759,    79,  1409])context_tensors: \n",
            "context_tensors:  tensor([   73, 20574,  4787, 17455,    79,  1409]) tensor([ 1411, 11359,    62, 10856,  2966, 27965])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11359,    62, 17809,  2966, 27965, 10990])\n",
            "context_tensors: tensor([ 1411,  1410, 10390,  1423, 23946, 11220])\n",
            " context_tensors: tensor([   62, 17809, 10856, 27965, 10990, 13448]) tensor([ 1410, 10390, 12418, 23946, 11220, 18918])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([10390, 12418,  1423, 11220, 18918,  2371])tensor([17809, 10856,  2966, 10990, 13448,   731])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([12418,  1423, 23946, 18918,  2371, 27372]) \n",
            "tensor([10856,  2966, 27965, 13448,   731,    76])context_tensors:  tensor([ 1423, 23946, 11220,  2371, 27372,    76])\n",
            "context_tensors: \n",
            " tensor([ 2966, 27965, 10990,   731,    76,  2371])context_tensors:  \n",
            "tensor([23946, 11220, 18918, 27372,    76, 18605])\n",
            "context_tensors: context_tensors:   tensor([27965, 10990, 13448,    76,  2371,  3666])tensor([11220, 18918,  2371,    76, 18605, 26026])\n",
            "\n",
            "context_tensors:  tensor([10990, 13448,   731,  2371,  3666,  1868])context_tensors:  tensor([18918,  2371, 27372, 18605, 26026, 15398])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 27372,    76, 26026, 15398,    79])tensor([13448,   731,    76,  3666,  1868, 28356])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([  731,    76,  2371,  1868, 28356, 10484])\n",
            " tensor([27372,    76, 18605, 15398,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([   76,  2371,  3666, 28356, 10484, 13448]) \n",
            "context_tensors: tensor([ 1411, 15726, 23996, 18609, 18691, 26910])\n",
            " tensor([ 2371,  3666,  1868, 10484, 13448,   749])context_tensors: \n",
            " context_tensors: tensor([15726, 23996, 14156, 18691, 26910,  1407]) \n",
            "tensor([ 3666,  1868, 28356, 13448,   749,    79])\n",
            "context_tensors: context_tensors:   tensor([23996, 14156, 18609, 26910,  1407, 26026])tensor([ 1868, 28356, 10484,   749,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 10856, 14156, 17451, 20119, 28399])\n",
            " context_tensors: tensor([14156, 18609, 18691,  1407, 26026, 18011]) \n",
            "tensor([10856, 14156, 26026, 20119, 28399,    62])\n",
            "context_tensors: context_tensors:   tensor([18609, 18691, 26910, 26026, 18011, 16699])tensor([14156, 26026, 17451, 28399,    62, 24560])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18691, 26910,  1407, 18011, 16699,   222])tensor([26026, 17451, 20119,    62, 24560, 13448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([17451, 20119, 28399, 24560, 13448, 26026]) \n",
            "tensor([26910,  1407, 26026, 16699,   222, 28846])context_tensors:  tensor([20119, 28399,    62, 13448, 26026,  6975])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 1407, 26026, 18011,   222, 28846,   305]) tensor([28399,    62, 24560, 26026,  6975,    76])\n",
            "\n",
            "context_tensors:  tensor([   62, 24560, 13448,  6975,    76,  2371])\n",
            "context_tensors: context_tensors:   tensor([26026, 18011, 16699, 28846,   305,  5953])tensor([24560, 13448, 26026,    76,  2371, 27965])\n",
            "context_tensors: \n",
            " tensor([18011, 16699,   222,   305,  5953,    72])context_tensors: \n",
            " context_tensors: tensor([13448, 26026,  6975,  2371, 27965, 10609]) tensor([16699,   222, 28846,  5953,    72,  1038])\n",
            "context_tensors: \n",
            " context_tensors: tensor([26026,  6975,    76, 27965, 10609, 19921]) tensor([  222, 28846,   305,    72,  1038,  1417])\n",
            "context_tensors: \n",
            " tensor([28846,   305,  5953,  1038,  1417,  1234])\n",
            "context_tensors:  tensor([ 6975,    76,  2371, 10609, 19921, 13448])\n",
            "context_tensors: context_tensors:   tensor([  305,  5953,    72,  1417,  1234, 28846])\n",
            "tensor([   76,  2371, 27965, 19921, 13448,  2334])\n",
            "context_tensors: context_tensors:   tensor([ 5953,    72,  1038,  1234, 28846,  1108])tensor([ 2371, 27965, 10609, 13448,  2334, 18750])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   72,  1038,  1417, 28846,  1108,  1417]) \n",
            "tensor([27965, 10609, 19921,  2334, 18750, 25622])\n",
            "context_tensors: context_tensors:   tensor([1038, 1417, 1234, 1108, 1417, 1108])\n",
            "tensor([10609, 19921, 13448, 18750, 25622, 13448])context_tensors:  \n",
            "context_tensors: tensor([ 1417,  1234, 28846,  1417,  1108, 13448]) tensor([19921, 13448,  2334, 25622, 13448,   785])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13448,  2334, 18750, 13448,   785,    79])\n",
            " context_tensors: tensor([ 1234, 28846,  1108,  1108, 13448,    73]) \n",
            "context_tensors: tensor([ 2334, 18750, 25622,   785,    79,  1409])\n",
            " context_tensors: tensor([28846,  1108,  1417, 13448,    73,  1657]) \n",
            "tensor([ 1411,  1423, 17809, 27965, 15287, 13448])context_tensors:  \n",
            "tensor([1108, 1417, 1108,   73, 1657,   79])\n",
            "context_tensors:  context_tensors: tensor([ 1423, 17809,  6297, 15287, 13448,   804])\n",
            " tensor([ 1417,  1108, 13448,  1657,    79,  1409])\n",
            "context_tensors:  tensor([17809,  6297, 27965, 13448,   804,    76])context_tensors: \n",
            " context_tensors: tensor([ 1411, 16220,  2371, 21335, 23522, 16578]) \n",
            "tensor([ 6297, 27965, 15287,   804,    76, 26026])context_tensors: \n",
            " tensor([16220,  2371, 10390, 23522, 16578,  3017])context_tensors: \n",
            "context_tensors:   tensor([ 2371, 10390, 21335, 16578,  3017,  8244])\n",
            "context_tensors: tensor([27965, 15287, 13448,    76, 26026, 22872])\n",
            " tensor([10390, 21335, 23522,  3017,  8244, 28235])context_tensors: \n",
            " tensor([15287, 13448,   804, 26026, 22872, 28612])\n",
            "context_tensors: context_tensors:   tensor([13448,   804,    76, 22872, 28612, 10484])tensor([21335, 23522, 16578,  8244, 28235, 18520])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23522, 16578,  3017, 28235, 18520,   794])\n",
            "context_tensors: tensor([  804,    76, 26026, 28612, 10484, 24746]) tensor([16578,  3017,  8244, 18520,   794, 28846])\n",
            "\n",
            "context_tensors:  tensor([ 3017,  8244, 28235,   794, 28846,   831])\n",
            "context_tensors: context_tensors:  tensor([ 8244, 28235, 18520, 28846,   831,  5953])\n",
            " context_tensors:  tensor([28235, 18520,   794,   831,  5953,    72])\n",
            "tensor([   76, 26026, 22872, 10484, 24746,  2334])context_tensors:  \n",
            "tensor([18520,   794, 28846,  5953,    72,  1234])context_tensors: \n",
            "context_tensors:   tensor([26026, 22872, 28612, 24746,  2334,  9083])tensor([  794, 28846,   831,    72,  1234,  1417])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([22872, 28612, 10484,  2334,  9083,  6991])\n",
            " context_tensors: tensor([28846,   831,  5953,  1234,  1417,  1350])\n",
            "context_tensors:  tensor([28612, 10484, 24746,  9083,  6991, 18605])\n",
            " tensor([  831,  5953,    72,  1417,  1350, 28846])context_tensors:  \n",
            "tensor([10484, 24746,  2334,  6991, 18605, 10856])context_tensors:  \n",
            "context_tensors: tensor([ 5953,    72,  1234,  1350, 28846,  1302])\n",
            "context_tensors:   tensor([24746,  2334,  9083, 18605, 10856, 10866])\n",
            "tensor([   72,  1234,  1417, 28846,  1302,  1417])\n",
            "context_tensors: context_tensors:   tensor([ 2334,  9083,  6991, 10856, 10866, 28399])\n",
            "context_tensors: tensor([1234, 1417, 1350, 1302, 1417,  942]) \n",
            "tensor([ 9083,  6991, 18605, 10866, 28399,    79])context_tensors: \n",
            " context_tensors: tensor([ 1417,  1350, 28846,  1417,   942, 13448]) tensor([ 6991, 18605, 10856, 28399,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1350, 28846,  1302,   942, 13448,    73])\n",
            "tensor([ 1411,  6297, 27965, 18605,  4304, 26026])context_tensors: \n",
            "context_tensors:  tensor([28846,  1302,  1417, 13448,    73,  2371]) tensor([ 6297, 27965,  1669,  4304, 26026, 17809])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([1302, 1417,  942,   73, 2371,  541])tensor([27965,  1669, 18605, 26026, 17809,  2371])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1669, 18605,  4304, 17809,  2371, 23093])\n",
            " tensor([ 1417,   942, 13448,  2371,   541, 28846])\n",
            "context_tensors: context_tensors:   tensor([18605,  4304, 26026,  2371, 23093, 15506])\n",
            "context_tensors: tensor([  942, 13448,    73,   541, 28846,   664]) \n",
            "context_tensors:  tensor([13448,    73,  2371, 28846,   664,  5953])tensor([ 4304, 26026, 17809, 23093, 15506,  4787])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026, 17809,  2371, 15506,  4787,   806])\n",
            " context_tensors:  tensor([  73, 2371,  541,  664, 5953,   72])tensor([17809,  2371, 23093,  4787,   806,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2371, 23093, 15506,   806,    79,  1409])\n",
            "tensor([ 2371,   541, 28846,  5953,    72,  1234])context_tensors: \n",
            " context_tensors:  tensor([  541, 28846,   664,    72,  1234,  1417])tensor([ 1411, 26069,  2733, 24658,  7631, 26285])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28846,   664,  5953,  1234,  1417,   117]) \n",
            "context_tensors: tensor([26069,  2733, 10996,  7631, 26285, 28399]) \n",
            "tensor([  664,  5953,    72,  1417,   117, 28846])\n",
            "context_tensors: context_tensors:  tensor([ 2733, 10996, 24658, 26285, 28399,    62])\n",
            " context_tensors: tensor([ 5953,    72,  1234,   117, 28846,  1234])\n",
            " context_tensors:  tensor([10996, 24658,  7631, 28399,    62, 10856])tensor([   72,  1234,  1417, 28846,  1234,  1417])\n",
            "context_tensors:  tensor([1234, 1417,  117, 1234, 1417, 1108])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1417,   117, 28846,  1417,  1108, 13448])\n",
            "context_tensors: tensor([24658,  7631, 26285,    62, 10856, 13448])\n",
            " tensor([  117, 28846,  1234,  1108, 13448,    73])\n",
            "context_tensors:  tensor([28846,  1234,  1417, 13448,    73, 22079])\n",
            "context_tensors: context_tensors:   tensor([ 7631, 26285, 28399, 10856, 13448, 26026])tensor([ 1234,  1417,  1108,    73, 22079,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1417,  1108, 13448, 22079,    79,  1409])\n",
            "tensor([26285, 28399,    62, 13448, 26026, 11359])\n",
            "context_tensors:  tensor([ 1411, 26026, 16595, 14156,  9719, 26285])context_tensors:  tensor([28399,    62, 10856, 26026, 11359, 10856])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   62, 10856, 13448, 11359, 10856,  2966])tensor([26026, 16595, 15573,  9719, 26285,  3623])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([16595, 15573, 14156, 26285,  3623,  1350])tensor([10856, 13448, 26026, 10856,  2966,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 11359,  2966,    76,  2371])\n",
            "context_tensors: tensor([15573, 14156,  9719,  3623,  1350, 28614]) \n",
            "tensor([26026, 11359, 10856,    76,  2371, 21955])\n",
            "context_tensors: context_tensors:  tensor([14156,  9719, 26285,  1350, 28614, 10866])\n",
            " tensor([11359, 10856,  2966,  2371, 21955, 18520])context_tensors: \n",
            " context_tensors: tensor([ 9719, 26285,  3623, 28614, 10866, 16220]) \n",
            "context_tensors: tensor([10856,  2966,    76, 21955, 18520, 28399])\n",
            "context_tensors:  tensor([26285,  3623,  1350, 10866, 16220,  2371]) \n",
            "tensor([ 2966,    76,  2371, 18520, 28399, 18605])context_tensors:  \n",
            "tensor([ 3623,  1350, 28614, 16220,  2371,   280])\n",
            "context_tensors: context_tensors:   tensor([ 1350, 28614, 10866,  2371,   280, 28614])tensor([   76,  2371, 21955, 28399, 18605, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 21955, 18520, 18605, 26026,  4144]) \n",
            "tensor([28614, 10866, 16220,   280, 28614, 10866])\n",
            "context_tensors: context_tensors:   tensor([21955, 18520, 28399, 26026,  4144, 14156])tensor([10866, 16220,  2371, 28614, 10866, 10390])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18520, 28399, 18605,  4144, 14156, 21997])tensor([16220,  2371,   280, 10866, 10390,    79])\n",
            "\n",
            "\n",
            "context_tensors:  tensor([28399, 18605, 26026, 14156, 21997,  4787])context_tensors:  tensor([18605, 26026,  4144, 21997,  4787, 26026])\n",
            "context_tensors:  tensor([26026,  4144, 14156,  4787, 26026,  2966])\n",
            "context_tensors: context_tensors:   tensor([ 4144, 14156, 21997, 26026,  2966,    62])tensor([ 2371,   280, 28614, 10390,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([14156, 21997,  4787,  2966,    62,  5511]) tensor([ 1411, 26026, 16172, 26145, 26285, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([21997,  4787, 26026,    62,  5511,    79])\n",
            " context_tensors:  tensor([26026, 16172,  6570, 26285, 26026, 19866])tensor([ 4787, 26026,  2966,  5511,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([16172,  6570, 26145, 26026, 19866, 16501])\n",
            " tensor([ 1411, 26026, 19866, 18691,  4597, 24898])context_tensors: \n",
            " context_tensors:  tensor([26026, 19866, 16501,  4597, 24898,    72])\n",
            "tensor([ 6570, 26145, 26285, 19866, 16501, 14156])context_tensors: \n",
            " context_tensors: tensor([19866, 16501, 18691, 24898,    72, 17955])\n",
            "context_tensors:   tensor([26145, 26285, 26026, 16501, 14156, 13488])\n",
            "tensor([16501, 18691,  4597,    72, 17955,  2454])context_tensors:  tensor([26285, 26026, 19866, 14156, 13488,  5045])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18691,  4597, 24898, 17955,  2454,    73])\n",
            " context_tensors: tensor([26026, 19866, 16501, 13488,  5045,  4787])context_tensors:  \n",
            "tensor([ 4597, 24898,    72,  2454,    73, 14156])\n",
            " context_tensors: tensor([19866, 16501, 14156,  5045,  4787,  6219]) \n",
            "tensor([24898,    72, 17955,    73, 14156,  1423])\n",
            "context_tensors: context_tensors:   tensor([16501, 14156, 13488,  4787,  6219,  4310])\n",
            "context_tensors:  tensor([14156, 13488,  5045,  6219,  4310,  1410])\n",
            "tensor([   72, 17955,  2454, 14156,  1423, 24420])context_tensors:  tensor([13488,  5045,  4787,  4310,  1410, 10622])context_tensors: \n",
            "\n",
            "context_tensors:   tensor([17955,  2454,    73,  1423, 24420, 18520])\n",
            "tensor([ 5045,  4787,  6219,  1410, 10622,    79])\n",
            "context_tensors: context_tensors:  tensor([ 2454,    73, 14156, 24420, 18520, 24898])\n",
            " tensor([ 4787,  6219,  4310, 10622,    79,  1409])context_tensors: \n",
            "context_tensors:   tensor([   73, 14156,  1423, 18520, 24898, 13448])tensor([ 1411, 13448, 26026,  7513,    76, 26115])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([14156,  1423, 24420, 24898, 13448, 26026])\n",
            " tensor([13448, 26026, 20414,    76, 26115, 14156])\n",
            "context_tensors: context_tensors:  tensor([26026, 20414,  7513, 26115, 14156, 17453])\n",
            "context_tensors:  tensor([20414,  7513,    76, 14156, 17453,  5250]) \n",
            "tensor([ 1423, 24420, 18520, 13448, 26026, 10217])context_tensors: \n",
            " context_tensors: tensor([ 7513,    76, 26115, 17453,  5250,  4787]) \n",
            "tensor([24420, 18520, 24898, 26026, 10217,  1410])\n",
            "context_tensors: context_tensors:   tensor([   76, 26115, 14156,  5250,  4787,  3149])tensor([18520, 24898, 13448, 10217,  1410,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26115, 14156, 17453,  4787,  3149,    62])tensor([24898, 13448, 26026,  1410,    79,  1409])\n",
            "context_tensors: \n",
            " tensor([14156, 17453,  5250,  3149,    62, 18229])context_tensors: \n",
            " context_tensors: tensor([ 1411, 14210, 14156, 13448, 23562,    76]) \n",
            "tensor([17453,  5250,  4787,    62, 18229,  1410])context_tensors: \n",
            " context_tensors: tensor([14210, 14156, 10987, 23562,    76, 24200]) \n",
            "tensor([ 5250,  4787,  3149, 18229,  1410,  1410])context_tensors: \n",
            " context_tensors: tensor([14156, 10987, 13448,    76, 24200,  1416]) \n",
            "tensor([4787, 3149,   62, 1410, 1410,   76])context_tensors: \n",
            " context_tensors: tensor([10987, 13448, 23562, 24200,  1416,  4311]) \n",
            "tensor([ 3149,    62, 18229,  1410,    76, 28175])context_tensors: \n",
            " context_tensors: tensor([13448, 23562,    76,  1416,  4311, 12142]) \n",
            "tensor([   62, 18229,  1410,    76, 28175, 18643])\n",
            "context_tensors:  tensor([23562,    76, 24200,  4311, 12142, 18521])context_tensors: \n",
            " context_tensors: tensor([18229,  1410,  1410, 28175, 18643, 26170])\n",
            " tensor([   76, 24200,  1416, 12142, 18521, 18229])\n",
            "context_tensors: context_tensors:  tensor([24200,  1416,  4311, 18521, 18229,  3149]) \n",
            "context_tensors:  tensor([ 1416,  4311, 12142, 18229,  3149,    79])\n",
            "tensor([ 1410,  1410,    76, 18643, 26170, 14227])\n",
            "context_tensors:  tensor([ 4311, 12142, 18521,  3149,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 21340,   869,    72,  1350,  1417]) tensor([ 1410,    76, 28175, 26170, 14227, 21235])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([21340,   869,  5953,  1350,  1417,  1038]) \n",
            "tensor([   76, 28175, 18643, 14227, 21235,    79])\n",
            "context_tensors:  context_tensors: tensor([  869,  5953,    72,  1417,  1038, 13448])\n",
            " tensor([28175, 18643, 26170, 21235,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411,  2217, 26115, 14156,  8245, 28165])tensor([ 5953,    72,  1350,  1038, 13448,    73])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   72,  1350,  1417, 13448,    73, 13448])tensor([ 2217, 26115, 24420,  8245, 28165,  5245])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26115, 24420, 14156, 28165,  5245,    76])tensor([ 1350,  1417,  1038,    73, 13448, 28234])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1417,  1038, 13448, 13448, 28234,    76])\n",
            "tensor([24420, 14156,  8245,  5245,    76, 14210])context_tensors: \n",
            " tensor([ 1038, 13448,    73, 28234,    76, 26115])\n",
            "context_tensors:  context_tensors:  tensor([13448,    73, 13448,    76, 26115, 24420])\n",
            "tensor([14156,  8245, 28165,    76, 14210, 14156])\n",
            "context_tensors: context_tensors:  tensor([   73, 13448, 28234, 26115, 24420, 12380])\n",
            " tensor([ 8245, 28165,  5245, 14210, 14156, 17392])context_tensors:  \n",
            "context_tensors: tensor([13448, 28234,    76, 24420, 12380,  1423])\n",
            " context_tensors: tensor([28165,  5245,    76, 14156, 17392,  7733])\n",
            " tensor([28234,    76, 26115, 12380,  1423,  8080])\n",
            "context_tensors: context_tensors:   tensor([   76, 26115, 24420,  1423,  8080,  1416])tensor([ 5245,    76, 14210, 17392,  7733,  1416])\n",
            "context_tensors: \n",
            "context_tensors:   tensor([   76, 14210, 14156,  7733,  1416,  4161])\n",
            "tensor([26115, 24420, 12380,  8080,  1416, 23586])\n",
            "context_tensors:  context_tensors: tensor([14210, 14156, 17392,  1416,  4161, 26015]) tensor([24420, 12380,  1423,  1416, 23586,    76])\n",
            "\n",
            "context_tensors:  tensor([12380,  1423,  8080, 23586,    76, 11908])context_tensors:  tensor([14156, 17392,  7733,  4161, 26015, 18832])\n",
            "context_tensors: \n",
            " context_tensors: tensor([ 1423,  8080,  1416,    76, 11908, 11927]) tensor([17392,  7733,  1416, 26015, 18832, 16502])\n",
            "\n",
            "context_tensors:  tensor([ 7733,  1416,  4161, 18832, 16502,  2371])context_tensors: \n",
            " tensor([ 8080,  1416, 23586, 11908, 11927, 19420])\n",
            "context_tensors:  context_tensors: tensor([ 1416,  4161, 26015, 16502,  2371, 14156]) \n",
            "tensor([ 1416, 23586,    76, 11927, 19420, 10538])context_tensors: \n",
            " context_tensors: tensor([ 4161, 26015, 18832,  2371, 14156, 26187]) \n",
            "tensor([23586,    76, 11908, 19420, 10538,  8244])context_tensors: \n",
            " context_tensors: tensor([26015, 18832, 16502, 14156, 26187, 27185]) \n",
            "tensor([   76, 11908, 11927, 10538,  8244,    79])context_tensors: \n",
            " context_tensors: tensor([18832, 16502,  2371, 26187, 27185, 26285]) \n",
            "tensor([11908, 11927, 19420,  8244,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([16502,  2371, 14156, 27185, 26285, 25440]) \n",
            "tensor([ 1411, 14227, 23735, 28183,  1416, 15606])context_tensors:  \n",
            "tensor([ 2371, 14156, 26187, 26285, 25440,  9394])\n",
            "context_tensors:  tensor([14227, 23735,    76,  1416, 15606, 25674])\n",
            "context_tensors:  tensor([23735,    76, 28183, 15606, 25674, 12380])\n",
            "context_tensors: context_tensors:   tensor([   76, 28183,  1416, 25674, 12380,  2213])\n",
            "tensor([14156, 26187, 27185, 25440,  9394, 28356])context_tensors:  \n",
            "tensor([28183,  1416, 15606, 12380,  2213,  4027])\n",
            "context_tensors: context_tensors:  tensor([ 1416, 15606, 25674,  2213,  4027,  2371]) \n",
            "tensor([26187, 27185, 26285,  9394, 28356, 26617])context_tensors:  \n",
            "tensor([15606, 25674, 12380,  4027,  2371, 28190])\n",
            "context_tensors:  context_tensors:  tensor([27185, 26285, 25440, 28356, 26617, 11476])\n",
            "tensor([25674, 12380,  2213,  2371, 28190,  3403])context_tensors: \n",
            " tensor([26285, 25440,  9394, 26617, 11476,    79])\n",
            "context_tensors: context_tensors:   tensor([25440,  9394, 28356, 11476,    79,  1409])\n",
            "tensor([12380,  2213,  4027, 28190,  3403,  2371])context_tensors: \n",
            " context_tensors: tensor([ 1411, 12774,    76, 24420, 16599,  2197]) \n",
            "tensor([ 2213,  4027,  2371,  3403,  2371, 10538])\n",
            "context_tensors: context_tensors:  tensor([ 4027,  2371, 28190,  2371, 10538, 10826]) \n",
            "tensor([12774,    76, 26115, 16599,  2197, 12418])\n",
            " context_tensors: context_tensors: tensor([ 2371, 28190,  3403, 10538, 10826,  1499]) \n",
            "tensor([   76, 26115, 24420,  2197, 12418,  3686])context_tensors: \n",
            "context_tensors:  tensor([28190,  3403,  2371, 10826,  1499,  2371]) tensor([26115, 24420, 16599, 12418,  3686, 17914])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24420, 16599,  2197,  3686, 17914,  1861])tensor([ 3403,  2371, 10538,  1499,  2371,  3767])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([16599,  2197, 12418, 17914,  1861,  4787])\n",
            "tensor([ 2371, 10538, 10826,  2371,  3767,    79])context_tensors:  \n",
            "context_tensors: tensor([ 2197, 12418,  3686,  1861,  4787, 14311]) \n",
            "tensor([10538, 10826,  1499,  3767,    79,  1409])context_tensors:  \n",
            "context_tensors: tensor([12418,  3686, 17914,  4787, 14311,    76]) tensor([ 1411, 26069,  2733, 22629, 18520, 26125])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 3686, 17914,  1861, 14311,    76,  5623]) tensor([26069,  2733, 23735, 18520, 26125, 18605])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2733, 23735, 22629, 26125, 18605, 26026])tensor([17914,  1861,  4787,    76,  5623,    76])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1861,  4787, 14311,  5623,    76,  2371]) \n",
            "tensor([23735, 22629, 18520, 18605, 26026,  3293])context_tensors: \n",
            " tensor([ 4787, 14311,    76,    76,  2371, 25679])context_tensors:  \n",
            "tensor([22629, 18520, 26125, 26026,  3293,  2371])context_tensors: \n",
            " tensor([14311,    76,  5623,  2371, 25679,  1410])context_tensors: \n",
            "context_tensors:   tensor([18520, 26125, 18605,  3293,  2371, 26026])tensor([   76,  5623,    76, 25679,  1410, 26023])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 5623,    76,  2371,  1410, 26023, 10620]) \n",
            "tensor([26125, 18605, 26026,  2371, 26026,  3524])context_tensors: \n",
            " context_tensors: tensor([   76,  2371, 25679, 26023, 10620, 13899])\n",
            " context_tensors: tensor([18605, 26026,  3293, 26026,  3524, 18520]) \n",
            "tensor([ 2371, 25679,  1410, 10620, 13899, 18521])\n",
            "context_tensors:  tensor([26026,  3293,  2371,  3524, 18520, 26026])context_tensors: \n",
            " context_tensors: tensor([25679,  1410, 26023, 13899, 18521, 18229]) \n",
            "tensor([ 3293,  2371, 26026, 18520, 26026, 25674])context_tensors: \n",
            "context_tensors:  tensor([ 1410, 26023, 10620, 18521, 18229,  3149]) \n",
            "context_tensors: tensor([ 2371, 26026,  3524, 26026, 25674,    76])\n",
            " context_tensors:  tensor([26023, 10620, 13899, 18229,  3149, 11158])tensor([26026,  3524, 18520, 25674,    76,  4767])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([10620, 13899, 18521,  3149, 11158,   738]) tensor([ 3524, 18520, 26026,    76,  4767, 18834])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([13899, 18521, 18229, 11158,   738, 26285]) \n",
            "context_tensors: tensor([18520, 26026, 25674,  4767, 18834, 26026]) \n",
            "tensor([18521, 18229,  3149,   738, 26285,   776])\n",
            "context_tensors: context_tensors:   tensor([18229,  3149, 11158, 26285,   776,    79])tensor([26026, 25674,    76, 18834, 26026, 24022])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([25674,    76,  4767, 26026, 24022, 14156])\n",
            " context_tensors:  tensor([   76,  4767, 18834, 24022, 14156, 24139])\n",
            "tensor([ 3149, 11158,   738,   776,    79,  1409])context_tensors: \n",
            " tensor([ 4767, 18834, 26026, 14156, 24139,    79])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 26080, 10154,  6982, 28356, 26026]) tensor([18834, 26026, 24022, 24139,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26080, 10154,    76, 28356, 26026, 19866])\n",
            "tensor([ 1411, 28179, 26115, 20188, 26026,  7468])\n",
            "context_tensors:  tensor([10154,    76,  6982, 26026, 19866, 16501])\n",
            "context_tensors:  context_tensors: tensor([28179, 26115, 24420, 26026,  7468, 16499]) tensor([   76,  6982, 28356, 19866, 16501,    62])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6982, 28356, 26026, 16501,    62, 15636])tensor([26115, 24420, 20188,  7468, 16499,  1416])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28356, 26026, 19866,    62, 15636,  8437])\n",
            " context_tensors: tensor([24420, 20188, 26026, 16499,  1416, 15606]) tensor([26026, 19866, 16501, 15636,  8437,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([20188, 26026,  7468,  1416, 15606, 19347])tensor([19866, 16501,    62,  8437,  2371, 15921])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  7468, 16499, 15606, 19347,  1657])tensor([16501,    62, 15636,  2371, 15921, 21977])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 7468, 16499,  1416, 19347,  1657, 14227])tensor([   62, 15636,  8437, 15921, 21977, 21285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15636,  8437,  2371, 21977, 21285,    76])\n",
            "tensor([16499,  1416, 15606,  1657, 14227, 10110])\n",
            "context_tensors: context_tensors:   tensor([ 1416, 15606, 19347, 14227, 10110,  6240])tensor([ 8437,  2371, 15921, 21285,    76, 12418])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([15606, 19347,  1657, 10110,  6240, 26285]) \n",
            "context_tensors: tensor([ 2371, 15921, 21977,    76, 12418, 22121]) \n",
            "tensor([19347,  1657, 14227,  6240, 26285, 14227])context_tensors:  tensor([15921, 21977, 21285, 12418, 22121, 13448])\n",
            "\n",
            "tensor([21977, 21285,    76, 22121, 13448, 14227])context_tensors:  \n",
            "context_tensors:  tensor([21285,    76, 12418, 13448, 14227,  3729])context_tensors: \n",
            "context_tensors:  tensor([   76, 12418, 22121, 14227,  3729,  2940])\n",
            " tensor([ 1657, 14227, 10110, 26285, 14227, 11543])context_tensors:  \n",
            "context_tensors: tensor([12418, 22121, 13448,  3729,  2940,  2858]) \n",
            "tensor([14227, 10110,  6240, 14227, 11543,    76])context_tensors: \n",
            " context_tensors: tensor([22121, 13448, 14227,  2940,  2858, 17873]) \n",
            "tensor([10110,  6240, 26285, 11543,    76, 14210])\n",
            "context_tensors:  tensor([13448, 14227,  3729,  2858, 17873, 26147])\n",
            "context_tensors: context_tensors:   tensor([14227,  3729,  2940, 17873, 26147,  4787])tensor([ 6240, 26285, 14227,    76, 14210, 14156])\n",
            "\n",
            "context_tensors:  tensor([26285, 14227, 11543, 14210, 14156, 18253])\n",
            "context_tensors:  tensor([14227, 11543,    76, 14156, 18253,  1410])\n",
            "context_tensors: context_tensors:  tensor([11543,    76, 14210, 18253,  1410, 19348])\n",
            " context_tensors: tensor([ 3729,  2940,  2858, 26147,  4787, 26026]) \n",
            "tensor([   76, 14210, 14156,  1410, 19348, 15606])context_tensors: \n",
            " context_tensors: tensor([ 2940,  2858, 17873,  4787, 26026, 13952])\n",
            " context_tensors:  tensor([14210, 14156, 18253, 19348, 15606, 18832])tensor([ 2858, 17873, 26147, 26026, 13952, 27157])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([14156, 18253,  1410, 15606, 18832, 16502])\n",
            " tensor([17873, 26147,  4787, 13952, 27157, 10866])\n",
            "context_tensors:  context_tensors: tensor([18253,  1410, 19348, 18832, 16502,    79]) \n",
            "context_tensors: tensor([26147,  4787, 26026, 27157, 10866,  6570])\n",
            " context_tensors: tensor([ 1410, 19348, 15606, 16502,    79,  1409])\n",
            " tensor([ 4787, 26026, 13952, 10866,  6570, 18520])context_tensors: \n",
            " tensor([ 1411,  1410, 13448,    76, 26026, 19866])context_tensors: \n",
            " context_tensors: tensor([26026, 13952, 27157,  6570, 18520, 17827])\n",
            " context_tensors: tensor([ 1410, 13448, 17827, 26026, 19866, 16501])\n",
            " context_tensors: tensor([13952, 27157, 10866, 18520, 17827,    72]) \n",
            "context_tensors: tensor([13448, 17827,    76, 19866, 16501, 10366])\n",
            " tensor([27157, 10866,  6570, 17827,    72, 14232])\n",
            "context_tensors:  tensor([10866,  6570, 18520,    72, 14232,    73])context_tensors: \n",
            "context_tensors:   tensor([17827,    76, 26026, 16501, 10366, 16176])tensor([ 6570, 18520, 17827, 14232,    73,    79])\n",
            "\n",
            "context_tensors:  tensor([18520, 17827,    72,    73,    79,  1409])\n",
            "context_tensors:  tensor([   76, 26026, 19866, 10366, 16176, 18605])context_tensors:  \n",
            "tensor([ 1411, 26026,   812,   222,  6141,  4125])context_tensors:  tensor([26026, 19866, 16501, 16176, 18605,  1410])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026,   812, 28846,  6141,  4125, 14252])tensor([19866, 16501, 10366, 18605,  1410, 23788])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  812, 28846,   222,  4125, 14252, 23244])\n",
            "tensor([16501, 10366, 16176,  1410, 23788,  2371])\n",
            "context_tensors: context_tensors:   tensor([10366, 16176, 18605, 23788,  2371, 20065])tensor([28846,   222,  6141, 14252, 23244, 27965])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([  222,  6141,  4125, 23244, 27965, 26026])\n",
            " tensor([16176, 18605,  1410,  2371, 20065, 28457])context_tensors: \n",
            " tensor([ 6141,  4125, 14252, 27965, 26026, 25819])context_tensors:  tensor([18605,  1410, 23788, 20065, 28457,    76])\n",
            "context_tensors: \n",
            " tensor([ 1410, 23788,  2371, 28457,    76,  2371])\n",
            "context_tensors:  context_tensors: tensor([ 4125, 14252, 23244, 26026, 25819,    62]) tensor([23788,  2371, 20065,    76,  2371, 26285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14252, 23244, 27965, 25819,    62,   279])\n",
            "context_tensors: tensor([ 2371, 20065, 28457,  2371, 26285,  1423]) \n",
            "tensor([23244, 27965, 26026,    62,   279, 23244])context_tensors: \n",
            " tensor([20065, 28457,    76, 26285,  1423, 15483])context_tensors: \n",
            "context_tensors:  tensor([27965, 26026, 25819,   279, 23244, 13448])\n",
            " context_tensors: tensor([28457,    76,  2371,  1423, 15483, 10080]) tensor([26026, 25819,    62, 23244, 13448, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([25819,    62,   279, 13448, 26026, 17809]) \n",
            "tensor([   76,  2371, 26285, 15483, 10080, 18605])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 26285,  1423, 10080, 18605, 24115])tensor([   62,   279, 23244, 26026, 17809, 12808])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26285,  1423, 15483, 18605, 24115,  4235])tensor([  279, 23244, 13448, 17809, 12808, 15348])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23244, 13448, 26026, 12808, 15348,    72])tensor([ 1423, 15483, 10080, 24115,  4235, 10627])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 17809, 15348,    72, 18047])tensor([15483, 10080, 18605,  4235, 10627,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 17809, 12808,    72, 18047,    73])tensor([10080, 18605, 24115, 10627,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17809, 12808, 15348, 18047,    73,    79])tensor([ 1411, 14210, 14156,    76, 28356, 10390])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([12808, 15348,    72,    73,    79,  1409]) \n",
            "tensor([14210, 14156, 27761, 28356, 10390, 20578])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026,  4125,     6, 21502, 18520]) \n",
            "tensor([14156, 27761,    76, 10390, 20578, 15728])context_tensors: \n",
            " context_tensors: tensor([26026,  4125, 14252, 21502, 18520,   930])\n",
            " tensor([27761,    76, 28356, 20578, 15728, 18520])context_tensors: \n",
            " context_tensors: tensor([ 4125, 14252,     6, 18520,   930, 28846])\n",
            " context_tensors: tensor([   76, 28356, 10390, 15728, 18520, 18609]) \n",
            "tensor([14252,     6, 21502,   930, 28846,  1080])\n",
            "context_tensors: context_tensors:   tensor([28356, 10390, 20578, 18520, 18609, 18691])tensor([    6, 21502, 18520, 28846,  1080, 28846])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10390, 20578, 15728, 18609, 18691, 26910])tensor([21502, 18520,   930,  1080, 28846,  1234])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([20578, 15728, 18520, 18691, 26910, 28661])tensor([18520,   930, 28846, 28846,  1234,  1418])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  930, 28846,  1080,  1234,  1418, 18259])tensor([15728, 18520, 18609, 26910, 28661, 26023])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28846,  1080, 28846,  1418, 18259,   117])tensor([18520, 18609, 18691, 28661, 26023,  2733])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1080, 28846,  1234, 18259,   117,  1420]) \n",
            "tensor([18609, 18691, 26910, 26023,  2733, 18286])context_tensors: \n",
            " tensor([28846,  1234,  1418,   117,  1420, 27965])context_tensors: \n",
            " context_tensors: tensor([18691, 26910, 28661,  2733, 18286,  8889]) \n",
            "tensor([ 1234,  1418, 18259,  1420, 27965, 26026])\n",
            "context_tensors: context_tensors:   tensor([26910, 28661, 26023, 18286,  8889, 11580])tensor([ 1418, 18259,   117, 27965, 26026, 28471])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28661, 26023,  2733,  8889, 11580, 27604])tensor([18259,   117,  1420, 26026, 28471, 21502])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26023,  2733, 18286, 11580, 27604, 12778])tensor([  117,  1420, 27965, 28471, 21502, 13448])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2733, 18286,  8889, 27604, 12778,    72]) \n",
            "tensor([ 1420, 27965, 26026, 21502, 13448, 26026])context_tensors: \n",
            " tensor([18286,  8889, 11580, 12778,    72,     1])context_tensors: \n",
            " context_tensors: tensor([27965, 26026, 28471, 13448, 26026, 18047])\n",
            " tensor([ 8889, 11580, 27604,    72,     1, 27371])context_tensors: \n",
            " tensor([26026, 28471, 21502, 26026, 18047, 10866])context_tensors:  \n",
            "tensor([11580, 27604, 12778,     1, 27371, 17029])context_tensors: \n",
            " context_tensors: tensor([28471, 21502, 13448, 18047, 10866,   812]) \n",
            "tensor([27604, 12778,    72, 27371, 17029,     1])context_tensors: \n",
            "context_tensors:   tensor([21502, 13448, 26026, 10866,   812, 28846])tensor([12778,    72,     1, 17029,     1,    73])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13448, 26026, 18047,   812, 28846,   222])tensor([   72,     1, 27371,     1,    73,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 18047, 10866, 28846,   222,  2371])tensor([    1, 27371, 17029,    73,    79,  1409])\n",
            "context_tensors: \n",
            " tensor([18047, 10866,   812,   222,  2371, 26026])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26115, 24420,  9026, 27431,  4767])\n",
            " tensor([10866,   812, 28846,  2371, 26026, 10609])\n",
            "context_tensors: context_tensors:  tensor([26115, 24420, 15122, 27431,  4767, 14156]) \n",
            "tensor([  812, 28846,   222, 26026, 10609, 26232])context_tensors:  \n",
            "context_tensors: tensor([24420, 15122,  9026,  4767, 14156,  5245])\n",
            " tensor([28846,   222,  2371, 10609, 26232, 13448])context_tensors: \n",
            " tensor([15122,  9026, 27431, 14156,  5245, 13489])context_tensors: \n",
            " context_tensors:  tensor([  222,  2371, 26026, 26232, 13448, 11034])tensor([ 9026, 27431,  4767,  5245, 13489, 13448])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 2371, 26026, 10609, 13448, 11034, 12777]) tensor([27431,  4767, 14156, 13489, 13448,  4310])\n",
            "\n",
            "context_tensors:  tensor([26026, 10609, 26232, 11034, 12777, 26083])\n",
            "context_tensors:  tensor([ 4767, 14156,  5245, 13448,  4310, 26618])\n",
            "context_tensors: context_tensors:   tensor([14156,  5245, 13489,  4310, 26618,    76])tensor([10609, 26232, 13448, 12777, 26083, 10575])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5245, 13489, 13448, 26618,    76, 28175])tensor([26232, 13448, 11034, 26083, 10575, 13448])\n",
            "\n",
            "context_tensors:  tensor([13489, 13448,  4310,    76, 28175, 14210])context_tensors:  \n",
            "context_tensors:  tensor([13448, 11034, 12777, 10575, 13448, 15252])tensor([13448,  4310, 26618, 28175, 14210, 14156])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 4310, 26618,    76, 14210, 14156, 26135])\n",
            " tensor([11034, 12777, 26083, 13448, 15252, 19854])\n",
            "context_tensors:  context_tensors: tensor([26618,    76, 28175, 14156, 26135, 26285])\n",
            " tensor([12777, 26083, 10575, 15252, 19854,    79])\n",
            "context_tensors: context_tensors:   tensor([26083, 10575, 13448, 19854,    79,  1409])\n",
            "tensor([   76, 28175, 14210, 26135, 26285,  3623])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 14210,  2197, 26026, 26108, 24970]) \n",
            "tensor([28175, 14210, 14156, 26285,  3623, 15481])\n",
            "context_tensors: context_tensors:   tensor([14210,  2197, 16414, 26108, 24970, 28612])tensor([14210, 14156, 26135,  3623, 15481,  1481])\n",
            "\n",
            "context_tensors:  tensor([14156, 26135, 26285, 15481,  1481, 26285])context_tensors: \n",
            " tensor([ 2197, 16414, 26026, 24970, 28612, 26023])context_tensors: \n",
            " tensor([26135, 26285,  3623,  1481, 26285, 28369])context_tensors:  \n",
            "tensor([16414, 26026, 26108, 28612, 26023, 26083])\n",
            "context_tensors: context_tensors:   tensor([26026, 26108, 24970, 26023, 26083, 17141])tensor([26285,  3623, 15481, 26285, 28369, 26015])\n",
            "\n",
            "context_tensors:  tensor([ 3623, 15481,  1481, 28369, 26015, 18832])context_tensors: tensor([26108, 24970, 28612, 26083, 17141, 26026]) \n",
            "\n",
            "context_tensors:  tensor([24970, 28612, 26023, 17141, 26026, 19928])\n",
            "context_tensors:  context_tensors: tensor([15481,  1481, 26285, 26015, 18832, 16502]) \n",
            "tensor([28612, 26023, 26083, 26026, 19928,    79])context_tensors: \n",
            " tensor([ 1481, 26285, 28369, 18832, 16502,  8830])\n",
            "context_tensors: context_tensors:  tensor([26285, 28369, 26015, 16502,  8830, 26285])\n",
            "context_tensors:   tensor([26023, 26083, 17141, 19928,    79,  1409])\n",
            "tensor([28369, 26015, 18832,  8830, 26285, 14227])context_tensors: \n",
            " context_tensors:  tensor([ 1411,  6568,    76, 12153, 26026,  3862])tensor([26015, 18832, 16502, 26285, 14227, 11829])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18832, 16502,  8830, 14227, 11829,  4663]) \n",
            "tensor([ 6568,    76, 26083, 26026,  3862,  5435])\n",
            "context_tensors: context_tensors:   tensor([   76, 26083, 12153,  3862,  5435, 26285])tensor([16502,  8830, 26285, 11829,  4663,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26083, 12153, 26026,  5435, 26285, 21438])tensor([ 8830, 26285, 14227,  4663,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  2858, 14210, 12380,  1423, 15636])tensor([12153, 26026,  3862, 26285, 21438, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2858, 14210,  2197,  1423, 15636,  8437])tensor([26026,  3862,  5435, 21438, 26026, 10609])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([14210,  2197, 12380, 15636,  8437,  2371])tensor([ 3862,  5435, 26285, 26026, 10609, 18923])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2197, 12380,  1423,  8437,  2371, 15921])\n",
            "tensor([ 5435, 26285, 21438, 10609, 18923, 23343])context_tensors: \n",
            " context_tensors:  tensor([12380,  1423, 15636,  2371, 15921,  1410])tensor([26285, 21438, 26026, 18923, 23343, 13448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1423, 15636,  8437, 15921,  1410,    76])\n",
            "context_tensors:   tensor([21438, 26026, 10609, 23343, 13448, 26026])tensor([15636,  8437,  2371,  1410,    76, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026, 10609, 18923, 13448, 26026,   813])\n",
            " tensor([ 8437,  2371, 15921,    76, 26026, 13952])\n",
            "context_tensors: context_tensors:  tensor([10609, 18923, 23343, 26026,   813, 18047])\n",
            " tensor([ 2371, 15921,  1410, 26026, 13952, 27157])context_tensors: \n",
            "context_tensors:   tensor([15921,  1410,    76, 13952, 27157, 10866])tensor([18923, 23343, 13448,   813, 18047,  9552])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1410,    76, 26026, 27157, 10866,  6570])\n",
            " context_tensors: tensor([23343, 13448, 26026, 18047,  9552,  8682])\n",
            "context_tensors:   tensor([13448, 26026,   813,  9552,  8682, 15891])tensor([   76, 26026, 13952, 10866,  6570, 18520])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026,   813, 18047,  8682, 15891,    76]) \n",
            "context_tensors:  tensor([26026, 13952, 27157,  6570, 18520, 17827])tensor([  813, 18047,  9552, 15891,    76,  4767])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18047,  9552,  8682,    76,  4767, 15888])\n",
            "context_tensors: tensor([13952, 27157, 10866, 18520, 17827,    72])\n",
            " context_tensors:  tensor([27157, 10866,  6570, 17827,    72, 14232])\n",
            "tensor([ 9552,  8682, 15891,  4767, 15888, 18854])context_tensors:  tensor([10866,  6570, 18520,    72, 14232,    73])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([ 6570, 18520, 17827, 14232,    73, 12380])\n",
            "tensor([ 8682, 15891,    76, 15888, 18854, 26285])context_tensors: \n",
            " context_tensors: tensor([18520, 17827,    72,    73, 12380, 15696])\n",
            " tensor([15891,    76,  4767, 18854, 26285, 26026])context_tensors: \n",
            " tensor([17827,    72, 14232, 12380, 15696, 14210])\n",
            "context_tensors: context_tensors:   tensor([   76,  4767, 15888, 26285, 26026,  9073])\n",
            "tensor([   72, 14232,    73, 15696, 14210,  2858])\n",
            "context_tensors: context_tensors:  tensor([ 4767, 15888, 18854, 26026,  9073, 18560]) \n",
            "tensor([14232,    73, 12380, 14210,  2858, 17873])context_tensors: \n",
            " context_tensors: tensor([15888, 18854, 26285,  9073, 18560,  2371]) \n",
            "tensor([   73, 12380, 15696,  2858, 17873, 26147])\n",
            " context_tensors: context_tensors:  tensor([12380, 15696, 14210, 17873, 26147,    79])\n",
            "tensor([18854, 26285, 26026, 18560,  2371, 21439])context_tensors: \n",
            " context_tensors: tensor([15696, 14210,  2858, 26147,    79,  1409])\n",
            "context_tensors:   tensor([26285, 26026,  9073,  2371, 21439, 26026])tensor([ 1411, 26026, 10609,  7915, 18520, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 10609, 23118, 18520, 26026, 19866]) tensor([26026,  9073, 18560, 21439, 26026, 23265])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 9073, 18560,  2371, 26026, 23265, 19733])\n",
            "tensor([10609, 23118,  7915, 26026, 19866, 16501])\n",
            "context_tensors:  context_tensors:  tensor([23118,  7915, 18520, 19866, 16501, 27965])\n",
            "tensor([18560,  2371, 21439, 23265, 19733, 13827])\n",
            "context_tensors: context_tensors:   tensor([ 7915, 18520, 26026, 16501, 27965,  3159])tensor([ 2371, 21439, 26026, 19733, 13827,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18520, 26026, 19866, 27965,  3159,  4787])\n",
            " context_tensors: tensor([21439, 26026, 23265, 13827,    79,  1409])\n",
            " tensor([26026, 19866, 16501,  3159,  4787,  6246])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26026,  4125,  3705, 26026, 28612])\n",
            "context_tensors:   tensor([19866, 16501, 27965,  4787,  6246, 23118])\n",
            "tensor([26026,  4125, 14252, 26026, 28612, 28356])\n",
            "context_tensors:  context_tensors: tensor([16501, 27965,  3159,  6246, 23118,  2371]) tensor([ 4125, 14252,  3705, 28612, 28356, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([27965,  3159,  4787, 23118,  2371, 13605])\n",
            " tensor([14252,  3705, 26026, 28356, 26026, 28471])context_tensors: \n",
            " tensor([ 3159,  4787,  6246,  2371, 13605, 22010])\n",
            "context_tensors: context_tensors:   tensor([ 4787,  6246, 23118, 13605, 22010, 18738])\n",
            "tensor([ 3705, 26026, 28612, 26026, 28471, 24745])context_tensors: \n",
            " tensor([ 6246, 23118,  2371, 22010, 18738,    72])\n",
            "context_tensors: context_tensors:   tensor([23118,  2371, 13605, 18738,    72,  7242])\n",
            "tensor([26026, 28612, 28356, 28471, 24745, 13448])context_tensors: \n",
            "context_tensors:  tensor([ 2371, 13605, 22010,    72,  7242,    73])\n",
            " context_tensors:  tensor([28612, 28356, 26026, 24745, 13448, 11034])\n",
            "tensor([13605, 22010, 18738,  7242,    73, 22012])\n",
            "context_tensors:  tensor([28356, 26026, 28471, 13448, 11034, 12777])\n",
            "context_tensors:  tensor([26026, 28471, 24745, 11034, 12777,  2371])\n",
            "context_tensors:  context_tensors: tensor([28471, 24745, 13448, 12777,  2371, 26026])\n",
            "context_tensors:  tensor([24745, 13448, 11034,  2371, 26026, 28471]) \n",
            "tensor([22010, 18738,    72,    73, 22012, 19612])context_tensors:  tensor([13448, 11034, 12777, 26026, 28471,  4787])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([18738,    72,  7242, 22012, 19612, 15252])tensor([11034, 12777,  2371, 28471,  4787,  2553])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12777,  2371, 26026,  4787,  2553, 25819])\n",
            "tensor([   72,  7242,    73, 19612, 15252, 13448])\n",
            "context_tensors:  tensor([ 2371, 26026, 28471,  2553, 25819, 13448])\n",
            "context_tensors: context_tensors:   tensor([ 7242,    73, 22012, 15252, 13448,  1423])tensor([26026, 28471,  4787, 25819, 13448,  2334])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([28471,  4787,  2553, 13448,  2334, 18047])tensor([   73, 22012, 19612, 13448,  1423,   772])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22012, 19612, 15252,  1423,   772, 14201])tensor([ 4787,  2553, 25819,  2334, 18047, 23244])\n",
            "\n",
            "context_tensors:  tensor([19612, 15252, 13448,   772, 14201, 18520])\n",
            "context_tensors: context_tensors:  tensor([15252, 13448,  1423, 14201, 18520, 16790])\n",
            " context_tensors:  tensor([13448,  1423,   772, 18520, 16790, 18520])\n",
            "tensor([ 2553, 25819, 13448, 18047, 23244, 13448])context_tensors: \n",
            " context_tensors: tensor([ 1423,   772, 14201, 16790, 18520, 26026]) \n",
            "tensor([25819, 13448,  2334, 23244, 13448,   664])context_tensors:  \n",
            "tensor([  772, 14201, 18520, 18520, 26026, 17809])context_tensors: \n",
            " context_tensors: tensor([13448,  2334, 18047, 13448,   664, 28614]) \n",
            "tensor([14201, 18520, 16790, 26026, 17809, 17625])context_tensors: \n",
            " tensor([ 2334, 18047, 23244,   664, 28614,    79])context_tensors:  \n",
            "tensor([18520, 16790, 18520, 17809, 17625, 18520])context_tensors: \n",
            " tensor([18047, 23244, 13448, 28614,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([16790, 18520, 26026, 17625, 18520, 27628]) \n",
            "tensor([ 1411,  1900,  2334, 28846,   879, 28846])\n",
            "context_tensors: context_tensors:   tensor([18520, 26026, 17809, 18520, 27628,    79])tensor([ 1900,  2334,   162,   879, 28846,  1108])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 17809, 17625, 27628,    79,  1409])tensor([ 2334,   162, 28846, 28846,  1108, 24745])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411, 26026, 24421,  1410,  6170, 11158])tensor([  162, 28846,   879,  1108, 24745,    76])\n",
            "\n",
            "context_tensors:  tensor([28846,   879, 28846, 24745,    76, 12452])context_tensors: \n",
            " context_tensors: tensor([26026, 24421, 17740,  6170, 11158, 26026]) \n",
            "tensor([  879, 28846,  1108,    76, 12452,  5963])\n",
            "context_tensors:  context_tensors: tensor([24421, 17740,  1410, 11158, 26026, 15268]) \n",
            "tensor([28846,  1108, 24745, 12452,  5963, 23146])context_tensors: \n",
            " tensor([17740,  1410,  6170, 26026, 15268,  2334])\n",
            "context_tensors:  tensor([ 1108, 24745,    76,  5963, 23146,  2802])context_tensors: \n",
            " context_tensors:  tensor([24745,    76, 12452, 23146,  2802, 27965])\n",
            "context_tensors: tensor([ 1410,  6170, 11158, 15268,  2334,    72]) \n",
            "tensor([   76, 12452,  5963,  2802, 27965, 10597])context_tensors: \n",
            " tensor([ 6170, 11158, 26026,  2334,    72,     1])\n",
            "context_tensors: context_tensors:  tensor([11158, 26026, 15268,    72,     1, 18253])\n",
            " tensor([12452,  5963, 23146, 27965, 10597,  2371])\n",
            "context_tensors: context_tensors:  tensor([ 5963, 23146,  2802, 10597,  2371, 21929])\n",
            "context_tensors:  tensor([23146,  2802, 27965,  2371, 21929,  4787])\n",
            " context_tensors:  tensor([26026, 15268,  2334,     1, 18253,     1])tensor([ 2802, 27965, 10597, 21929,  4787,  2956])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15268,  2334,    72, 18253,     1,    73])\n",
            "tensor([27965, 10597,  2371,  4787,  2956,  5963])\n",
            "context_tensors:  context_tensors: tensor([2334,   72,    1,    1,   73, 2371]) tensor([10597,  2371, 21929,  2956,  5963, 26294])\n",
            "context_tensors:  \n",
            "tensor([   72,     1, 18253,    73,  2371,  1410])context_tensors: \n",
            " context_tensors: tensor([ 2371, 21929,  4787,  5963, 26294, 22303]) \n",
            "tensor([    1, 18253,     1,  2371,  1410,    72])context_tensors: \n",
            "context_tensors:   tensor([21929,  4787,  2956, 26294, 22303,    79])\n",
            "tensor([18253,     1,    73,  1410,    72,     1])context_tensors:  tensor([ 4787,  2956,  5963, 22303,    79,  1409])\n",
            "\n",
            "context_tensors:  tensor([    1,    73,  2371,    72,     1, 16414])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026, 20104, 20664, 23506, 19581]) \n",
            "tensor([   73,  2371,  1410,     1, 16414,     1])context_tensors: \n",
            " context_tensors: tensor([26026, 20104, 23244, 23506, 19581,  5448]) \n",
            "tensor([ 2371,  1410,    72, 16414,     1,    73])\n",
            "context_tensors: context_tensors:   tensor([1410,   72,    1,    1,   73,   76])tensor([20104, 23244, 20664, 19581,  5448, 13497])\n",
            "\n",
            "context_tensors:  tensor([   72,     1, 16414,    73,    76,  2371])context_tensors: \n",
            " context_tensors: tensor([23244, 20664, 23506,  5448, 13497, 26026]) \n",
            "tensor([    1, 16414,     1,    76,  2371, 21598])\n",
            "context_tensors: context_tensors:   tensor([20664, 23506, 19581, 13497, 26026, 26477])tensor([16414,     1,    73,  2371, 21598, 26285])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([    1,    73,    76, 21598, 26285, 26026]) \n",
            "tensor([23506, 19581,  5448, 26026, 26477, 18520])context_tensors:  \n",
            "context_tensors: tensor([   73,    76,  2371, 26285, 26026, 21321]) \n",
            "tensor([19581,  5448, 13497, 26477, 18520,  2128])\n",
            "context_tensors:  context_tensors: tensor([   76,  2371, 21598, 26026, 21321,    62]) \n",
            "tensor([ 5448, 13497, 26026, 18520,  2128,  1416])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 21598, 26285, 21321,    62,  6117])tensor([13497, 26026, 26477,  2128,  1416, 24727])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([26026, 26477, 18520,  1416, 24727, 10975]) \n",
            "tensor([21598, 26285, 26026,    62,  6117,    79])context_tensors: \n",
            " context_tensors: tensor([26477, 18520,  2128, 24727, 10975, 14343]) \n",
            "tensor([26285, 26026, 21321,  6117,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([18520,  2128,  1416, 10975, 14343,  5146])\n",
            " context_tensors: tensor([ 1411, 26026, 12852,  1423, 16217,   831]) \n",
            "tensor([ 2128,  1416, 24727, 14343,  5146,    76])\n",
            "context_tensors:  context_tensors:  tensor([ 1416, 24727, 10975,  5146,    76, 28200])tensor([26026, 12852, 14156, 16217,   831,  1417])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24727, 10975, 14343,    76, 28200, 27965])\n",
            "tensor([12852, 14156,  1423,   831,  1417,   792])\n",
            "context_tensors: context_tensors:   tensor([14156,  1423, 16217,  1417,   792,  5953])\n",
            "tensor([10975, 14343,  5146, 28200, 27965,  1647])\n",
            "context_tensors: context_tensors:  tensor([ 1423, 16217,   831,   792,  5953,    72]) \n",
            "tensor([14343,  5146,    76, 27965,  1647, 28356])\n",
            "context_tensors:  context_tensors: tensor([16217,   831,  1417,  5953,    72,  1302]) \n",
            "context_tensors: tensor([ 5146,    76, 28200,  1647, 28356, 17546])\n",
            " tensor([ 831, 1417,  792,   72, 1302, 1417])\n",
            "context_tensors:  context_tensors: tensor([1417,  792, 5953, 1302, 1417,  942])\n",
            "context_tensors:  tensor([   76, 28200, 27965, 28356, 17546, 10225]) tensor([  792,  5953,    72,  1417,   942, 13448])\n",
            "context_tensors: \n",
            " tensor([ 5953,    72,  1302,   942, 13448,    73])context_tensors: \n",
            " context_tensors: tensor([28200, 27965,  1647, 17546, 10225,  8889]) \n",
            "tensor([   72,  1302,  1417, 13448,    73,  1657])\n",
            "context_tensors:  context_tensors: tensor([1302, 1417,  942,   73, 1657,   76]) \n",
            "tensor([27965,  1647, 28356, 10225,  8889, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 1417,   942, 13448,  1657,    76,  5245])tensor([ 1647, 28356, 17546,  8889, 26026, 18521])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28356, 17546, 10225, 26026, 18521,  1416])\n",
            " tensor([  942, 13448,    73,    76,  5245, 18521])\n",
            "context_tensors:  tensor([17546, 10225,  8889, 18521,  1416, 23244])\n",
            "context_tensors: context_tensors:  tensor([10225,  8889, 26026,  1416, 23244,    79]) tensor([13448,    73,  1657,  5245, 18521, 28126])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   73,  1657,    76, 18521, 28126,  3149]) \n",
            "tensor([ 8889, 26026, 18521, 23244,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([ 1657,    76,  5245, 28126,  3149,  1407])\n",
            "context_tensors:   tensor([ 1411, 28356, 26026, 18520,  2475, 21424])tensor([   76,  5245, 18521,  3149,  1407, 23506])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28356, 26026, 20718,  2475, 21424, 15859])tensor([ 5245, 18521, 28126,  1407, 23506,  1410])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18521, 28126,  3149, 23506,  1410, 28115]) \n",
            "tensor([26026, 20718, 18520, 21424, 15859, 26026])context_tensors: \n",
            "context_tensors:  tensor([28126,  3149,  1407,  1410, 28115,  2197]) \n",
            "tensor([20718, 18520,  2475, 15859, 26026,  4125])context_tensors: \n",
            " context_tensors:  tensor([ 3149,  1407, 23506, 28115,  2197,  7925])tensor([18520,  2475, 21424, 26026,  4125, 14252])\n",
            "\n",
            "context_tensors:  tensor([ 2475, 21424, 15859,  4125, 14252,     6])context_tensors: \n",
            " tensor([ 1407, 23506,  1410,  2197,  7925,    79])context_tensors:  \n",
            "tensor([21424, 15859, 26026, 14252,     6,  5035])context_tensors: \n",
            " tensor([23506,  1410, 28115,  7925,    79,  1409])context_tensors: \n",
            " tensor([15859, 26026,  4125,     6,  5035,  2371])context_tensors: \n",
            " context_tensors: tensor([ 1411, 15252, 25927, 26026, 24420, 13448]) \n",
            "tensor([26026,  4125, 14252,  5035,  2371,  3862])\n",
            "context_tensors: context_tensors:  tensor([15252, 25927, 19855, 24420, 13448, 26026]) \n",
            "tensor([ 4125, 14252,     6,  2371,  3862, 19922])\n",
            "context_tensors: context_tensors:   tensor([14252,     6,  5035,  3862, 19922,    76])tensor([25927, 19855, 26026, 13448, 26026, 11543])\n",
            "context_tensors:  tensor([    6,  5035,  2371, 19922,    76, 22312])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 5035,  2371,  3862,    76, 22312, 17794]) \n",
            "tensor([19855, 26026, 24420, 26026, 11543,  7490])\n",
            "context_tensors:  context_tensors:  tensor([ 2371,  3862, 19922, 22312, 17794,    76])tensor([26026, 24420, 13448, 11543,  7490,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24420, 13448, 26026,  7490,    76, 18273])\n",
            "tensor([ 3862, 19922,    76, 17794,    76, 21993])\n",
            "context_tensors: context_tensors:   tensor([ 1411,  8889, 26026,  6141, 16249, 18616])tensor([19922,    76, 22312,    76, 21993, 26285])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 22312, 17794, 21993, 26285,  3623])\n",
            " tensor([ 8889, 26026, 23244, 16249, 18616, 26910])context_tensors: \n",
            " tensor([22312, 17794,    76, 26285,  3623, 26478])context_tensors: \n",
            " tensor([26026, 23244,  6141, 18616, 26910, 28321])context_tensors: \n",
            " tensor([17794,    76, 21993,  3623, 26478,    76])context_tensors: \n",
            " tensor([23244,  6141, 16249, 26910, 28321, 25004])context_tensors: \n",
            " context_tensors: tensor([   76, 21993, 26285, 26478,    76, 26134]) \n",
            "tensor([ 6141, 16249, 18616, 28321, 25004, 18520])\n",
            "context_tensors:  context_tensors: tensor([21993, 26285,  3623,    76, 26134, 12451]) \n",
            "tensor([16249, 18616, 26910, 25004, 18520, 26151])\n",
            "context_tensors:  tensor([26285,  3623, 26478, 26134, 12451, 28479])\n",
            "context_tensors: context_tensors:   tensor([18616, 26910, 28321, 18520, 26151, 18691])tensor([ 3623, 26478,    76, 12451, 28479, 21807])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26478,    76, 26134, 28479, 21807, 28356])tensor([26910, 28321, 25004, 26151, 18691, 17392])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([28321, 25004, 18520, 18691, 17392, 11372])\n",
            " tensor([   76, 26134, 12451, 21807, 28356, 26026])\n",
            "context_tensors: context_tensors:   tensor([25004, 18520, 26151, 17392, 11372,    79])tensor([26134, 12451, 28479, 28356, 26026, 25819])\n",
            "\n",
            "context_tensors:  tensor([18520, 26151, 18691, 11372,    79,  1409])context_tensors: \n",
            " tensor([12451, 28479, 21807, 26026, 25819, 10866])\n",
            "context_tensors:  tensor([ 1411, 18609, 18520,  4914, 26438, 26026])context_tensors:  \n",
            "tensor([28479, 21807, 28356, 25819, 10866, 26026])\n",
            "context_tensors: context_tensors:  tensor([18609, 18520, 28175, 26438, 26026,  9405]) tensor([21807, 28356, 26026, 10866, 26026,  9535])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([18520, 28175,  4914, 26026,  9405, 18520])tensor([28356, 26026, 25819, 26026,  9535, 23244])\n",
            "\n",
            "context_tensors:  tensor([26026, 25819, 10866,  9535, 23244,    79])\n",
            "context_tensors:  tensor([28175,  4914, 26438,  9405, 18520, 26026])context_tensors: \n",
            " tensor([25819, 10866, 26026, 23244,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([ 1411, 26026, 25819, 14092, 13448,  1423])\n",
            " tensor([ 4914, 26438, 26026, 18520, 26026, 28612])context_tensors:  \n",
            "tensor([26026, 25819, 27965, 13448,  1423,  6744])context_tensors:  \n",
            "tensor([26438, 26026,  9405, 26026, 28612, 12569])\n",
            "context_tensors:  tensor([25819, 27965, 14092,  1423,  6744, 15886])\n",
            "context_tensors: context_tensors:   tensor([26026,  9405, 18520, 28612, 12569, 26026])tensor([27965, 14092, 13448,  6744, 15886, 26285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14092, 13448,  1423, 15886, 26285, 26026])tensor([ 9405, 18520, 26026, 12569, 26026,  4125])\n",
            "\n",
            "context_tensors:  tensor([13448,  1423,  6744, 26285, 26026, 15881])context_tensors: \n",
            " tensor([18520, 26026, 28612, 26026,  4125, 14252])context_tensors: \n",
            " tensor([ 1423,  6744, 15886, 26026, 15881,  2400])context_tensors: \n",
            " tensor([26026, 28612, 12569,  4125, 14252, 10574])context_tensors: \n",
            " tensor([ 6744, 15886, 26285, 15881,  2400, 14870])\n",
            "context_tensors:  context_tensors: tensor([28612, 12569, 26026, 14252, 10574, 28356])\n",
            " tensor([15886, 26285, 26026,  2400, 14870,    76])context_tensors: \n",
            " tensor([12569, 26026,  4125, 10574, 28356,  1206])\n",
            "context_tensors:  context_tensors: tensor([26285, 26026, 15881, 14870,    76, 28165]) \n",
            "tensor([26026,  4125, 14252, 28356,  1206, 20015])\n",
            "context_tensors:  tensor([26026, 15881,  2400,    76, 28165, 26026])context_tensors: \n",
            " context_tensors: tensor([ 4125, 14252, 10574,  1206, 20015,    76])\n",
            " context_tensors: tensor([15881,  2400, 14870, 28165, 26026, 24726]) \n",
            "tensor([14252, 10574, 28356, 20015,    76, 26026])\n",
            "context_tensors:  context_tensors: tensor([ 2400, 14870,    76, 26026, 24726,  5334])\n",
            " tensor([10574, 28356,  1206,    76, 26026, 26108])context_tensors: \n",
            " tensor([14870,    76, 28165, 24726,  5334,  5911])\n",
            "context_tensors: context_tensors:   tensor([28356,  1206, 20015, 26026, 26108, 28471])tensor([   76, 28165, 26026,  5334,  5911,  2606])\n",
            "\n",
            "context_tensors:  tensor([ 1206, 20015,    76, 26108, 28471, 20010])\n",
            "context_tensors: context_tensors:  tensor([20015,    76, 26026, 28471, 20010, 26404])\n",
            " tensor([28165, 26026, 24726,  5911,  2606, 26285])context_tensors:  tensor([   76, 26026, 26108, 20010, 26404, 13448])\n",
            "\n",
            "context_tensors:  tensor([26026, 24726,  5334,  2606, 26285, 11092])\n",
            "context_tensors:  tensor([24726,  5334,  5911, 26285, 11092,  3017])\n",
            "context_tensors:  tensor([ 5334,  5911,  2606, 11092,  3017,   117])\n",
            "context_tensors:  context_tensors:  tensor([26026, 26108, 28471, 26404, 13448, 11034])\n",
            "tensor([ 5911,  2606, 26285,  3017,   117,  1417])\n",
            "context_tensors: context_tensors:   \n",
            "tensor([ 2606, 26285, 11092,   117,  1417,  1302])tensor([26108, 28471, 20010, 13448, 11034, 12777])\n",
            "context_tensors: context_tensors:   tensor([28471, 20010, 26404, 11034, 12777,    79])tensor([26285, 11092,  3017,  1417,  1302, 23269])\n",
            "\n",
            "context_tensors:  tensor([11092,  3017,   117,  1302, 23269,  2164])\n",
            "context_tensors:  tensor([ 3017,   117,  1417, 23269,  2164, 26026])\n",
            "context_tensors: context_tensors:  tensor([20010, 26404, 13448, 12777,    79,  1409])\n",
            "context_tensors:   tensor([ 1411, 13448, 26026,  1416, 23244, 26026])tensor([  117,  1417,  1302,  2164, 26026, 14870])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1417,  1302, 23269, 26026, 14870, 26232]) tensor([13448, 26026, 18521, 23244, 26026,  4125])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 18521,  1416, 26026,  4125, 14252])\n",
            "tensor([ 1302, 23269,  2164, 14870, 26232, 26285])context_tensors: \n",
            " tensor([18521,  1416, 23244,  4125, 14252,     6])\n",
            "context_tensors:  tensor([ 1416, 23244, 26026, 14252,     6,  2646])context_tensors:  \n",
            "context_tensors:  tensor([23269,  2164, 26026, 26232, 26285, 23133])\n",
            "context_tensors: tensor([23244, 26026,  4125,     6,  2646, 26285])\n",
            " tensor([ 2164, 26026, 14870, 26285, 23133, 26026])context_tensors: \n",
            " context_tensors: tensor([26026,  4125, 14252,  2646, 26285,  4666]) \n",
            "tensor([26026, 14870, 26232, 23133, 26026, 26911])context_tensors: \n",
            "context_tensors:  tensor([14870, 26232, 26285, 26026, 26911, 11723]) \n",
            "tensor([ 4125, 14252,     6, 26285,  4666, 26040])\n",
            "context_tensors:  context_tensors:  tensor([26232, 26285, 23133, 26911, 11723,    76])\n",
            "tensor([14252,     6,  2646,  4666, 26040, 25819])context_tensors: \n",
            " tensor([26285, 23133, 26026, 11723,    76,  3698])\n",
            "context_tensors: context_tensors:  tensor([    6,  2646, 26285, 26040, 25819,  5447]) tensor([23133, 26026, 26911,    76,  3698, 28321])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 2646, 26285,  4666, 25819,  5447,    76]) tensor([26026, 26911, 11723,  3698, 28321, 13448])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26911, 11723,    76, 28321, 13448, 18973])\n",
            " tensor([26285,  4666, 26040,  5447,    76, 17517])context_tensors: \n",
            " tensor([11723,    76,  3698, 13448, 18973,    79])\n",
            "context_tensors: context_tensors:  tensor([ 4666, 26040, 25819,    76, 17517, 11158]) \n",
            "tensor([   76,  3698, 28321, 18973,    79,  1409])context_tensors: \n",
            " tensor([26040, 25819,  5447, 17517, 11158,  1423])\n",
            "context_tensors: context_tensors:   tensor([24755, 26023, 12451, 18145, 13901, 18520])tensor([25819,  5447,    76, 11158,  1423, 25819])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26023, 12451, 12153, 13901, 18520, 26485]) \n",
            "tensor([ 5447,    76, 17517,  1423, 25819, 18520])context_tensors: \n",
            " context_tensors: tensor([12451, 12153, 18145, 18520, 26485, 17794])\n",
            " tensor([   76, 17517, 11158, 25819, 18520, 28661])\n",
            "context_tensors:  context_tensors:  tensor([12153, 18145, 13901, 26485, 17794,    79])tensor([17517, 11158,  1423, 18520, 28661,  8015])\n",
            "\n",
            "context_tensors:  tensor([18145, 13901, 18520, 17794,    79,  1409])context_tensors: \n",
            " tensor([11158,  1423, 25819, 28661,  8015, 19923])\n",
            "context_tensors:  tensor([ 1423, 25819, 18520,  8015, 19923, 14014])context_tensors:  tensor([ 1411, 17392, 22690, 26285, 15589, 28165])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([17392, 22690,  4914, 15589, 28165, 21953])\n",
            "tensor([25819, 18520, 28661, 19923, 14014, 18609])\n",
            "context_tensors:  tensor([22690,  4914, 26285, 28165, 21953,  3099])\n",
            "context_tensors:  context_tensors: tensor([18520, 28661,  8015, 14014, 18609, 28356])\n",
            " tensor([ 4914, 26285, 15589, 21953,  3099, 26285])\n",
            "context_tensors: context_tensors:  tensor([28661,  8015, 19923, 18609, 28356,  9705])\n",
            " tensor([26285, 15589, 28165,  3099, 26285,  1410])context_tensors: \n",
            "context_tensors:   tensor([ 8015, 19923, 14014, 28356,  9705, 19923])tensor([15589, 28165, 21953, 26285,  1410,  7900])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28165, 21953,  3099,  1410,  7900, 24564])\n",
            " context_tensors: tensor([19923, 14014, 18609,  9705, 19923,    79])\n",
            " tensor([21953,  3099, 26285,  7900, 24564, 24755])\n",
            "context_tensors: context_tensors:   tensor([ 3099, 26285,  1410, 24564, 24755, 26023])\n",
            "tensor([14014, 18609, 28356, 19923,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([26285,  1410,  7900, 24755, 26023,  5146]) \n",
            "tensor([ 1411, 26026, 10609, 11505, 16251, 23146])\n",
            "context_tensors: context_tensors:   tensor([ 1410,  7900, 24564, 26023,  5146, 27965])tensor([26026, 10609,  7537, 16251, 23146, 13010])\n",
            "\n",
            "context_tensors:  tensor([10609,  7537, 11505, 23146, 13010, 16104])\n",
            "context_tensors:  context_tensors: tensor([ 7900, 24564, 24755,  5146, 27965, 27132])\n",
            " tensor([ 7537, 11505, 16251, 13010, 16104, 27965])\n",
            "context_tensors:  tensor([24564, 24755, 26023, 27965, 27132, 13448])\n",
            "context_tensors:  context_tensors: tensor([11505, 16251, 23146, 16104, 27965, 26026])\n",
            " context_tensors:  tensor([24755, 26023,  5146, 27132, 13448,  6141])tensor([16251, 23146, 13010, 27965, 26026,  1649])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([23146, 13010, 16104, 26026,  1649, 18520]) tensor([26023,  5146, 27965, 13448,  6141,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5146, 27965, 27132,  6141,  2371,  7753])tensor([13010, 16104, 27965,  1649, 18520,  2128])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([27965, 27132, 13448,  2371,  7753,  1423])tensor([16104, 27965, 26026, 18520,  2128,  1416])\n",
            "\n",
            "context_tensors:  tensor([27132, 13448,  6141,  7753,  1423, 26477])\n",
            "context_tensors:  tensor([27965, 26026,  1649,  2128,  1416, 24727])\n",
            "context_tensors: context_tensors:  tensor([26026,  1649, 18520,  1416, 24727, 10975])\n",
            "context_tensors:   tensor([ 1649, 18520,  2128, 24727, 10975, 14343])tensor([13448,  6141,  2371,  1423, 26477,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18520,  2128,  1416, 10975, 14343,  5146])\n",
            "tensor([ 6141,  2371,  7753, 26477,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 2128,  1416, 24727, 14343,  5146, 18605])tensor([ 1411, 13010,    76,  2371, 12762,  1924])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([13010,    76,  5146, 12762,  1924,  2128])tensor([ 1416, 24727, 10975,  5146, 18605, 14553])\n",
            "\n",
            "context_tensors:  tensor([  76, 5146, 2371, 1924, 2128, 7793])\n",
            "context_tensors:  tensor([ 5146,  2371, 12762,  2128,  7793, 26023])\n",
            "context_tensors: context_tensors:   tensor([ 2371, 12762,  1924,  7793, 26023,  1423])tensor([24727, 10975, 14343, 18605, 14553,   855])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10975, 14343,  5146, 14553,   855,    76])\n",
            "tensor([12762,  1924,  2128, 26023,  1423, 26477])\n",
            "context_tensors: context_tensors:  tensor([14343,  5146, 18605,   855,    76,   812])\n",
            " tensor([ 1924,  2128,  7793,  1423, 26477, 21992])\n",
            "context_tensors: context_tensors:   tensor([ 2128,  7793, 26023, 26477, 21992, 27965])tensor([ 5146, 18605, 14553,    76,   812,    79])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 7793, 26023,  1423, 21992, 27965,  9810]) \n",
            "tensor([18605, 14553,   855,   812,    79,  1409])\n",
            "context_tensors:  context_tensors: tensor([26023,  1423, 26477, 27965,  9810, 16104])\n",
            " tensor([ 1411, 26026,  7537,  1410,  1410,    76])context_tensors: \n",
            " tensor([ 1423, 26477, 21992,  9810, 16104,    76])context_tensors: \n",
            " tensor([26026,  7537, 23407,  1410,    76,  6141])context_tensors: \n",
            "context_tensors:   tensor([26477, 21992, 27965, 16104,    76,  2371])tensor([ 7537, 23407,  1410,    76,  6141,     6])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23407,  1410,  1410,  6141,     6, 10609])\n",
            "tensor([21992, 27965,  9810,    76,  2371, 26083])context_tensors: \n",
            " tensor([ 1410,  1410,    76,     6, 10609,  1416])\n",
            "context_tensors:  context_tensors: tensor([27965,  9810, 16104,  2371, 26083, 28115])\n",
            " tensor([ 1410,    76,  6141, 10609,  1416, 22600])context_tensors:  tensor([ 9810, 16104,    76, 26083, 28115, 27253])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([16104,    76,  2371, 28115, 27253, 28167])\n",
            " tensor([   76,  6141,     6,  1416, 22600,  8682])\n",
            "context_tensors: context_tensors:   tensor([ 6141,     6, 10609, 22600,  8682,  5638])\n",
            "context_tensors:  tensor([    6, 10609,  1416,  8682,  5638,    76])\n",
            "tensor([   76,  2371, 26083, 27253, 28167, 26026])\n",
            "context_tensors:  tensor([10609,  1416, 22600,  5638,    76, 26026])\n",
            "context_tensors:  tensor([ 2371, 26083, 28115, 28167, 26026, 21953])context_tensors:  tensor([ 1416, 22600,  8682,    76, 26026,  9127])\n",
            "\n",
            "context_tensors:  tensor([22600,  8682,  5638, 26026,  9127, 18923])\n",
            "context_tensors: context_tensors:   tensor([26083, 28115, 27253, 26026, 21953, 28115])tensor([ 8682,  5638,    76,  9127, 18923,    76])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 5638,    76, 26026, 18923,    76,  2371]) \n",
            "tensor([28115, 27253, 28167, 21953, 28115,  6181])\n",
            "context_tensors:  tensor([   76, 26026,  9127,    76,  2371, 26040])\n",
            "context_tensors: context_tensors:   tensor([26026,  9127, 18923,  2371, 26040, 26108])\n",
            "tensor([27253, 28167, 26026, 28115,  6181, 11158])\n",
            "context_tensors:  context_tensors: tensor([ 9127, 18923,    76, 26040, 26108,  1416])\n",
            " context_tensors: tensor([28167, 26026, 21953,  6181, 11158,    79]) tensor([18923,    76,  2371, 26108,  1416, 22600])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([   76,  2371, 26040,  1416, 22600, 19733])\n",
            "tensor([26026, 21953, 28115, 11158,    79,  1409])context_tensors: \n",
            "context_tensors:  tensor([ 1411, 28356, 26026,  7531,  2649,    76]) \n",
            "tensor([ 2371, 26040, 26108, 22600, 19733, 13448])\n",
            "context_tensors: context_tensors:  tensor([26040, 26108,  1416, 19733, 13448, 26026])\n",
            "context_tensors:  tensor([28356, 26026, 26477,  2649,    76, 24450]) tensor([26108,  1416, 22600, 13448, 26026,   812])\n",
            "\n",
            "context_tensors:  tensor([ 1416, 22600, 19733, 26026,   812,  8682])\n",
            "context_tensors:  context_tensors: tensor([26026, 26477,  7531,    76, 24450, 19734]) \n",
            "tensor([22600, 19733, 13448,   812,  8682, 26285])\n",
            "context_tensors: context_tensors:   tensor([26477,  7531,  2649, 24450, 19734, 27275])tensor([19733, 13448, 26026,  8682, 26285, 26026])\n",
            "context_tensors: \n",
            " tensor([ 7531,  2649,    76, 19734, 27275, 18605])\n",
            "context_tensors:  tensor([13448, 26026,   812, 26285, 26026, 19660])context_tensors:  tensor([ 2649,    76, 24450, 27275, 18605, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 24450, 19734, 18605, 26026,  4125])\n",
            " tensor([26026,   812,  8682, 26026, 19660,  1410])context_tensors: \n",
            " tensor([24450, 19734, 27275, 26026,  4125, 14252])context_tensors: \n",
            " tensor([  812,  8682, 26285, 19660,  1410, 13448])context_tensors: \n",
            " context_tensors: tensor([19734, 27275, 18605,  4125, 14252, 26485]) tensor([ 8682, 26285, 26026,  1410, 13448,  9889])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26285, 26026, 19660, 13448,  9889, 10866])tensor([27275, 18605, 26026, 14252, 26485,  5146])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18605, 26026,  4125, 26485,  5146,    79]) \n",
            "tensor([26026, 19660,  1410,  9889, 10866,  5146])context_tensors: \n",
            "context_tensors:   tensor([26026,  4125, 14252,  5146,    79,  1409])\n",
            "tensor([19660,  1410, 13448, 10866,  5146,    79])\n",
            "context_tensors:  context_tensors:  tensor([ 1410, 13448,  9889,  5146,    79,  1409])tensor([ 1411, 21953, 28115,  6141, 27965, 26780])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([21953, 28115, 26023, 27965, 26780, 26285])\n",
            "tensor([ 1411, 26026, 26477,  1423, 20181, 22088])\n",
            "context_tensors:  tensor([28115, 26023,  6141, 26780, 26285, 26477])\n",
            "context_tensors: context_tensors:  tensor([26026, 26477, 21439, 20181, 22088, 13448]) tensor([26023,  6141, 27965, 26285, 26477,  5146])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26477, 21439,  1423, 22088, 13448,  6141]) \n",
            "tensor([ 6141, 27965, 26780, 26477,  5146,  2371])context_tensors: \n",
            " tensor([21439,  1423, 20181, 13448,  6141, 11158])context_tensors: \n",
            " tensor([27965, 26780, 26285,  5146,  2371, 26023])context_tensors: \n",
            " context_tensors: tensor([ 1423, 20181, 22088,  6141, 11158, 10232]) \n",
            "tensor([26780, 26285, 26477,  2371, 26023, 12451])context_tensors: \n",
            "context_tensors:  tensor([20181, 22088, 13448, 11158, 10232,  2371]) tensor([26285, 26477,  5146, 26023, 12451, 27965])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26477,  5146,  2371, 12451, 27965,     1])\n",
            "tensor([22088, 13448,  6141, 10232,  2371, 16250])context_tensors: \n",
            " tensor([ 5146,  2371, 26023, 27965,     1,   123])\n",
            "context_tensors:  context_tensors: tensor([13448,  6141, 11158,  2371, 16250, 28200]) \n",
            "tensor([ 2371, 26023, 12451,     1,   123, 19496])context_tensors: \n",
            " tensor([ 6141, 11158, 10232, 16250, 28200, 10388])context_tensors: \n",
            " tensor([26023, 12451, 27965,   123, 19496,  3195])context_tensors: \n",
            " context_tensors: tensor([11158, 10232,  2371, 28200, 10388, 26083]) \n",
            "tensor([12451, 27965,     1, 19496,  3195,    79])\n",
            "context_tensors:  tensor([10232,  2371, 16250, 10388, 26083, 10544])\n",
            "context_tensors:  context_tensors:  tensor([27965,     1,   123,  3195,    79,     1])\n",
            "tensor([ 2371, 16250, 28200, 26083, 10544, 12153])\n",
            "context_tensors:  tensor([    1,   123, 19496,    79,     1,  1409])\n",
            "context_tensors:  context_tensors:  tensor([16250, 28200, 10388, 10544, 12153,  1423])tensor([ 1411,  3017, 26026, 20010, 18520, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 3017, 26026, 12194, 18520, 26026, 23244])\n",
            "tensor([28200, 10388, 26083, 12153,  1423, 18347])context_tensors: \n",
            " context_tensors: tensor([26026, 12194, 20010, 26026, 23244,    76])\n",
            " context_tensors: tensor([10388, 26083, 10544,  1423, 18347, 18609]) \n",
            "tensor([12194, 20010, 18520, 23244,    76, 28356])\n",
            "context_tensors:  context_tensors: tensor([26083, 10544, 12153, 18347, 18609,  5334])\n",
            "context_tensors:   tensor([10544, 12153,  1423, 18609,  5334, 26285])tensor([20010, 18520, 26026,    76, 28356, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([12153,  1423, 18347,  5334, 26285, 19917])\n",
            "tensor([18520, 26026, 23244, 28356, 26026,  4125])\n",
            "context_tensors:  context_tensors: tensor([26026, 23244,    76, 26026,  4125, 14252]) \n",
            "tensor([ 1423, 18347, 18609, 26285, 19917,  2186])context_tensors: \n",
            " context_tensors: tensor([23244,    76, 28356,  4125, 14252,  3468])\n",
            " context_tensors: tensor([18347, 18609,  5334, 19917,  2186, 18520]) \n",
            "tensor([   76, 28356, 26026, 14252,  3468, 14014])\n",
            "context_tensors:  context_tensors:  tensor([28356, 26026,  4125,  3468, 14014,  8638])tensor([18609,  5334, 26285,  2186, 18520, 26040])\n",
            "\n",
            "context_tensors:  tensor([ 5334, 26285, 19917, 18520, 26040,  3862])context_tensors:  tensor([26026,  4125, 14252, 14014,  8638,  8143])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4125, 14252,  3468,  8638,  8143, 28323])tensor([26285, 19917,  2186, 26040,  3862, 19922])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19917,  2186, 18520,  3862, 19922,    76])\n",
            "tensor([14252,  3468, 14014,  8143, 28323, 28356])context_tensors: \n",
            " context_tensors:  tensor([ 2186, 18520, 26040, 19922,    76, 22312])tensor([ 3468, 14014,  8638, 28323, 28356,  2334])\n",
            "context_tensors:  \n",
            "tensor([14014,  8638,  8143, 28356,  2334,   162])\n",
            "context_tensors:  tensor([18520, 26040,  3862,    76, 22312, 17794])\n",
            "context_tensors: context_tensors:   tensor([ 8638,  8143, 28323,  2334,   162, 28846])tensor([26040,  3862, 19922, 22312, 17794,    79])\n",
            "\n",
            "context_tensors:  tensor([ 3862, 19922,    76, 17794,    79,  1409])context_tensors: \n",
            " tensor([ 8143, 28323, 28356,   162, 28846,   879])\n",
            "context_tensors: context_tensors:  tensor([ 1411, 18035,    76, 26478, 10866, 26026]) \n",
            "tensor([28323, 28356,  2334, 28846,   879, 28846])context_tensors: \n",
            "context_tensors:   tensor([28356,  2334,   162,   879, 28846,  1108])tensor([18035,    76, 26083, 10866, 26026, 17921])\n",
            "\n",
            "context_tensors:  tensor([ 2334,   162, 28846, 28846,  1108, 21502])context_tensors: \n",
            " context_tensors:  tensor([   76, 26083, 26478, 26026, 17921, 22359])tensor([  162, 28846,   879,  1108, 21502,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26083, 26478, 10866, 17921, 22359, 18520])tensor([28846,   879, 28846, 21502,    76, 28471])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  879, 28846,  1108,    76, 28471, 13448])tensor([26478, 10866, 26026, 22359, 18520, 24288])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28846,  1108, 21502, 28471, 13448, 26026]) \n",
            "tensor([10866, 26026, 17921, 18520, 24288, 26285])\n",
            "context_tensors:  context_tensors:  tensor([ 1108, 21502,    76, 13448, 26026, 15348])tensor([26026, 17921, 22359, 24288, 26285,  3623])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([17921, 22359, 18520, 26285,  3623, 11074]) \n",
            "tensor([21502,    76, 28471, 26026, 15348,    76])\n",
            "context_tensors: context_tensors:   tensor([   76, 28471, 13448, 15348,    76,  2371])tensor([22359, 18520, 24288,  3623, 11074,  1924])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28471, 13448, 26026,    76,  2371, 23983])tensor([18520, 24288, 26285, 11074,  1924, 14292])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24288, 26285,  3623,  1924, 14292, 28350])\n",
            "tensor([13448, 26026, 15348,  2371, 23983,   794])context_tensors: \n",
            " context_tensors: tensor([26285,  3623, 11074, 14292, 28350,    79]) \n",
            "tensor([26026, 15348,    76, 23983,   794, 20015])context_tensors:  \n",
            "context_tensors:  tensor([ 3623, 11074,  1924, 28350,    79,  1409])\n",
            "tensor([15348,    76,  2371,   794, 20015, 18854])context_tensors: \n",
            " context_tensors: tensor([ 1411, 28350, 23134,  5075, 12696,  1119]) \n",
            "tensor([   76,  2371, 23983, 20015, 18854, 18520])context_tensors: \n",
            " context_tensors: tensor([28350, 23134,  1423, 12696,  1119, 20015]) \n",
            "tensor([ 2371, 23983,   794, 18854, 18520, 19927])context_tensors: \n",
            " tensor([23134,  1423,  5075,  1119, 20015,  8889])context_tensors: \n",
            " context_tensors: tensor([23983,   794, 20015, 18520, 19927, 20176])\n",
            " tensor([ 1423,  5075, 12696, 20015,  8889, 26026])\n",
            "context_tensors: context_tensors:   tensor([ 5075, 12696,  1119,  8889, 26026,   810])tensor([  794, 20015, 18854, 19927, 20176,    76])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([12696,  1119, 20015, 26026,   810, 28846])tensor([20015, 18854, 18520, 20176,    76,  6141])\n",
            "\n",
            "context_tensors:  tensor([ 1119, 20015,  8889,   810, 28846,   162])context_tensors: \n",
            " context_tensors: tensor([18854, 18520, 19927,    76,  6141, 10597]) tensor([20015,  8889, 26026, 28846,   162, 23244])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 8889, 26026,   810,   162, 23244,    76])tensor([18520, 19927, 20176,  6141, 10597,  2802])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([19927, 20176,    76, 10597,  2802,    79])\n",
            "tensor([26026,   810, 28846, 23244,    76, 24535])context_tensors: \n",
            " context_tensors: tensor([20176,    76,  6141,  2802,    79,  1409]) \n",
            "tensor([  810, 28846,   162,    76, 24535, 26232])context_tensors: \n",
            " tensor([ 1411, 12451, 27965,  4787,  2956,  5963])\n",
            "context_tensors: context_tensors:   tensor([12451, 27965, 21929,  2956,  5963, 26294])tensor([28846,   162, 23244, 24535, 26232,  3886])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  162, 23244,    76, 26232,  3886, 26026])tensor([27965, 21929,  4787,  5963, 26294, 22303])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([23244,    76, 24535,  3886, 26026, 18008])\n",
            "tensor([21929,  4787,  2956, 26294, 22303, 18605])\n",
            "context_tensors: context_tensors:  tensor([   76, 24535, 26232, 26026, 18008, 28653]) tensor([ 4787,  2956,  5963, 22303, 18605,  2334])\n",
            "context_tensors:  \n",
            "context_tensors: tensor([24535, 26232,  3886, 18008, 28653, 14179]) tensor([ 2956,  5963, 26294, 18605,  2334, 13940])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26232,  3886, 26026, 28653, 14179,  2371])tensor([ 5963, 26294, 22303,  2334, 13940,  3543])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26294, 22303, 18605, 13940,  3543,    79])tensor([ 3886, 26026, 18008, 14179,  2371, 17357])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22303, 18605,  2334,  3543,    79,  1409])tensor([26026, 18008, 28653,  2371, 17357,  4954])\n",
            "context_tensors:  \n",
            "tensor([ 1411, 22303, 12153,  5964, 26026, 17097])context_tensors: \n",
            " context_tensors: tensor([18008, 28653, 14179, 17357,  4954,    79]) \n",
            "context_tensors:  tensor([22303, 12153, 20471, 26026, 17097, 28259])tensor([28653, 14179,  2371,  4954,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 26026, 20010, 27965, 10489,  1416]) \n",
            "tensor([12153, 20471,  5964, 17097, 28259,    79])\n",
            "context_tensors:  context_tensors: tensor([26026, 20010, 26404, 10489,  1416, 12699]) tensor([20471,  5964, 26026, 28259,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1411, 12451, 21503, 10609,  5966, 27633]) \n",
            "tensor([20010, 26404, 27965,  1416, 12699, 13448])context_tensors: \n",
            " tensor([12451, 21503, 12762,  5966, 27633, 10866])context_tensors: \n",
            "context_tensors:   tensor([26404, 27965, 10489, 12699, 13448, 26026])tensor([21503, 12762, 10609, 27633, 10866, 26026])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([12762, 10609,  5966, 10866, 26026,  4125]) tensor([27965, 10489,  1416, 13448, 26026, 15348])\n",
            "context_tensors:  \n",
            "context_tensors: tensor([10489,  1416, 12699, 26026, 15348, 10866])\n",
            " tensor([10609,  5966, 27633, 26026,  4125, 14252])context_tensors: \n",
            " tensor([ 1416, 12699, 13448, 15348, 10866,  7675])context_tensors: \n",
            " tensor([ 5966, 27633, 10866,  4125, 14252, 13448])context_tensors: \n",
            " context_tensors: tensor([12699, 13448, 26026, 10866,  7675, 23139])\n",
            " tensor([27633, 10866, 26026, 14252, 13448, 12762])context_tensors: \n",
            " context_tensors: tensor([13448, 26026, 15348,  7675, 23139,    76]) \n",
            "tensor([10866, 26026,  4125, 13448, 12762, 23265])\n",
            "context_tensors: tensor([26026, 15348, 10866, 23139,    76, 26911]) \n",
            "context_tensors:  tensor([26026,  4125, 14252, 12762, 23265, 11365])context_tensors:  tensor([15348, 10866,  7675,    76, 26911, 26291])\n",
            "\n",
            "context_tensors:  tensor([10866,  7675, 23139, 26911, 26291,  1410])\n",
            "context_tensors:  tensor([ 4125, 14252, 13448, 23265, 11365,    76])\n",
            "context_tensors: context_tensors:  tensor([14252, 13448, 12762, 11365,    76,  1423]) \n",
            "tensor([ 7675, 23139,    76, 26291,  1410,    79])context_tensors: \n",
            " context_tensors: tensor([13448, 12762, 23265,    76,  1423,  1038]) \n",
            "context_tensors: tensor([23139,    76, 26911,  1410,    79,  1409])\n",
            " tensor([12762, 23265, 11365,  1423,  1038, 28846])context_tensors: \n",
            " context_tensors: tensor([ 1411, 26026,  4125,  4914, 26285, 25951])\n",
            " context_tensors: tensor([23265, 11365,    76,  1038, 28846,   942])\n",
            " context_tensors:  tensor([26026,  4125, 14252, 26285, 25951, 28356])tensor([11365,    76,  1423, 28846,   942, 28295])\n",
            "context_tensors:  tensor([   76,  1423,  1038,   942, 28295, 18921])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 4125, 14252,  4914, 25951, 28356, 28350])tensor([ 1423,  1038, 28846, 28295, 18921, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([14252,  4914, 26285, 28356, 28350,    76])tensor([ 1038, 28846,   942, 18921, 26026, 19688])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28846,   942, 28295, 26026, 19688,  7034])tensor([ 4914, 26285, 25951, 28350,    76, 14576])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([  942, 28295, 18921, 19688,  7034,    79]) tensor([26285, 25951, 28356,    76, 14576,  2334])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28295, 18921, 26026,  7034,    79,  1409])tensor([25951, 28356, 28350, 14576,  2334, 12988])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([28356, 28350,    76,  2334, 12988, 20515])tensor([ 1411, 26026,  5445,  5966,  8109, 18253])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28350,    76, 14576, 12988, 20515, 26285]) \n",
            "context_tensors: tensor([26026,  5445, 13448,  8109, 18253,  5445]) tensor([   76, 14576,  2334, 20515, 26285, 26026])\n",
            "\n",
            "context_tensors:  tensor([ 5445, 13448,  5966, 18253,  5445, 26026])context_tensors: \n",
            "context_tensors:   tensor([14576,  2334, 12988, 26285, 26026, 24745])\n",
            "tensor([13448,  5966,  8109,  5445, 26026, 10971])context_tensors: \n",
            "context_tensors:   tensor([ 5966,  8109, 18253, 26026, 10971, 18520])tensor([ 2334, 12988, 20515, 26026, 24745, 18520])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 8109, 18253,  5445, 10971, 18520, 26026]) \n",
            "tensor([12988, 20515, 26285, 24745, 18520, 11074])\n",
            "context_tensors:  tensor([18253,  5445, 26026, 18520, 26026, 25819])\n",
            "context_tensors: context_tensors:  tensor([20515, 26285, 26026, 18520, 11074,  1922]) \n",
            "tensor([ 5445, 26026, 10971, 26026, 25819,    76])context_tensors: \n",
            " tensor([26285, 26026, 24745, 11074,  1922,    76])context_tensors: \n",
            " context_tensors:  tensor([26026, 24745, 18520,  1922,    76, 23878])tensor([26026, 10971, 18520, 25819,    76,  2858])\n",
            "context_tensors:  \n",
            "tensor([24745, 18520, 11074,    76, 23878, 12729])\n",
            "context_tensors:  context_tensors: tensor([10971, 18520, 26026,    76,  2858, 26083]) \n",
            "tensor([18520, 11074,  1922, 23878, 12729, 26285])\n",
            "context_tensors: context_tensors:   tensor([11074,  1922,    76, 12729, 26285,  1423])tensor([18520, 26026, 25819,  2858, 26083, 21338])\n",
            "context_tensors: \n",
            " context_tensors:  tensor([ 1922,    76, 23878, 26285,  1423, 23989])tensor([26026, 25819,    76, 26083, 21338, 26026])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([   76, 23878, 12729,  1423, 23989,  1416])tensor([25819,    76,  2858, 21338, 26026,  2128])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([   76,  2858, 26083, 26026,  2128,  1416]) \n",
            "tensor([23878, 12729, 26285, 23989,  1416, 28612])context_tensors: \n",
            " tensor([ 2858, 26083, 21338,  2128,  1416, 24727])context_tensors: \n",
            " tensor([12729, 26285,  1423,  1416, 28612,    76])\n",
            "context_tensors:  context_tensors: tensor([26083, 21338, 26026,  1416, 24727,  4439]) \n",
            "tensor([26285,  1423, 23989, 28612,    76,     3])context_tensors: \n",
            " context_tensors: tensor([21338, 26026,  2128, 24727,  4439, 28356]) \n",
            "tensor([ 1423, 23989,  1416,    76,     3,   972])\n",
            "context_tensors: context_tensors:  tensor([26026,  2128,  1416,  4439, 28356,  1423]) \n",
            "tensor([23989,  1416, 28612,     3,   972, 17043])\n",
            "context_tensors: context_tensors:   tensor([ 1416, 28612,    76,   972, 17043,  7537])\n",
            "tensor([ 2128,  1416, 24727, 28356,  1423,   280])context_tensors: \n",
            "context_tensors:  tensor([28612,    76,     3, 17043,  7537,    79]) \n",
            "tensor([ 1416, 24727,  4439,  1423,   280, 28846])\n",
            "context_tensors: context_tensors:  tensor([  76,    3,  972, 7537,   79, 1409]) tensor([24727,  4439, 28356,   280, 28846,   943])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1411,  6141,  2197, 10942, 10609, 22600])\n",
            " context_tensors: tensor([ 4439, 28356,  1423, 28846,   943, 28846])\n",
            "context_tensors:  tensor([ 6141,  2197, 26478, 10609, 22600,  8682])\n",
            " context_tensors: tensor([28356,  1423,   280,   943, 28846,  1176])\n",
            " tensor([ 2197, 26478, 10942, 22600,  8682, 19733])context_tensors:  tensor([ 1423,   280, 28846, 28846,  1176, 21502])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  280, 28846,   943,  1176, 21502,    79])tensor([26478, 10942, 10609,  8682, 19733, 18098])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([28846,   943, 28846, 21502,    79,  1409])tensor([10942, 10609, 22600, 19733, 18098,  1410])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  3017, 26026,    76,  4125, 14252])tensor([10609, 22600,  8682, 18098,  1410, 26285])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22600,  8682, 19733,  1410, 26285, 26026])\n",
            "tensor([ 3017, 26026,  4439,  4125, 14252,     6])\n",
            "context_tensors: context_tensors:  tensor([ 8682, 19733, 18098, 26285, 26026, 18838]) \n",
            "tensor([26026,  4439,    76, 14252,     6, 18999])context_tensors:  \n",
            "tensor([19733, 18098,  1410, 26026, 18838, 23379])\n",
            "context_tensors:  context_tensors:  tensor([ 4439,    76,  4125,     6, 18999, 14442])tensor([18098,  1410, 26285, 18838, 23379, 10866])\n",
            "context_tensors:  \n",
            "tensor([   76,  4125, 14252, 18999, 14442, 19022])context_tensors:  \n",
            "tensor([ 1410, 26285, 26026, 23379, 10866,  1423])\n",
            "context_tensors:  \n",
            "tensor([ 4125, 14252,     6, 14442, 19022,  1410])context_tensors: context_tensors:   tensor([26285, 26026, 18838, 10866,  1423, 26108])tensor([14252,     6, 18999, 19022,  1410, 23407])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([    6, 18999, 14442,  1410, 23407, 18854])tensor([26026, 18838, 23379,  1423, 26108,  1416])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([18838, 23379, 10866, 26108,  1416, 22600])tensor([18999, 14442, 19022, 23407, 18854,  1423])\n",
            "context_tensors: \n",
            " context_tensors: tensor([23379, 10866,  1423,  1416, 22600, 19733])\n",
            " context_tensors: tensor([14442, 19022,  1410, 18854,  1423, 15491])\n",
            "context_tensors:  tensor([10866,  1423, 26108, 22600, 19733, 13448]) \n",
            "tensor([19022,  1410, 23407,  1423, 15491, 26285])\n",
            "context_tensors: context_tensors:   tensor([ 1410, 23407, 18854, 15491, 26285, 10232])\n",
            "tensor([ 1423, 26108,  1416, 19733, 13448, 26026])context_tensors:  tensor([23407, 18854,  1423, 26285, 10232, 24762])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18854,  1423, 15491, 10232, 24762, 12762])\n",
            "context_tensors:  tensor([26108,  1416, 22600, 13448, 26026,   812])\n",
            " context_tensors: tensor([ 1423, 15491, 26285, 24762, 12762, 27076])\n",
            " context_tensors: tensor([ 1416, 22600, 19733, 26026,   812,  8682]) \n",
            "tensor([15491, 26285, 10232, 12762, 27076, 18520])context_tensors:  \n",
            "tensor([22600, 19733, 13448,   812,  8682,    79])context_tensors: \n",
            " context_tensors: tensor([26285, 10232, 24762, 27076, 18520, 26040]) \n",
            "tensor([19733, 13448, 26026,  8682,    79,  1409])context_tensors: \n",
            " tensor([10232, 24762, 12762, 18520, 26040, 11184])context_tensors:  \n",
            "tensor([ 1411,  1410, 12153, 26285, 15732, 27275])\n",
            "context_tensors: context_tensors:   tensor([24762, 12762, 27076, 26040, 11184,    79])\n",
            "tensor([ 1410, 12153, 10166, 15732, 27275, 26285])\n",
            "context_tensors:  context_tensors: tensor([12762, 27076, 18520, 11184,    79,  1409])\n",
            " context_tensors: tensor([12153, 10166, 26285, 27275, 26285,  9979])\n",
            " tensor([ 1411, 12451,  1703,  1662, 28479,  3623])context_tensors:  tensor([10166, 26285, 15732, 26285,  9979, 13448])\n",
            "\n",
            "context_tensors:  tensor([12451,  1703, 26023, 28479,  3623, 25686])\n",
            "context_tensors: context_tensors:   tensor([26285, 15732, 27275,  9979, 13448,  6141])\n",
            "tensor([ 1703, 26023,  1662,  3623, 25686,  2806])\n",
            "context_tensors: context_tensors:   tensor([15732, 27275, 26285, 13448,  6141,    76])tensor([26023,  1662, 28479, 25686,  2806, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([27275, 26285,  9979,  6141,    76, 19926])\n",
            " context_tensors: tensor([ 1662, 28479,  3623,  2806, 26026, 26477])\n",
            " tensor([26285,  9979, 13448,    76, 19926, 13448])context_tensors: \n",
            " context_tensors: tensor([28479,  3623, 25686, 26026, 26477,  7531]) \n",
            "tensor([ 9979, 13448,  6141, 19926, 13448, 18616])context_tensors: \n",
            " context_tensors:  tensor([13448,  6141,    76, 13448, 18616,  1066])\n",
            "context_tensors: tensor([ 3623, 25686,  2806, 26477,  7531,    76])\n",
            " tensor([ 6141,    76, 19926, 18616,  1066, 11372])context_tensors: \n",
            "context_tensors:   tensor([25686,  2806, 26026,  7531,    76, 26026])tensor([   76, 19926, 13448,  1066, 11372, 18921])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19926, 13448, 18616, 11372, 18921, 26151])tensor([ 2806, 26026, 26477,    76, 26026,  9552])\n",
            "\n",
            "context_tensors: context_tensors:   \n",
            "tensor([26026, 26477,  7531, 26026,  9552,  8682])tensor([13448, 18616,  1066, 18921, 26151, 23247])context_tensors: \n",
            " tensor([26477,  7531,    76,  9552,  8682,  2371])\n",
            "context_tensors: context_tensors:  tensor([ 7531,    76, 26026,  8682,  2371, 11074]) \n",
            "tensor([18616,  1066, 11372, 26151, 23247, 23139])\n",
            "context_tensors: context_tensors:   tensor([   76, 26026,  9552,  2371, 11074,  1922])tensor([ 1066, 11372, 18921, 23247, 23139, 23989])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026,  9552,  8682, 11074,  1922, 26285])\n",
            "tensor([11372, 18921, 26151, 23139, 23989, 11726])\n",
            "context_tensors:  context_tensors: tensor([ 9552,  8682,  2371,  1922, 26285, 25684]) \n",
            "tensor([18921, 26151, 23247, 23989, 11726,    79])\n",
            "context_tensors:  tensor([ 8682,  2371, 11074, 26285, 25684, 26026])context_tensors: \n",
            " tensor([26151, 23247, 23139, 11726,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([ 2371, 11074,  1922, 25684, 26026, 25819])\n",
            " tensor([ 1411, 20515, 26285, 24745, 18520, 26026])\n",
            "context_tensors:  context_tensors: tensor([11074,  1922, 26285, 26026, 25819, 13448]) \n",
            "tensor([20515, 26285, 26026, 18520, 26026, 23244])\n",
            "context_tensors:  tensor([ 1922, 26285, 25684, 25819, 13448,  1423])\n",
            "context_tensors: context_tensors:   tensor([26285, 26026, 24745, 26026, 23244,    76])tensor([26285, 25684, 26026, 13448,  1423, 18008])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([26026, 24745, 18520, 23244,    76, 26026])tensor([25684, 26026, 25819,  1423, 18008,  8199])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026, 25819, 13448, 18008,  8199,    79])tensor([24745, 18520, 26026,    76, 26026,  4125])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([25819, 13448,  1423,  8199,    79,  1409])\n",
            " tensor([18520, 26026, 23244, 26026,  4125, 14252])context_tensors: \n",
            "context_tensors:   tensor([ 1411, 28165, 24403, 26026, 23244,    76])tensor([26026, 23244,    76,  4125, 14252, 28115])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28165, 24403, 18520, 23244,    76,  1410]) \n",
            "tensor([23244,    76, 26026, 14252, 28115, 21050])\n",
            "context_tensors:  tensor([   76, 26026,  4125, 28115, 21050, 10866])\n",
            "context_tensors: context_tensors:   tensor([24403, 18520, 26026,    76,  1410, 24755])tensor([26026,  4125, 14252, 21050, 10866, 18253])\n",
            "context_tensors: \n",
            " tensor([18520, 26026, 23244,  1410, 24755,     1])context_tensors: \n",
            " tensor([ 4125, 14252, 28115, 10866, 18253, 23878])context_tensors:  tensor([26026, 23244,    76, 24755,     1,  8232])\n",
            "\n",
            "context_tensors:  tensor([14252, 28115, 21050, 18253, 23878,  1423])context_tensors: \n",
            " context_tensors:  tensor([23244,    76,  1410,     1,  8232, 14156])\n",
            "tensor([28115, 21050, 10866, 23878,  1423, 27592])\n",
            "context_tensors:  context_tensors:  tensor([21050, 10866, 18253,  1423, 27592,  3293])\n",
            "tensor([   76,  1410, 24755,  8232, 14156, 18253])context_tensors:  \n",
            "tensor([10866, 18253, 23878, 27592,  3293,  1416])context_tensors:  tensor([18253, 23878,  1423,  3293,  1416, 27275])\n",
            "\n",
            "context_tensors:  tensor([23878,  1423, 27592,  1416, 27275, 26285])\n",
            "context_tensors:  tensor([ 1423, 27592,  3293, 27275, 26285, 24749])\n",
            "context_tensors: context_tensors:   tensor([ 1410, 24755,     1, 14156, 18253,  1423])tensor([27592,  3293,  1416, 26285, 24749, 11729])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([24755,     1,  8232, 18253,  1423, 25061]) \n",
            "tensor([ 3293,  1416, 27275, 24749, 11729, 24867])context_tensors:  \n",
            "tensor([    1,  8232, 14156,  1423, 25061,  9490])\n",
            "context_tensors:  tensor([ 1416, 27275, 26285, 11729, 24867, 16505])\n",
            "context_tensors: context_tensors:  tensor([ 8232, 14156, 18253, 25061,  9490, 28432]) tensor([27275, 26285, 24749, 24867, 16505,    76])\n",
            "\n",
            "context_tensors:  tensor([14156, 18253,  1423,  9490, 28432,     1])context_tensors:  tensor([26285, 24749, 11729, 16505,    76,  2858])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([24749, 11729, 24867,    76,  2858, 26026])tensor([18253,  1423, 25061, 28432,     1,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([11729, 24867, 16505,  2858, 26026, 10942])\n",
            "tensor([ 1423, 25061,  9490,     1,  2371, 26023])\n",
            "context_tensors: context_tensors:  tensor([24867, 16505,    76, 26026, 10942,  4873]) \n",
            "context_tensors: tensor([25061,  9490, 28432,  2371, 26023, 12451]) tensor([16505,    76,  2858, 10942,  4873, 16794])\n",
            "\n",
            "context_tensors:  tensor([   76,  2858, 26026,  4873, 16794, 26739])\n",
            "context_tensors: context_tensors:  tensor([ 2858, 26026, 10942, 16794, 26739, 28319]) \n",
            "tensor([ 9490, 28432,     1, 26023, 12451, 27965])\n",
            "context_tensors: context_tensors:  tensor([26026, 10942,  4873, 26739, 28319, 12153])\n",
            " tensor([28432,     1,  2371, 12451, 27965,  6233])\n",
            "context_tensors: context_tensors:  tensor([10942,  4873, 16794, 28319, 12153, 25079]) \n",
            "tensor([    1,  2371, 26023, 27965,  6233, 26285])context_tensors:  \n",
            "tensor([ 4873, 16794, 26739, 12153, 25079, 13448])\n",
            "context_tensors:  tensor([ 2371, 26023, 12451,  6233, 26285, 11655])\n",
            "context_tensors: context_tensors:   tensor([26023, 12451, 27965, 26285, 11655, 10232])\n",
            "tensor([16794, 26739, 28319, 25079, 13448,  6560])context_tensors: \n",
            " tensor([12451, 27965,  6233, 11655, 10232,  1423])\n",
            "context_tensors: context_tensors:   tensor([27965,  6233, 26285, 10232,  1423, 25819])tensor([26739, 28319, 12153, 13448,  6560, 23247])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 6233, 26285, 11655,  1423, 25819, 18520])\n",
            "tensor([28319, 12153, 25079,  6560, 23247,    79])\n",
            "context_tensors: context_tensors:  tensor([12153, 25079, 13448, 23247,    79,  1409])\n",
            " tensor([26285, 11655, 10232, 25819, 18520, 28175])\n",
            "context_tensors:  tensor([ 1411, 26026,  4125, 23869, 16413,  1410])\n",
            "context_tensors:  context_tensors: tensor([26026,  4125, 14252, 16413,  1410,  2858])\n",
            " tensor([11655, 10232,  1423, 18520, 28175, 26083])\n",
            "context_tensors: context_tensors:   tensor([10232,  1423, 25819, 28175, 26083,  4947])\n",
            "tensor([ 4125, 14252, 23869,  1410,  2858, 26026])\n",
            "context_tensors: context_tensors:   tensor([14252, 23869, 16413,  2858, 26026,  3293])\n",
            "tensor([ 1423, 25819, 18520, 26083,  4947,  3623])context_tensors: \n",
            "context_tensors:  tensor([23869, 16413,  1410, 26026,  3293,  1416]) \n",
            "context_tensors:  tensor([16413,  1410,  2858,  3293,  1416, 27275])tensor([25819, 18520, 28175,  4947,  3623, 20767])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1410,  2858, 26026,  1416, 27275, 28200])\n",
            " tensor([18520, 28175, 26083,  3623, 20767, 18520])context_tensors: \n",
            " context_tensors:  tensor([28175, 26083,  4947, 20767, 18520,    79])tensor([ 2858, 26026,  3293, 27275, 28200, 12153])\n",
            "context_tensors: \n",
            " tensor([26083,  4947,  3623, 18520,    79,  1409])\n",
            "context_tensors:  context_tensors:  tensor([26026,  3293,  1416, 28200, 12153, 18616])tensor([ 1411, 12451,  2197, 26042, 10866, 26040])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([12451,  2197, 26020, 10866, 26040,  7633])\n",
            " context_tensors:  tensor([ 3293,  1416, 27275, 12153, 18616,  1109])\n",
            "tensor([ 2197, 26020, 26042, 26040,  7633,  2371])context_tensors: \n",
            " tensor([ 1416, 27275, 28200, 18616,  1109, 17114])\n",
            "context_tensors: context_tensors:  tensor([27275, 28200, 12153,  1109, 17114, 18520])\n",
            " context_tensors: tensor([26020, 26042, 10866,  7633,  2371, 19292]) \n",
            "\n",
            "tensor([28200, 12153, 18616, 17114, 18520, 18047])context_tensors: context_tensors:  tensor([26042, 10866, 26040,  2371, 19292,    76]) tensor([12153, 18616,  1109, 18520, 18047,  9996])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([10866, 26040,  7633, 19292,    76, 28179])\n",
            "tensor([18616,  1109, 17114, 18047,  9996, 20515])\n",
            "context_tensors: context_tensors:  tensor([ 1109, 17114, 18520,  9996, 20515, 26285])\n",
            " tensor([26040,  7633,  2371,    76, 28179, 21727])context_tensors:  \n",
            "tensor([17114, 18520, 18047, 20515, 26285, 26026])\n",
            "context_tensors: context_tensors:   tensor([18520, 18047,  9996, 26285, 26026, 24745])tensor([ 7633,  2371, 19292, 28179, 21727, 26023])\n",
            "\n",
            "context_tensors:  tensor([ 2371, 19292,    76, 21727, 26023, 26026])context_tensors: \n",
            " context_tensors: tensor([18047,  9996, 20515, 26026, 24745, 18520])\n",
            "context_tensors:  tensor([19292,    76, 28179, 26023, 26026, 25819])\n",
            "context_tensors:  tensor([ 9996, 20515, 26285, 24745, 18520, 26026])\n",
            " tensor([   76, 28179, 21727, 26026, 25819, 11723])\n",
            "context_tensors:  tensor([20515, 26285, 26026, 18520, 26026, 23244])\n",
            " context_tensors: tensor([28179, 21727, 26023, 25819, 11723, 27965])\n",
            "context_tensors: context_tensors:  tensor([21727, 26023, 26026, 11723, 27965, 26285]) \n",
            "tensor([26285, 26026, 24745, 26026, 23244,    79])\n",
            "context_tensors: context_tensors:   tensor([26023, 26026, 25819, 27965, 26285,     1])tensor([26026, 24745, 18520, 23244,    79,  1409])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  6141,  8109,  1423, 27592,  7316])tensor([26026, 25819, 11723, 26285,     1, 28295])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 6141,  8109, 23859, 27592,  7316, 22906]) \n",
            "tensor([25819, 11723, 27965,     1, 28295,  6585])\n",
            "context_tensors: context_tensors:   tensor([ 8109, 23859,  1423,  7316, 22906, 26285])tensor([11723, 27965, 26285, 28295,  6585,  2371])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([27965, 26285,     1,  6585,  2371,  6291]) \n",
            "tensor([23859,  1423, 27592, 22906, 26285,  3623])context_tensors:  \n",
            "tensor([26285,     1, 28295,  2371,  6291, 10866])context_tensors: \n",
            " context_tensors: tensor([ 1423, 27592,  7316, 26285,  3623, 26040]) tensor([    1, 28295,  6585,  6291, 10866, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([28295,  6585,  2371, 10866, 26026, 24719]) \n",
            "tensor([27592,  7316, 22906,  3623, 26040, 26108])context_tensors: \n",
            " tensor([ 6585,  2371,  6291, 26026, 24719,  7287])context_tensors: \n",
            "context_tensors:   tensor([ 7316, 22906, 26285, 26040, 26108, 25046])tensor([ 2371,  6291, 10866, 24719,  7287,    79])\n",
            "\n",
            "context_tensors:  tensor([ 6291, 10866, 26026,  7287,    79,     1])\n",
            "context_tensors: context_tensors:  tensor([10866, 26026, 24719,    79,     1,  1409]) \n",
            "tensor([22906, 26285,  3623, 26108, 25046, 11729])context_tensors: \n",
            " tensor([ 1411,  7516, 15261,  1423,   880,  1416])context_tensors: \n",
            " context_tensors:  tensor([26285,  3623, 26040, 25046, 11729,  2371])\n",
            "tensor([ 7516, 15261,    76,   880,  1416, 19571])\n",
            "context_tensors: context_tensors:  tensor([15261,    76,  1423,  1416, 19571, 20745]) \n",
            "context_tensors: tensor([ 3623, 26040, 26108, 11729,  2371, 26285])\n",
            " tensor([   76,  1423,   880, 19571, 20745, 18482])\n",
            "context_tensors: context_tensors:  tensor([26040, 26108, 25046,  2371, 26285, 24745]) \n",
            "tensor([ 1423,   880,  1416, 20745, 18482, 18904])context_tensors:  \n",
            "tensor([26108, 25046, 11729, 26285, 24745, 10866])\n",
            "context_tensors: context_tensors:  tensor([  880,  1416, 19571, 18482, 18904, 18520]) tensor([25046, 11729,  2371, 24745, 10866, 26040])\n",
            "\n",
            "context_tensors:  tensor([ 1416, 19571, 20745, 18904, 18520, 17817])context_tensors: \n",
            " tensor([11729,  2371, 26285, 10866, 26040,  2279])context_tensors: \n",
            " tensor([19571, 20745, 18482, 18520, 17817,  2738])context_tensors:  \n",
            "tensor([ 2371, 26285, 24745, 26040,  2279, 12808])context_tensors:  tensor([20745, 18482, 18904, 17817,  2738,    79])\n",
            "\n",
            "context_tensors:  tensor([18482, 18904, 18520,  2738,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([26285, 24745, 10866,  2279, 12808, 15348])\n",
            "tensor([ 1411, 10232, 28115, 28356, 26026,  4125])\n",
            "context_tensors:  context_tensors: tensor([24745, 10866, 26040, 12808, 15348,    72])\n",
            " tensor([10232, 28115, 27308, 26026,  4125, 14252])context_tensors: \n",
            " context_tensors: tensor([10866, 26040,  2279, 15348,    72,  1410])\n",
            " context_tensors: tensor([28115, 27308, 28356,  4125, 14252,     6]) \n",
            "tensor([26040,  2279, 12808,    72,  1410,    73])\n",
            "context_tensors:  context_tensors: tensor([27308, 28356, 26026, 14252,     6, 16250]) \n",
            "tensor([ 2279, 12808, 15348,  1410,    73,  1867])context_tensors:  tensor([28356, 26026,  4125,     6, 16250,  2371])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([26026,  4125, 14252, 16250,  2371, 28115])tensor([12808, 15348,    72,    73,  1867,    76])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15348,    72,  1410,  1867,    76, 26026])tensor([ 4125, 14252,     6,  2371, 28115,  4892])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([14252,     6, 16250, 28115,  4892, 10866]) \n",
            "context_tensors: tensor([   72,  1410,    73,    76, 26026, 24591]) \n",
            "tensor([    6, 16250,  2371,  4892, 10866,  5448])\n",
            "context_tensors:  context_tensors: tensor([ 1410,    73,  1867, 26026, 24591, 10193]) \n",
            "tensor([16250,  2371, 28115, 10866,  5448,  3017])\n",
            "context_tensors: context_tensors:  tensor([ 2371, 28115,  4892,  5448,  3017, 26026])\n",
            " tensor([   73,  1867,    76, 24591, 10193,    79])\n",
            "context_tensors: context_tensors:   tensor([28115,  4892, 10866,  3017, 26026, 26358])\n",
            "tensor([ 1867,    76, 26026, 10193,    79,  1409])\n",
            "context_tensors: context_tensors:  tensor([ 4892, 10866,  5448, 26026, 26358,    79]) tensor([ 1411, 22906, 12153, 19921, 13448, 26026])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([22906, 12153, 18253, 13448, 26026, 18047])tensor([10866,  5448,  3017, 26358,    79,  1409])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([12153, 18253, 19921, 26026, 18047, 23934]) tensor([ 1411, 26026, 22872, 26026, 10232, 20748])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([18253, 19921, 13448, 18047, 23934,   806]) tensor([26026, 22872,  7513, 10232, 20748,    76])\n",
            "\n",
            "context_tensors:  tensor([19921, 13448, 26026, 23934,   806,    79])context_tensors:  \n",
            "tensor([22872,  7513, 26026, 20748,    76, 14210])context_tensors: \n",
            " context_tensors:  tensor([13448, 26026, 18047,   806,    79,  1409])\n",
            "tensor([ 7513, 26026, 10232,    76, 14210, 27965])context_tensors: \n",
            " context_tensors:  tensor([26026, 10232, 20748, 14210, 27965,  2456])\n",
            "tensor([ 1411,  8889, 26507,    76,  1410, 25246])\n",
            "context_tensors: context_tensors:   tensor([10232, 20748,    76, 27965,  2456, 26023])tensor([ 8889, 26507,  4927,  1410, 25246,  1423])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([20748,    76, 14210,  2456, 26023, 26026])tensor([26507,  4927,    76, 25246,  1423, 12696])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([   76, 14210, 27965, 26023, 26026, 11034])\n",
            "tensor([ 4927,    76,  1410,  1423, 12696,  2439])context_tensors: \n",
            "context_tensors:  tensor([14210, 27965,  2456, 26026, 11034, 28479])\n",
            " tensor([   76,  1410, 25246, 12696,  2439, 24582])context_tensors: \n",
            " context_tensors: tensor([27965,  2456, 26023, 11034, 28479, 12969]) tensor([ 1410, 25246,  1423,  2439, 24582, 26023])\n",
            "\n",
            "context_tensors:  tensor([ 2456, 26023, 26026, 28479, 12969, 26026])context_tensors: \n",
            "context_tensors:   tensor([26023, 26026, 11034, 12969, 26026,   814])\n",
            "tensor([25246,  1423, 12696, 24582, 26023, 27965])\n",
            "context_tensors: context_tensors:  tensor([ 1423, 12696,  2439, 26023, 27965,  9980]) \n",
            "tensor([26026, 11034, 28479, 26026,   814,  2128])\n",
            "context_tensors:  context_tensors: tensor([12696,  2439, 24582, 27965,  9980, 26285]) \n",
            "tensor([11034, 28479, 12969,   814,  2128,  1416])\n",
            "context_tensors: context_tensors:  tensor([28479, 12969, 26026,  2128,  1416, 24727]) \n",
            "tensor([ 2439, 24582, 26023,  9980, 26285, 14726])context_tensors:  \n",
            "tensor([12969, 26026,   814,  1416, 24727, 11365])\n",
            "context_tensors:  context_tensors: tensor([26026,   814,  2128, 24727, 11365,    79]) tensor([24582, 26023, 27965, 26285, 14726, 12729])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([  814,  2128,  1416, 11365,    79,  1409])tensor([26023, 27965,  9980, 14726, 12729, 18854])\n",
            "\n",
            "context_tensors:  tensor([ 1411,  6141, 27965,  1423, 21957, 10866])context_tensors:  \n",
            "tensor([27965,  9980, 26285, 12729, 18854, 18520])context_tensors: \n",
            " tensor([ 6141, 27965, 28368, 21957, 10866, 26026])context_tensors:  \n",
            "tensor([ 9980, 26285, 14726, 18854, 18520, 26026])\n",
            "context_tensors:  tensor([27965, 28368,  1423, 10866, 26026,   813])context_tensors: \n",
            " tensor([26285, 14726, 12729, 18520, 26026, 15648])\n",
            "context_tensors: context_tensors:  tensor([28368,  1423, 21957, 26026,   813,  2128]) tensor([14726, 12729, 18854, 26026, 15648,  1416])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([ 1423, 21957, 10866,   813,  2128,  1416])\n",
            " context_tensors: tensor([12729, 18854, 18520, 15648,  1416, 27275])\n",
            " tensor([21957, 10866, 26026,  2128,  1416, 24727])context_tensors: \n",
            " tensor([18854, 18520, 26026,  1416, 27275, 10866])context_tensors:  \n",
            "tensor([10866, 26026,   813,  1416, 24727, 11365])\n",
            "context_tensors:  tensor([26026,   813,  2128, 24727, 11365,    76])context_tensors:  \n",
            "tensor([18520, 26026, 15648, 27275, 10866,  1423])context_tensors:  \n",
            "tensor([  813,  2128,  1416, 11365,    76,  4767])\n",
            "context_tensors: context_tensors:   tensor([26026, 15648,  1416, 10866,  1423, 17352])tensor([ 2128,  1416, 24727,    76,  4767, 22735])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([15648,  1416, 27275,  1423, 17352,    79])\n",
            "tensor([ 1416, 24727, 11365,  4767, 22735, 14441])\n",
            "context_tensors: context_tensors:   tensor([ 1416, 27275, 10866, 17352,    79,  1409])tensor([24727, 11365,    76, 22735, 14441, 21959])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1411,  1713,    76, 25246,  1423, 11981])\n",
            "tensor([11365,    76,  4767, 14441, 21959, 26026])context_tensors: \n",
            " tensor([ 1713,    76, 22906,  1423, 11981, 13740])\n",
            "context_tensors: context_tensors:   tensor([   76, 22906, 25246, 11981, 13740,    76])tensor([   76,  4767, 22735, 21959, 26026,  5938])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22906, 25246,  1423, 13740,    76, 15376])tensor([ 4767, 22735, 14441, 26026,  5938,  2858])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([25246,  1423, 11981,    76, 15376,  2143]) tensor([22735, 14441, 21959,  5938,  2858,  1423])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 1423, 11981, 13740, 15376,  2143, 28653])\n",
            "context_tensors: tensor([14441, 21959, 26026,  2858,  1423, 22540])\n",
            " tensor([11981, 13740,    76,  2143, 28653,  2858])context_tensors: \n",
            " context_tensors: tensor([21959, 26026,  5938,  1423, 22540, 19248]) \n",
            "tensor([13740,    76, 15376, 28653,  2858, 26026])context_tensors:  \n",
            "tensor([26026,  5938,  2858, 22540, 19248, 13448])\n",
            "context_tensors: context_tensors:   tensor([ 5938,  2858,  1423, 19248, 13448, 26026])tensor([   76, 15376,  2143,  2858, 26026,  3293])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 2858,  1423, 22540, 13448, 26026, 25326])\n",
            "tensor([15376,  2143, 28653, 26026,  3293,  1416])context_tensors: \n",
            "context_tensors:   tensor([ 1423, 22540, 19248, 26026, 25326,  1410])tensor([ 2143, 28653,  2858,  3293,  1416, 27275])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([22540, 19248, 13448, 25326,  1410,  6297])tensor([28653,  2858, 26026,  1416, 27275,    79])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([19248, 13448, 26026,  1410,  6297,    79])\n",
            "context_tensors: tensor([ 2858, 26026,  3293, 27275,    79,  1409]) \n",
            "tensor([13448, 26026, 25326,  6297,    79,  1409])context_tensors: \n",
            " context_tensors: tensor([ 1411, 28653, 12153, 19921, 10996, 20586]) \n",
            "tensor([ 1411, 13448, 26026,    76, 14441, 19251])context_tensors: \n",
            " context_tensors: tensor([28653, 12153, 18616, 10996, 20586, 11372]) \n",
            "tensor([13448, 26026,  6297, 14441, 19251, 13448])context_tensors: \n",
            "context_tensors:   tensor([12153, 18616, 19921, 20586, 11372,    76])tensor([26026,  6297,    76, 19251, 13448, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([18616, 19921, 10996, 11372,    76,  2128]) tensor([ 6297,    76, 14441, 13448, 26026,  1410])\n",
            "\n",
            "context_tensors:  context_tensors:  tensor([19921, 10996, 20586,    76,  2128, 13448])\n",
            "tensor([   76, 14441, 19251, 26026,  1410, 13863])\n",
            "context_tensors: context_tensors:   tensor([10996, 20586, 11372,  2128, 13448, 26026])\n",
            "tensor([14441, 19251, 13448,  1410, 13863, 18047])\n",
            "context_tensors:  context_tensors: tensor([20586, 11372,    76, 13448, 26026,  1410]) \n",
            "tensor([19251, 13448, 26026, 13863, 18047,  1410])\n",
            "context_tensors: context_tensors:   tensor([13448, 26026,  1410, 18047,  1410,  5415])\n",
            "tensor([11372,    76,  2128, 26026,  1410,    76])\n",
            "context_tensors: context_tensors:   tensor([26026,  1410, 13863,  1410,  5415,    76])\n",
            "context_tensors: tensor([   76,  2128, 13448,  1410,    76,  9518]) \n",
            "tensor([ 1410, 13863, 18047,  5415,    76,  1423])context_tensors: \n",
            "context_tensors:   tensor([13863, 18047,  1410,    76,  1423, 23726])\n",
            "tensor([ 2128, 13448, 26026,    76,  9518, 26026])\n",
            "context_tensors: context_tensors:   tensor([18047,  1410,  5415,  1423, 23726, 26046])\n",
            "tensor([13448, 26026,  1410,  9518, 26026, 23244])\n",
            "context_tensors: context_tensors:   tensor([26026,  1410,    76, 26026, 23244,    79])tensor([ 1410,  5415,    76, 23726, 26046,  9805])\n",
            "\n",
            "context_tensors:  tensor([ 1410,    76,  9518, 23244,    79,  1409])\n",
            "context_tensors:  context_tensors:  tensor([ 5415,    76,  1423, 26046,  9805, 14519])\n",
            "tensor([ 1411,  1900, 26026, 10648, 11372,    76])\n",
            "context_tensors: context_tensors:   tensor([ 1900, 26026, 10609, 11372,    76,  2128])tensor([   76,  1423, 23726,  9805, 14519,  4787])\n",
            "\n",
            "context_tensors: context_tensors:  tensor([26026, 10609, 10648,    76,  2128, 15887]) \n",
            "tensor([ 1423, 23726, 26046, 14519,  4787, 26026])context_tensors: \n",
            " context_tensors:  tensor([10609, 10648, 11372,  2128, 15887,    76])\n",
            "tensor([23726, 26046,  9805,  4787, 26026, 10232])context_tensors: \n",
            " tensor([10648, 11372,    76, 15887,    76, 14343])\n",
            "context_tensors: context_tensors:  tensor([11372,    76,  2128,    76, 14343,  5146])\n",
            " context_tensors: tensor([26046,  9805, 14519, 26026, 10232,    79])\n",
            " context_tensors:  tensor([ 9805, 14519,  4787, 10232,    79,  1409])tensor([   76,  2128, 15887, 14343,  5146, 25246])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([ 1411, 12451, 21439,   117,     4, 18520]) \n",
            "context_tensors: tensor([ 2128, 15887,    76,  5146, 25246,  1423])\n",
            " context_tensors: tensor([12451, 21439, 14576,     4, 18520, 26026])\n",
            " tensor([15887,    76, 14343, 25246,  1423,  4563])context_tensors: \n",
            " tensor([21439, 14576,   117, 18520, 26026, 27811])context_tensors: \n",
            " context_tensors: tensor([   76, 14343,  5146,  1423,  4563, 10854]) \n",
            "tensor([14576,   117,     4, 26026, 27811,  2371])context_tensors: \n",
            "context_tensors:   tensor([14343,  5146, 25246,  4563, 10854, 26023])tensor([  117,     4, 18520, 27811,  2371, 10575])\n",
            "\n",
            "context_tensors: context_tensors:   tensor([ 5146, 25246,  1423, 10854, 26023, 14763])\n",
            "context_tensors: tensor([    4, 18520, 26026,  2371, 10575, 15252]) tensor([25246,  1423,  4563, 26023, 14763, 12729])\n",
            "\n",
            "context_tensors:  tensor([ 1423,  4563, 10854, 14763, 12729, 18854])\n",
            "context_tensors: context_tensors:  tensor([18520, 26026, 27811, 10575, 15252,    79])\n",
            " tensor([ 4563, 10854, 26023, 12729, 18854, 18520])context_tensors: \n",
            " tensor([26026, 27811,  2371, 15252,    79,  1409])\n",
            "context_tensors: context_tensors:   tensor([ 1411, 10839, 26026,    76, 26026,  4125])tensor([10854, 26023, 14763, 18854, 18520, 26026])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([10839, 26026,  4439, 26026,  4125, 14252])\n",
            " context_tensors: tensor([26023, 14763, 12729, 18520, 26026, 15648])\n",
            " tensor([26026,  4439,    76,  4125, 14252, 28115])\n",
            "context_tensors: context_tensors:   tensor([14763, 12729, 18854, 26026, 15648,  1416])tensor([ 4439,    76, 26026, 14252, 28115, 18605])\n",
            "\n",
            "context_tensors:  context_tensors: tensor([   76, 26026,  4125, 28115, 18605, 26026]) \n",
            "tensor([12729, 18854, 18520, 15648,  1416, 27275])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8df680a9531d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Train model for N_EPOCHS epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_cbow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-b95ff9f73dce>\u001b[0m in \u001b[0;36mtrain_cbow_model\u001b[0;34m(model, num_epochs, data_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to(torch.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__=='__main__':\n",
        "    N_EPOCHS = 5 # Feel free to change this\n",
        "    \n",
        "    # Train model for N_EPOCHS epochs\n",
        "    train_cbow_model(cbow_model, N_EPOCHS, cbow_dataloader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLNHHFgoB7Tb"
      },
      "source": [
        "To get full credit on the word embeddings, you must return the correct vectors when your model is instantiated with a particular random seed and called on the autograder. This is worth <b>15 points</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWea2Lgh-MBX"
      },
      "source": [
        "## Visualize Word Embeddings\n",
        "\n",
        "Now that you have a trained model, we can extract the word embeddings and visualize them. The word embeddings are basically the weight matrix of the embedding layer that you defined, as this maps each index of your vocab to a dense vector of size `embed_size`.\n",
        "\n",
        "Since we cannot easily visualize such high-dimensional vectors, we use a process called TSNE (t-distributed stochastic neighbor embedding). This reduces the vectors to a 2-dimensional space so that we can visualize them. For more information on TSNE, see https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding). Note that this method is not deterministic, so running this cell multiple times will give you a different visualization.\n",
        "\n",
        "The cell below will run TSNE and plot the word embeddings corresponding to thed 1,000 most frequent words on a 2-dimensional plot. You are welcome to increase this threshold if you'd like to see the vectors for more words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5e4xjOIS3nS"
      },
      "outputs": [],
      "source": [
        "if __name__=='__main__':    \n",
        "    from sklearn.manifold import TSNE\n",
        "    import numpy as np\n",
        "    import plotly.express as px\n",
        "    import pandas as pd\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    THRESHOLD = 1000\n",
        "    words = [x[0] for x in sorted(vocab.items(), key = lambda x: -x[1])[:THRESHOLD]]\n",
        "    idxes = [cbow_dataset.word2idx[word] for word in words]\n",
        "    vectors = np.array([cbow_model.embedding.weight[i].tolist() for i in idxes])\n",
        "\n",
        "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, verbose=False)\n",
        "    new_vectors = tsne_model.fit_transform(vectors)\n",
        "\n",
        "    df = pd.DataFrame(data={'x': new_vectors[:,0], 'y': new_vectors[:,1], 'word':words})\n",
        "\n",
        "    fig = px.scatter(df, x='x', y='y', text='word')\n",
        "    fig.update_traces(textposition='top center')\n",
        "    fig.update_layout(height=600, title_text='Word Embedding 2D Visualization')\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qNOeI2Wn76l"
      },
      "source": [
        "At a high level, you should see words with similar meaning clustering together. You can use your mouse to zoom in and inspect the vector space closer.\n",
        "\n",
        "You should also see mini-clusters within this plot; you would need to zoom into examine these. Examples of mini-clusters you might see are:\n",
        "* <b>Time words:</b> hours, minutes, seconds, months, weeks, years, etc.\n",
        "* <b>Years:</b> 2000, 2002, 2004, etc.\n",
        "* <b>Numbers:</b> 10, 15, 37, etc.\n",
        "* <b>Months:</b> january, february, march, etc. <em>Question: does the word 'may', which is both a month and a modal verb, cluster with the other months? If not, can you see where it is in relation to other modal verbs ('can', 'will', 'would', 'might', etc.)?</em>\n",
        "\n",
        "Feel free to increase the number of vectors plotted if you want to investigate further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHbJ1-aDsWCG"
      },
      "source": [
        "# Part 2: Train a Convolutional Neural Network (CNN) [50 points]\n",
        "\n",
        "The second part of this homework concerns text classification. You will train a CNN classifier to determine the sentiment of movie reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMVBA0ijAUgt"
      },
      "source": [
        "## Download & Preprocess the Data\n",
        "We will be using the IMDb movie reviews dataset, which is a corpus of movie reviews along with a <em>positive</em> or <em>negative</em> classification. This is again provided by torchtext.\n",
        "\n",
        "The following cell will produce `train_data` and `test_data`. It also does some basic tokenization.\n",
        "\n",
        "*   To access the list of textual tokens for the *i*th example, use `train_data[i][1]`\n",
        "*   To access the label for the *i*th example, use `train_data[i][0]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dfX3bNby8FYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e3b0f4-e86e-4faf-fad4-1d6866aa10d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. Train Examples: 20000\n",
            "Num. Test Examples: 5000\n",
            "\n",
            "SAMPLE DATA:\n",
            "Sample text: ['This', 'movie', 'pretty', 'much', 'surprised', 'me', '.', 'I', \"didn't\", 'have', 'very', 'high', 'expectations', 'for', 'it', 'but', 'I', 'was', 'wrong', '.', 'Mary', '&', 'Rhoda', 'was', 'very', 'funny', 'and', 'well', 'written', '.', 'They', \"didn't\", 'spend', 'too', 'much', 'time', 'rehashing', 'the', 'past', 'so', 'they', \"weren't\", 'relying', 'on', 'the', 'success', 'of', 'the', 'old', 'TV', 'show', 'to', 'carry', 'the', 'movie', '.', 'Overall', 'it', 'was', 'very', 'entertaining.<br', '/><br', '/>My', 'girlfriend', 'commented', 'that', 'this', 'could', 'be', 'a', 'weekly', 'sit-com', 'and', 'I', 'think', 'I', 'might', 'agree', 'with', 'her', '.']\n",
            "Sample label: pos \n",
            "\n",
            "Sample text: ['This', 'movie', 'is', 'brilliant', 'in', 'every', 'way', '.', 'It', 'touches', 'on', 'the', 'complexities', 'of', 'loving', 'relationships', 'in', 'a', 'meaningful', 'way', ',', 'but', 'never', 'lectures', '.', 'The', 'script', 'never', 'condescends', 'toward', 'any', 'character', ',', 'not', 'even', 'the', 'hapless', 'Johnny', '.', 'It', 'also', 'and', 'benefits', 'from', 'spot-on', 'direction', ',', 'production', 'design', ',', 'casting', ',', 'and', 'performances', '.', 'The', 'fact', 'that', 'Cher', 'is', 'so', 'perfect', 'in', 'the', 'film', 'and', 'is', 'more', 'unlike', '\"', 'Cher', '\"', 'than', 'she', 'has', 'ever', 'been', 'is', 'a', 'wonder', 'to', 'me', '.', 'I', 'watch', 'Moonstruck', 'at', 'least', 'once', 'a', 'year', 'and', 'I', 'just', 'viewed', 'it', 'again', 'this', 'Christmas', 'eve', 'with', 'my', '16', 'year', 'old', 'twin', 'daughters', 'and', 'they', 'loved', 'it', 'as', 'well', '.', 'It', 'has', 'something', 'for', 'everyone', 'with', 'a', 'heart', 'and', 'leaves', 'you', 'filled', 'with', 'joy', 'in', 'the', 'end', '.']\n",
            "Sample label: pos \n",
            "\n",
            "Sample text: ['This', 'is', 'the', 'worst', 'movie', 'I', 'have', 'seen', 'for', 'years', '!', 'It', 'starts', 'ridicoulus', 'and', 'continues', 'in', 'the', 'same', 'way', '.', 'I', 'thnik', 'when', 'is', 'something', 'going', 'to', 'happen', 'in', 'this', 'film,,,', ',', 'and', 'the', 'the', 'acting', 'is', 'worse', '.', 'The', 'ending', 'lifts', 'it', 'a', 'bit', 'and', 'saves', 'the', 'movie', 'from', 'a', 'total', 'flop', '.', 'Mark', 'Wahlberg', 'is', 'a', 'bad', 'actor', 'in', 'a', 'bad', 'movie', '.', 'Sorry', 'Tim', 'Burton', 'Batman', 'was', 'good', 'but', 'this', 'one', 'sucks', '.']\n",
            "Sample label: neg \n",
            "\n",
            "Sample text: ['There', 'is', 'no', 'question', 'as', 'to', 'who', 'is', 'in', 'command', 'of', 'the', 'training', 'of', 'cadets', 'in', 'this', 'film', ':', 'Major', 'Chick', 'Davis', '(', 'Pat', \"O'Brien)\", '.', \"O'Brien\", 'plays', 'an', 'officer', 'who', 'adheres', 'to', 'military', 'discipline', 'in', 'the', 'creation', 'of', 'a', 'new', 'kind', 'of', 'soldier', 'from', 'his', 'cadets--the', 'bombardier', '.', 'But', 'he', 'is', 'not', 'so', 'rigid', 'as', 'to', 'be', 'unfair', 'or', 'unfriendly', '.', 'In', 'fact', ',', 'he', 'even', 'changes', 'his', 'opinion', 'as', 'to', 'the', 'value', 'of', 'women', 'working', 'in', 'the', 'military', '.', \"He's\", 'tough', 'when', 'he', 'has', 'to', 'be', ',', 'yet', 'at', 'other', 'times', 'he', 'is', 'a', 'clear', 'mix', 'of', 'coach', 'and', 'pastor', ',', 'roles', 'he', 'perfected', 'in', 'other', 'films', '.', 'His', 'character', 'is', 'the', 'foundation', 'of', 'the', 'action', 'around', 'which', 'everything', 'revolves', '.', \"O'Brien\", 'seems', 'natural', 'in', 'the', 'role', ',', 'and', 'plays', 'it', 'in', 'fine', 'fashion', '.', 'Two', 'things', 'help', 'this', 'movie', ':', \"O'Brien's\", 'performance', 'and', 'the', 'spectacular', 'special', 'effects', 'ending', '.']\n",
            "Sample label: neg \n",
            "\n",
            "Sample text: ['Probably', 'the', 'worst', 'Bollywood', 'film', \"I've\", 'seen.<br', '/><br', '/>No', 'plot', 'line', '.', 'Very', 'little', 'character', 'developments.<br', '/><br', '/>Full', 'of', 'silly', 'and', 'pointless', 'humor', '.', 'The', 'whole', 'film', 'was', 'chaotic', 'and', 'direction-less', '.', 'There', 'was', 'no', 'proper', 'ending', 'to', 'the', 'story', '.', 'The', 'airport', 'was', 'filmed', 'in', 'a', 'shopping', 'mall', '.', '<br', '/><br', '/>Same', 'story', 'chewed', 'over', 'and', 'over', 'again', 'until', 'you', 'want', 'to', 'say', '\"', 'please', ',', 'just', 'move', 'on', 'with', 'it!!', '\"', 'Even', 'the', 'song', 'and', 'dance', 'was', 'pointless', 'and', 'badly', 'choreographed.<br', '/><br', '/>The', 'only', 'good', 'thing', 'about', 'this', 'movie', 'is', 'that', 'there', 'were', 'hot', 'bods', 'all', 'around..', '.', 'but', 'then', 'most', 'of', 'the', 'Bollywood', 'movies', 'have', 'that', 'anyways', 'these', 'days.<br', '/><br', '/>Btw', \"I'm\", 'not', 'from', 'an', 'Indian', 'background<br', '/><br', '/>2/10']\n",
            "Sample label: neg \n",
            "\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torchtext\n",
        "import random\n",
        "\n",
        "def cnn_preprocess(review):\n",
        "    '''\n",
        "    Simple preprocessing function.\n",
        "    '''\n",
        "    res = []\n",
        "    for x in review.split(' '):\n",
        "        remove_beg=True if x[0] in {'(', '\"', \"'\"} else False\n",
        "        remove_end=True if x[-1] in {'.', ',', ';', ':', '?', '!', '\"', \"'\", ')'} else False\n",
        "        if remove_beg and remove_end: res += [x[0], x[1:-1], x[-1]]\n",
        "        elif remove_beg: res += [x[0], x[1:]]\n",
        "        elif remove_end: res += [x[:-1], x[-1]]\n",
        "        else: res += [x]\n",
        "    return res\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_data = torchtext.datasets.IMDB(root='.data', split='train')\n",
        "    train_data = list(train_data)\n",
        "    train_data = [(x[0], cnn_preprocess(x[1])) for x in train_data]\n",
        "    train_data, test_data = train_data[0:10000] + train_data[12500:12500+10000], train_data[10000:12500] + train_data[12500+10000:], \n",
        "\n",
        "    print('Num. Train Examples:', len(train_data))\n",
        "    print('Num. Test Examples:', len(test_data))\n",
        "\n",
        "    # Make pos/neg\n",
        "    train_data = [('neg' if x[0] == 1 else 'pos', x[1]) for x in train_data]  \n",
        "    test_data = [('neg' if x[0] == 1 else 'pos', x[1]) for x in test_data]\n",
        "\n",
        "    print(\"\\nSAMPLE DATA:\")\n",
        "    for x in random.sample(train_data, 5):\n",
        "        print('Sample text:', x[1])\n",
        "        print('Sample label:', x[0], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvFX-iX5oq7T"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the Dataset Class [10 Points]\n",
        "\n",
        "In the following cell, we will define the <b>dataset</b> class. The dataset contains the tokenized data for your model. You need to implement the following functions: \n",
        "\n",
        "*   <b>` build_dictionary(self)`:</b>  <b>[5 points]</b> Creates the dictionaries `idx2word` and `word2idx`. You will represent each word in the dataset with a unique index, and keep track of this in these dictionaries. Use the hyperparameter `threshold` to control which words appear in the dictionary: a training word’s frequency should be `>= threshold` to be included in the dictionary.\n",
        "\n",
        "* <b>`convert_text(self)`:</b> Converts each review in the dataset to a list of indices, given by your `word2idx` dictionary. You should store this in the `textual_ids` variable, and the function does not return anything. If a word is not present in the  `word2idx` dictionary, you should use the `<UNK>` token for that word. Be sure to append the `<END>` token to the end of each review.\n",
        "\n",
        "*   <b>` get_text(self, idx) `:</b> Return the review at `idx` in the dataset as an array of indices corresponding to the words in the review. If the length of the review is less than `max_len`, you should pad the review with the `<PAD>` character up to the length of `max_len`. If the length is greater than `max_len`, then it should only return the first `max_len` words. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*   <b>`get_label(self, idx) `</b>: Return the value `1` if the label for `idx` in the dataset is `positive`, and should return `0` if it is `negative`. The return type should be `torch.LongTensor`.\n",
        "\n",
        "*  <b> ` __len__(self) `:</b> Return the total number of reviews in the dataset as an `int`.\n",
        "\n",
        "*   <b>` __getitem__(self, idx)`:</b> <b>[5 points]</b> Return the (padded) text, and the label. The return type for both these items should be `torch.LongTensor`. You should use the ` get_label(self, idx) ` and ` get_text(self, idx) ` functions here.\n",
        "\n",
        "\n",
        "<b>Note:</b> You should convert all words to lower case in your functions.\n",
        "\n",
        "<font color='green'><b>Hint:</b> Make sure that you use instance variables such as `self.threshold` throughout your code, rather than the global variable `THRESHOLD` (defined later on). The variable `THRESHOLD` will not be known to the autograder, and the use of it within the class will cause an autograder error.</font>\n",
        "\n",
        "<font color='green'><b>Hint:</b> Make sure that your dataset is deterministic $-$ that is, if it is instantiated multiple times, then the `word2idx` and `idx2word` mappings are the same. If they are not, the autograder will be unable to evaluate your CNN classifications.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1irMn3LX2YDB"
      },
      "outputs": [],
      "source": [
        "CNN_PAD = '<PAD>'\n",
        "CNN_END = '<END>'\n",
        "CNN_UNK = '<UNK>'\n",
        "\n",
        "from torch.utils import data\n",
        "from collections import defaultdict\n",
        "\n",
        "class TextDataset(data.Dataset):\n",
        "    def __init__(self, examples, split, threshold, max_len, idx2word=None, word2idx=None):\n",
        "        ##### DO NOT EDIT #####\n",
        "\n",
        "        self.examples = examples\n",
        "        assert split in {'train', 'val', 'test'}\n",
        "        self.split = split\n",
        "        self.threshold = threshold\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Dictionaries\n",
        "        self.word2idx = word2idx # Mapping of word to index\n",
        "        self.idx2word = idx2word # Mapping of index to word\n",
        "        if split == 'train':\n",
        "            self.build_dictionary()\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "        \n",
        "        # Convert text to indices\n",
        "        self.textual_ids = []\n",
        "        self.convert_text()\n",
        "\n",
        "    \n",
        "    def build_dictionary(self): \n",
        "        '''\n",
        "        Build the dictionaries idx2word and word2idx. This is only called when split='train', as these\n",
        "        dictionaries are passed in to the __init__(...) function otherwise. Be sure to use self.threshold\n",
        "        to control which words are assigned indices in the dictionaries.\n",
        "        Returns nothing.\n",
        "        '''\n",
        "        assert self.split == 'train'\n",
        "        \n",
        "        # Don't change this\n",
        "        self.idx2word = {0:CNN_PAD, 1:CNN_END, 2: CNN_UNK}\n",
        "        self.word2idx = {CNN_PAD:0, CNN_END:1, CNN_UNK: 2}\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Count the frequencies of all words in the training data (self.examples)\n",
        "        # Assign idx (starting from 3) to all words having word_freq >= self.threshold\n",
        "        # Make sure you call word.lower() on each word to convert it to lowercase\n",
        "        \n",
        "        #print(\"hahahah\",self.examples) # [('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health']), ('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])]\n",
        "        d_temp=defaultdict(int)\n",
        "        for sent in self.examples:\n",
        "          #print(sent[1])\n",
        "          for word in sent[1]:    \n",
        "            #print(word)\n",
        "            d_temp[word.lower()]+=1\n",
        "        idx =3\n",
        "        for k,v in d_temp.items():\n",
        "          #print(self.threshold)\n",
        "          if int(v >= self.threshold):\n",
        "            self.idx2word[idx]=k\n",
        "            self.word2idx[k]=idx\n",
        "            idx+=1\n",
        "        #print(\"dictionary \",self.word2idx)\n",
        "\n",
        "    def convert_text(self):\n",
        "        '''\n",
        "        Convert each review in the dataset (self.examples) to a list of indices, given by self.word2idx.\n",
        "        Store this in self.textual_ids; returns nothing.\n",
        "        '''\n",
        "\n",
        "        ##### TODO #####\n",
        "        # Remember to replace a word with the <UNK> token if it does not exist in the word2idx dictionary.\n",
        "        # Remember to append the <END> token to the end of each review.\n",
        "        for sent in self.examples:\n",
        "            #sent[1].append('<END>')\n",
        "            #print(sent[1])\n",
        "            temp=[]\n",
        "            for word in sent[1]:\n",
        "              #word=word.lower()\n",
        "              if word.lower() in self.word2idx:\n",
        "                temp.append(self.word2idx[word.lower()])\n",
        "              else:\n",
        "                temp.append(self.word2idx[CNN_UNK]) # textual_ids has indices of words in self.examples\n",
        "            temp.append(self.word2idx[CNN_END])\n",
        "            self.textual_ids.append(temp)\n",
        "\n",
        "        #print(\"textual stuff: \",self.textual_ids)\n",
        "        \n",
        "        \n",
        "\n",
        "    def get_text(self, idx):\n",
        "        '''\n",
        "        Return the review at idx as a long tensor (torch.LongTensor) of integers corresponding to the words in the review.\n",
        "        You may need to pad as necessary (see above).\n",
        "        '''\n",
        "        #for review in self.textual_ids:\n",
        "        if len(self.textual_ids[idx]) < self.max_len:\n",
        "          diff=self.max_len-len(self.textual_ids[idx])\n",
        "          self.textual_ids[idx].extend((diff)*[self.word2idx[CNN_PAD]])\n",
        "          tensor_indices=torch.LongTensor(self.textual_ids[idx])\n",
        "        else:\n",
        "          tensor_indices=torch.LongTensor(self.textual_ids[idx][0:self.max_len])\n",
        "        \n",
        "        return tensor_indices\n",
        "    \n",
        "    def get_label(self, idx):\n",
        "        '''\n",
        "        This function should return the value 1 if the label for idx in the dataset is 'positive', \n",
        "        and 0 if it is 'negative'. The return type should be torch.LongTensor.\n",
        "        '''\n",
        "        if self.examples[idx][0]=='pos':\n",
        "          tensor_label = torch.tensor(1, dtype=torch.long)\n",
        "        else:\n",
        "          tensor_label = torch.tensor(0, dtype=torch.long)\n",
        "        return tensor_label\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Return the number of reviews (int value) in the dataset\n",
        "        '''\n",
        "        return int(len(self.textual_ids)) # same as examples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Return the review, and label of the review specified by idx.\n",
        "        '''\n",
        "        i = self.get_text(idx)\n",
        "        l = self.get_label(idx)\n",
        "        ##### TODO #####\n",
        "\n",
        "        return i,l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxVxiGGbFJAj"
      },
      "source": [
        "##Sanity Check: Dataset Class\n",
        "\n",
        "The code below runs a sanity check for your `Dataset` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bvHIZt8Z-RzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d26c35-9a52-4cbc-c73d-b29d1f5225ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "('pos', ['Your', 'life', 'is', 'good', 'when', 'you', 'have', 'money', ',', 'success', 'and', 'health'])\n",
            "('neg', ['Life', 'is', 'bad', 'when', 'you', 'got', 'not', 'a', 'lot'])\n",
            "\n",
            "--- TEST: idx2word and word2idx dictionaries ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tPASSED \t\n",
            "\n",
            "--- TEST: len(dataset) ---\n",
            "\tPASSED\n",
            "\n",
            "--- TEST: __getitem__(self, idx) ---\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 1 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 2 \tmax_len: 15 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 3 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 8 \tidx: 1 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 0 \tPASSED \t\n",
            "\tthreshold: 3 \tmax_len: 15 \tidx: 1 \tPASSED \t\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def sanityCheckTextDataset():\n",
        "    #\tRead in the sample corpus\n",
        "    reviews = [('pos', 'Your life is good when you have money, success and health'),\n",
        "               ('neg', 'Life is bad when you got not a lot')]\n",
        "    data = [(x[0], cnn_preprocess(x[1])) for x in reviews]\n",
        "    print(\"Sample dataset:\")\n",
        "    for x in data: print(x)\n",
        "\n",
        "    thresholds = [1,2,3]\n",
        "    print('\\n--- TEST: idx2word and word2idx dictionaries ---') # max_len does not matter for this test\n",
        "    correct = [[',', '<END>', '<PAD>', '<UNK>', 'a', 'and', 'bad', 'good', 'got', 'have', 'health', 'is', 'life', 'lot', 'money', 'not', 'success', 'when', 'you', 'your'], ['<END>', '<PAD>', '<UNK>', 'is', 'life', 'when', 'you'], ['<END>', '<PAD>', '<UNK>']]\n",
        "    for i in range(len(thresholds)):\n",
        "        dataset = TextDataset(data, 'train', threshold=thresholds[i], max_len=3)\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and (dataset.vocab_size != len(dataset.word2idx) or dataset.vocab_size != len(dataset.idx2word)):\n",
        "            has_passed, message = False, 'dataset.vocab_size (' + str(dataset.vocab_size) + ') must be the same length as dataset.word2idx (' + str(len(dataset.word2idx)) + ') and dataset.idx2word ('+str(len(dataset.idx2word)) +').'\n",
        "        if has_passed and (dataset.vocab_size != len(correct[i])):\n",
        "            has_passed, message = False, 'Your vocab size is incorrect. Expected: ' + str(len(correct[i])) + '\\tGot: ' + str(dataset.vocab_size)\n",
        "        if has_passed and sorted(list(dataset.idx2word.keys())) != list(range(0, dataset.vocab_size)):\n",
        "            has_passed, message = False, 'dataset.idx2word must have keys ranging from 0 to dataset.vocab_size-1. Keys in your dataset.idx2word: ' + str(sorted(list(dataset.idx2word.keys())))\n",
        "        if has_passed and sorted(list(dataset.word2idx.keys())) != correct[i]:\n",
        "            has_passed, message = False, 'Your dataset.word2idx has incorrect keys. Expected: ' + str(correct[i]) + '\\tGot: ' + str(sorted(list(dataset.word2idx.keys())))\n",
        "        if has_passed: # Check that word2idx and idx2word are consistent\n",
        "            widx = sorted(list(dataset.word2idx.items())) \n",
        "            idxw = sorted(list([(v,k) for k,v in dataset.idx2word.items()]))\n",
        "            if not (len(widx) == len(idxw) and all([widx[q] == idxw[q] for q in range(len(widx))])):\n",
        "                has_passed, message = False, 'Your dataset.word2idx and dataset.idx2word are not consistent. dataset.idx2word: ' + str(dataset.idx2word) + '\\tdataset.word2idx: ' + str(dataset.word2idx)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', thresholds[i], '\\tmax_len:', 3, '\\t'+status, '\\t'+message)\n",
        "    \n",
        "    print('\\n--- TEST: len(dataset) ---')\n",
        "    has_passed = len(dataset) == 2\n",
        "    if has_passed: print('\\tPASSED')\n",
        "    else: print('\\tlen(dataset) is incorrect. Expected: 2\\tGot: ' + str(len(dataset)))\n",
        "\n",
        "    print('\\n--- TEST: __getitem__(self, idx) ---')\n",
        "    max_lens = [3,8,15]\n",
        "    idxes = [0,1]\n",
        "    combos = [{'threshold': t, 'max_len': m, 'idx': idx} for t in thresholds for m in max_lens for idx in idxes]\n",
        "    correct = [(torch.tensor([3, 4, 5]), torch.tensor(1)), (torch.tensor([ 4,  5, 15]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18]), torch.tensor(0)), (torch.tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  0,  0]), torch.tensor(1)), (torch.tensor([ 4,  5, 15,  7,  8, 16, 17, 18, 19,  1,  0,  0,  0,  0,  0]), torch.tensor(0)), (torch.tensor([2, 3, 4]), torch.tensor(1)), (torch.tensor([3, 4, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 3, 4, 2, 5, 6, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([3, 4, 2, 5, 6, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0)), (torch.tensor([2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2]), torch.tensor(0)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0]), torch.tensor(1)), (torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0]), torch.tensor(0))]\n",
        "    for i in range(len(combos)):\n",
        "        combo = combos[i]\n",
        "        dataset = TextDataset(data, 'train', threshold=combo['threshold'], max_len=combo['max_len'])\n",
        "        returned = dataset.__getitem__(combo['idx'])\n",
        "\n",
        "        has_passed, message = True, ''\n",
        "        if has_passed and len(returned) != 2:\n",
        "            has_passed, message = False, 'dataset.__getitem__(idx) must return 2 items. Got ' + str(len(returned)) +' items instead.'\n",
        "        if has_passed and (type(returned[0]) != torch.Tensor or type(returned[1]) != torch.Tensor):\n",
        "            has_passed, message = False, 'Both returns must be of type torch.Tensor. Got: (' + str(type(returned[0])) + ', ' + str(type(returned[1])) + ')'\n",
        "        if has_passed and (returned[0].shape != correct[i][0].shape):\n",
        "            has_passed, message = False, 'Shape of first return is incorrect. Expected: ' + str(correct[i][0].shape) + '.\\tGot: ' + str(returned[0].shape)\n",
        "        if has_passed and (returned[1].shape != correct[i][1].shape):\n",
        "            has_passed, message = False, 'Shape of second return is incorrect. Expected: ' + str(correct[i][1].shape) + '.\\tGot: ' + str(returned[1].shape) + '\\n\\t\\tHint: torch.Size([]) means that the tensor should be dimensionless (just a number). Try squeezing your result.'\n",
        "        if has_passed and (returned[1] != correct[i][1]):\n",
        "            has_passed, message = False, 'Label (second return) is incorrect. Expected: ' + str(correct[i][1]) + '.\\tGot: ' + str(returned[1])\n",
        "        if has_passed:\n",
        "            correct_padding_idxes, your_padding_idxes = torch.where(correct[i][0] == 0)[0], torch.where(returned[0] == dataset.word2idx[CNN_PAD])[0]\n",
        "            if not (correct_padding_idxes.shape == your_padding_idxes.shape and torch.all(correct_padding_idxes == your_padding_idxes)):\n",
        "                has_passed, message = False, 'Padding is not correct. Expected padding indxes: ' + str(correct_padding_idxes) + '.\\tYour padding indexes: ' + str(your_padding_idxes)\n",
        "\n",
        "        status = 'PASSED' if has_passed else 'FAILED'\n",
        "        print('\\tthreshold:', combo['threshold'], '\\tmax_len:', combo['max_len'] , '\\tidx:', combo['idx'], '\\t'+status, '\\t'+message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sanityCheckTextDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4VQbQCNZH6"
      },
      "source": [
        "The following cell builds the dataset on the IMDb movie reviews and prints an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HSxpGXj6ml9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4503bcc-1527-44cc-a0cb-623476d78c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 19002 \n",
            "\n",
            "Example text:\n",
            "['This', 'was', 'the', 'worst', 'movie', 'I', 'have', 'ever', 'seen', 'and', \"I've\", 'seen', 'a', 'lot', 'of', 'bad', 'movies', '.', 'First', 'of', \"I'm\", 'from', 'Kansas', 'this', 'movie', 'does', 'not', 'have', 'a', 'shred', 'of', 'truth', 'in', 'it', 'at', 'all', '.', 'Its', 'like', 'they', 'took', 'BTK', 'name', 'and', 'made', 'up', 'the', 'rest', '.', 'On', 'top', 'of', 'that', 'it', 'looks', 'like', 'someone', 'was', 'like', \"I've\", 'only', 'got', '$20', 'bucks', 'here', 'take', 'it', 'and', 'make', 'a', 'movie', 'and', 'oh', 'yeah', \"don't\", 'worry', 'about', 'researching', 'btk', 'at', 'all', 'just', 'make', 'up', 'something', '.', 'seriously', 'pure', 'dookie', 'no', 'one', 'should', 'ever', 'see', 'this', 'movie', '.', 'The', 'slaughtering', 'cows', 'scenes', 'and', 'making', 'his', 'victims', 'eat', 'stuff', 'and', 'describing', 'animal', 'slaughter', 'BTK', 'did', 'none', 'of', 'these', 'things', 'but', 'the', 'movie', 'does', 'so', 'for', 'the', 'love', 'of', 'god', 'never', 'see', 'this', 'god', 'awful', 'movie', '.', 'The', 'made', 'for', 'TV', 'ones', 'are', 'way', 'better', 'and', 'way', 'more', 'accurate']\n",
            "tensor([   36,    19,    13,   474,   369,     3,   182,    32,   206,    91,\n",
            "          205,   206,    41,   624,    11,   473,   229,    24,    20,    11,\n",
            "         1280,     6, 12702,    36,   369,   305,   125,   182,    41,   426,\n",
            "           11,  2376,    22,    17,    27,    12,    24,   370,   127,   209,\n",
            "         1183, 13147,  1613,    91,   129,   314,    13,   829,    24,    80,\n",
            "          467,    11,    15,    17,   567,   127,   562,    19,   127,   205,\n",
            "          210,   410,  1672,  1305,   976,   250,    17,    91,   165,    41,\n",
            "          369,    91,   373,  3690,   217,  1636,    70, 14246, 13147,    27,\n",
            "           12,   162,   165,   314,  1146,    24,   195,  2393,     2,   176,\n",
            "          253,   249,    32,    49,    36,   369,    24,    13,  8096, 14019,\n",
            "          118,    91,    76,   148,  3522,  3416,   428,    91,  6702,  3100,\n",
            "        12980, 13147,   387,   977,    11,   618,   784,   180,    13,   369,\n",
            "          305,   302,    50,    13,   569,    11,  2717,   507,    49,    36,\n",
            "         2717,   547,   369,    24,    13,   129,    50,  1173,   476,   119,\n",
            "          553,   321,    91,   553,   743,  6161,     1,     0,     0,     0])\n",
            "\n",
            "Example label:\n",
            "neg\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    train_dataset = TextDataset(train_data, 'train', threshold=10, max_len=150)\n",
        "    print('Vocab size:', train_dataset.vocab_size, '\\n')\n",
        "\n",
        "    randidx = random.randint(0, len(train_dataset)-1)\n",
        "    text, label = train_dataset[randidx]\n",
        "    print('Example text:')\n",
        "    print(train_data[randidx][1])\n",
        "    print(text)\n",
        "    print('\\nExample label:')\n",
        "    print(train_data[randidx][0])\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcSKydlClwOC"
      },
      "source": [
        "## <font color='red'>TODO:</font> Define the CNN Model [20 points]\n",
        "Here you will define your convolutional neural network for text classification. We provide you with the CNN class, you need to fill in parts of the `__init__(...)` and `forward(...)` functions. Each of these functions is worth <b>10 points</b>.\n",
        "\n",
        "We have provided you with instructions and hints in the comments. In particular, pay attention to the desired shapes; you may find it helpful to print the shape of the tensors as you code. It may also help to keep PyTorch documentation open for the modules & functions you are using, since they describe input and output dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ztuy2hUaAof"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, out_channels, filter_heights, stride, dropout, num_classes, pad_idx):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        ##### TODO #####\n",
        "        # Create an embedding layer (https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "        #   to represent the words in your vocabulary. Make sure to use vocab_size, embed_size, and pad_idx here.\n",
        "\n",
        "        # Define multiple Convolution layers (nn.Conv2d) with filter (kernel) size [filter_height, embed_size] based on your \n",
        "        #   different filter_heights.\n",
        "        # Input channels will be 1 and output channels will be out_channels (these many different filters will be trained \n",
        "        #   for each convolution layer)\n",
        "        # If you want, you can store a list of modules inside nn.ModuleList.\n",
        "        # Note: even though your conv layers are nn.Conv2d, we are doing a 1d convolution since we are only moving the filter \n",
        "        #   in one direction\n",
        "\n",
        "        # Create a dropout layer (nn.Dropout) using dropout\n",
        "\n",
        "        # Define a linear layer (nn.Linear) that consists of num_classes units \n",
        "        #   and takes as input the concatenated output for all cnn layers (out_channels * num_of_cnn_layers units)\n",
        "        # Create an embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, pad_idx)\n",
        "\n",
        "        # Define multiple Convolution layers\n",
        "        self.conv_layers = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(fh, embed_size), stride=(stride, embed_size)) for fh in filter_heights])\n",
        "\n",
        "        # Create a dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Define a linear layer\n",
        "        self.fc = nn.Linear(out_channels * len(filter_heights), num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, texts):\n",
        "        \"\"\"\n",
        "        texts: LongTensor [batch_size, max_len]\n",
        "        \n",
        "        Returns output: Tensor [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "\n",
        "        ##### TODO #####\n",
        "\n",
        "        # Pass texts through your embedding layer to convert from word ids to word embeddings\n",
        "        #   Resulting: shape: [batch_size, max_len, embed_size]\n",
        "\n",
        "        # Input to conv should have 1 channel. Take a look at torch's unsqueeze() function\n",
        "        #   Resulting shape: [batch_size, 1, MAX_LEN, embed_size]\n",
        "        \n",
        "        # Pass these texts to each of your conv layers and compute their output as follows:\n",
        "        #   Your cnn output will have shape [batch_size, out_channels, *, 1] where * depends on filter_height and stride\n",
        "        #   Convert to shape [batch_size, out_channels, *] (see torch's squeeze() function)\n",
        "        #   Apply non-linearity on it (F.relu() is a commonly used one. Feel free to try others)\n",
        "        #   Take the max value across last dimension to have shape [batch_size, out_channels]\n",
        "        # Concatenate (torch.cat) outputs from all your cnns [batch_size, (out_channels*num_of_cnn_layers)]\n",
        "        #\n",
        "\n",
        "        # Let's understand what you just did:\n",
        "        #   Since each cnn is of different filter_height, it will look at different number of words at a time\n",
        "        #     So, a filter_height of 3 means your cnn looks at 3 words (3-grams) at a time and tries to extract some information from it\n",
        "        #   Each cnn will learn out_channels number of features from the words it sees at a time\n",
        "        #   Then you applied a non-linearity and took the max value for all channels\n",
        "        #     You are essentially trying to find important n-grams from the entire text\n",
        "        # Everything happens on a batch simultaneously hence you have that additional batch_size as the first dimension\n",
        "\n",
        "        # Apply dropout\n",
        "\n",
        "        # Pass your output through the linear layer and return its output \n",
        "        #   Resulting shape: [batch_size, num_classes]\n",
        "\n",
        "        # NOTE: Do NOT apply a sigmoid or softmax to the final output - this is done in the training method!\n",
        "        # Pass texts through your embedding layer\n",
        "        embedded = self.embedding(texts)  # shape: [batch_size, max_len, embed_size]\n",
        "\n",
        "        # Input to conv should have 1 channel\n",
        "        embedded = embedded.unsqueeze(1)  # shape: [batch_size, 1, max_len, embed_size]\n",
        "\n",
        "        # Pass these texts to each of your conv layers\n",
        "        cnn_outputs = []\n",
        "        for conv in self.conv_layers:\n",
        "            output = conv(embedded)\n",
        "            output = output.squeeze(-1)  # shape: [batch_size, out_channels, *]\n",
        "            output = F.relu(output)\n",
        "            output = F.max_pool1d(output, output.size(2))  # shape: [batch_size, out_channels, 1]\n",
        "            cnn_outputs.append(output)\n",
        "\n",
        "        # Concatenate outputs from all your cnns\n",
        "        concat_cnn_outputs = torch.cat(cnn_outputs, dim=1)  # shape: [batch_size, out_channels*num_of_cnn_layers]\n",
        "\n",
        "        # Reshape to match input size expected by the fully connected layer\n",
        "        batch_size = concat_cnn_outputs.size(0)\n",
        "        fc_input = concat_cnn_outputs.view(batch_size, -1)\n",
        "\n",
        "        # Apply dropout\n",
        "        dropped = self.dropout(fc_input)\n",
        "\n",
        "        # Pass your output through the linear layer\n",
        "        out = self.fc(dropped)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVE_ujfnh0w"
      },
      "source": [
        "##Sanity Check: CNN Model\n",
        "\n",
        "The code below runs a sanity check for your `CNN` class. The tests are similar to the hidden ones in Gradescope. However, note that passing the sanity check does <b>not</b> guarantee that you will pass the autograder; it is intended to help you debug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yy9oF6qUUHvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6bf899-b9f0-4142-c1a0-db2d63ef2cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TEST: Number of Model Parameters (tests __init__(...)) ---\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 22434\tYour Num. Params: 22434\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 22531\tYour Num. Params: 22531\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 23874\tYour Num. Params: 23874\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 23939\tYour Num. Params: 23939\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 41730\tYour Num. Params: 41730\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 42115\tYour Num. Params: 42115\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47490\tYour Num. Params: 47490\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47747\tYour Num. Params: 47747\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 44578\tYour Num. Params: 44578\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 44675\tYour Num. Params: 44675\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 47554\tYour Num. Params: 47554\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 47619\tYour Num. Params: 47619\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 82306\tYour Num. Params: 82306\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 82691\tYour Num. Params: 82691\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tExpected Num. Params: 94210\tYour Num. Params: 94210\n",
            "\tPASSED\tInput: {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tExpected Num. Params: 94467\tYour Num. Params: 94467\n",
            "\n",
            "--- TEST: Output shape of forward(...) ---\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 2])\tYour Output Shape: torch.Size([1, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 2])\tYour Output Shape: torch.Size([50, 2])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 10])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 10])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([1, 100])\tExpected Output Shape: torch.Size([1, 3])\tYour Output Shape: torch.Size([1, 3])\n",
            "\tPASSED\t Init Input: {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}\tForward Input Shape: torch.Size([50, 100])\tExpected Output Shape: torch.Size([50, 3])\tYour Output Shape: torch.Size([50, 3])\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def makeCnnSanityBatch(test_params):\n",
        "    batch_size = test_params['batch_size']\n",
        "    max_len = test_params['max_len']\n",
        "    new_test_params = {k:v for k,v in test_params.items() if k not in {'batch_size', 'max_len'}}\n",
        "    batch = torch.randint(0, new_test_params['vocab_size'], (batch_size,max_len))\n",
        "    return batch, new_test_params\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Test init\n",
        "    cnn_init_inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 32, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0}, {'vocab_size': 1000, 'embed_size': 32, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0}]\n",
        "    cnn_init_expected_outputs = [22434, 22531, 22434, 22531, 23874, 23939, 23874, 23939, 41730, 42115, 41730, 42115, 47490, 47747, 47490, 47747, 44578, 44675, 44578, 44675, 47554, 47619, 47554, 47619, 82306, 82691, 82306, 82691, 94210, 94467, 94210, 94467]\n",
        "\n",
        "    sanityCheckModel(cnn_init_inputs, CNN, cnn_init_expected_outputs, \"init\")\n",
        "    print()\n",
        "\n",
        "    # Test forward\n",
        "    cnn_forward_inputs = [{'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [3, 4, 5], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 1, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 2, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 10, 'batch_size': 50}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 1}, {'vocab_size': 1000, 'embed_size': 16, 'out_channels': 128, 'filter_heights': [5, 10], 'stride': 3, 'dropout': 0, 'num_classes': 3, 'pad_idx': 0, 'max_len': 100, 'batch_size': 50}]\n",
        "    cnn_forward_expected_outputs = [torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 2]), torch.Size([50, 2]), torch.Size([1, 3]), torch.Size([50, 3]), torch.Size([1, 3]), torch.Size([50, 3])]\n",
        "\n",
        "    sanityCheckModel(cnn_forward_inputs, CNN, cnn_forward_expected_outputs, \"forward\", makeCnnSanityBatch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupiBIfasCu_"
      },
      "source": [
        "## Train CNN Model\n",
        "\n",
        "First, we initialize the train and test <b>dataloaders</b>. A dataloader is responsible for providing batches of data to your model. Notice how we first instantiate datasets for the train and test data, and that we use the training vocabulary for both.\n",
        "\n",
        "You do not need to edit this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J2QYl334n9ON"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    THRESHOLD = 5 # Don't change this\n",
        "    MAX_LEN = 200 # Don't change this\n",
        "    BATCH_SIZE = 32 # Feel free to try other batch sizes\n",
        "\n",
        "    train_dataset = TextDataset(train_data, 'train', THRESHOLD, MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    test_dataset = TextDataset(test_data, 'test', THRESHOLD, MAX_LEN, train_dataset.idx2word, train_dataset.word2idx)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvsctopWmeoY"
      },
      "source": [
        "Now we provide you with a function that takes your model and trains it on the data.\n",
        "\n",
        "You do not need to edit this cell. However, you may want to write code to save your model periodically, as Colab connections are not permanent. See the tutorial here if you wish to do this: https://pytorch.org/tutorials/beginner/saving_loading_models.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LD-Jj2rUFOzr"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_cnn_model(model, num_epochs, data_loader, optimizer, criterion):\n",
        "    print('Training Model...')\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        for texts, labels in tqdm(data_loader):\n",
        "            texts = texts.to(DEVICE) # shape: [batch_size, MAX_LEN]\n",
        "            labels = labels.to(DEVICE) # shape: [batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(texts)\n",
        "            acc = accuracy(output, labels)\n",
        "            \n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        print('[TRAIN]\\t Epoch: {:2d}\\t Loss: {:.4f}\\t Train Accuracy: {:.2f}%'.format(epoch+1, epoch_loss/len(data_loader), 100*epoch_acc/len(data_loader)))\n",
        "    print('Model Trained!\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIZS0WUhFA6"
      },
      "source": [
        "Here are some other helper functions we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zVP2scuyhG5f"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch\n",
        "    output: Tensor [batch_size, n_classes]\n",
        "    labels: LongTensor [batch_size]\n",
        "    \"\"\"\n",
        "    preds = output.argmax(dim=1) # find predicted class\n",
        "    correct = (preds == labels).sum().float() # convert into float for division \n",
        "    acc = correct / len(labels)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjvX5c6Isw9e"
      },
      "source": [
        "Now you can instantiate your model. We provide you with some recommended hyperparameters; you should be able to get the desired accuracy with these, but feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "M5UtdjGDuBty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d43c33-77ee-4e35-aac4-ad31f7470c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 3,879,746 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    cnn_model = CNN(vocab_size = train_dataset.vocab_size, # Don't change this\n",
        "                embed_size = 128, \n",
        "                out_channels = 64, \n",
        "                filter_heights = [2, 3, 4], \n",
        "                stride = 1, \n",
        "                dropout = 0.5, \n",
        "                num_classes = 2, # Don't change this\n",
        "                pad_idx = train_dataset.word2idx[CNN_PAD]) # Don't change this\n",
        "\n",
        "    # Put your model on the device (cuda or cpu)\n",
        "    cnn_model = cnn_model.to(DEVICE)\n",
        "    \n",
        "    print('The model has {:,d} trainable parameters'.format(count_parameters(cnn_model)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeHpqw6zvkhI"
      },
      "source": [
        "Next, we create the **criterion**, which is our loss function: it is a measure of how well the model matches the empirical distribution of the data. We use cross-entropy loss (https://en.wikipedia.org/wiki/Cross_entropy).\n",
        "\n",
        "We also define the **optimizer**, which performs gradient descent. We use the Adam optimizer (https://arxiv.org/pdf/1412.6980.pdf), which has been shown to work well on these types of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FoeyQL4PoNoH"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__=='__main__':    \n",
        "    LEARNING_RATE = 5e-4 # Feel free to try other learning rates\n",
        "\n",
        "    # Define the loss function\n",
        "    criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "    # Define the optimizer\n",
        "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopLfAJ9wOHN"
      },
      "source": [
        "Finally, we can train the model. If the model is implemented correctly and you're using the GPU, this cell should take around <b>4 minutes</b> (or less). Feel free to change the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lPOs1FifoNoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "8ac159dc87194ff0b449004957c27d1c",
            "e582078932ae4a23b3a442e73da3ca9a",
            "ac8f9d7e4c364402bcd481d18646ef86",
            "403a174803f04264923ed7a859331358",
            "edc2b29e9d41494397ed2f0f926593c6",
            "b00b437bf049482fac8768c7478a4f28",
            "ef72536f248f49e185c7c898436c792b",
            "e7689894c97146a4842e2f25e3007bf0",
            "e1d6c6645980455580540a4ad1e5002e",
            "83764529bb914d0fbda28fd16c1a5ea5",
            "f12175feec3442e6aae5f04d9814c4c8",
            "1325f33a32a34cf2834c5f423502038b",
            "39fe3648b38844ffa9f1d345fd7497e5",
            "df65e3cc86f748eca16276a4332df7f3",
            "c62cdfd6a21c4ba3a83bde9cccfd1481",
            "c13bee128b204a2d8729663e89d19bba",
            "5452a920d9414af69dd61a2be7df7c8c",
            "0a2ab581d4d14e47851e00e4978e32dd",
            "7a2d1de7fcdb4757b954ba365e01c6de",
            "713604b357e04f6b8b0bf87571001475",
            "0f798c23b07441c889c0bb9aafc47515",
            "3f4bc42d451f4a4c949f5d188f8ad51c",
            "0698c738d2314436848a176da83c780c",
            "030e805119b74f1ea749f67cde2d3833",
            "b26f580ef4de48eab36c0c9a3237dbbe",
            "58090ace810949ccb33704b4465f4e08",
            "d75150f6b0284c768beba8daac3e64f8",
            "3605ee5a69ce46f798b20dce44d47074",
            "8425b86ac04c4d54b7ef5ab3a5e6c7b0",
            "5c6e62797adb42fea5a3cc9ac913f7bd",
            "86dc0d1ec62a43d48b984555e794ee2a",
            "a206266d7a284577bfc5558b7c3fa828",
            "a2453a032b0b46e1a9b95d589bb81702",
            "5db7a401cb5240ffbaf93531440fbf3f",
            "08ae54dc002649189a8239c003b1f2a6",
            "a822339fb5504d93b72e2cd4c6f069c3",
            "92cca41a83ca4247a28e5589138ddb04",
            "1d98b8929d1a47e6820453c303f8f851",
            "6dabe28a626143978653499267dad47d",
            "5cffc661bc854b11a1f6090aac71d537",
            "2e6f036c893f4320b2d279bf3ce91ac3",
            "b11519b60a514faa933bf8e6cf87da8d",
            "e3c0dc5228dc4c01bc2b49b90a58724d",
            "8f38be94bf71492d95d39dc994c562c1",
            "09245a77fbd143e7809c6b99cddc3035",
            "14615c60064443f886dfdc0b821df816",
            "7801b26328aa4b7a874e1c45ca7af928",
            "4b30ac7198be4b2c8458fcaf0c48e742",
            "e89b2929db9845c5b7a03f5434ae0a9e",
            "22535200d73142309433fd28c1a9e2fe",
            "e832f0eef4644e67b21337d6242415ef",
            "7d86a93377654525bbb9b222c6824c7c",
            "79ad5229bbe74a7f9fc01c48f514fa68",
            "bc93da66d4b54d37874f58a501242621",
            "11c7eaf548b540058e4b0ecc8c4de53b",
            "d45f25e426f1496abc577f2dfa92f454",
            "1a6ae2618b8c4dd989cb710599b50f0b",
            "247c859a39c1405f99da652df8ba60d2",
            "eba571f250ef4713b29fe0d04ed032a6",
            "d42afdd86a924785b9409f91d047dfb4",
            "439d61a8a2f44c36bb73d298ede41750",
            "0b300e46b0c74d639b700a7ea7123e1b",
            "754903083fcf425fbfc700ccccb411f6",
            "920205c1e1b04875a42371d396a352c0",
            "22bf123eae114b18b84195f2f89de11b",
            "d398cc14ac2d46dbbe298c719b74fb7b",
            "b157d90e2bb14ef49a6d32f65b5e5358",
            "63861df1daa54aeeae95796d852dd54d",
            "32f011d88bdd4d33aab775b848b5cfd3",
            "4d370240e805494b8e577cfcb9686f99",
            "2f4daede5fea4ced9ca315d620b59dcd",
            "4c00e3ccf4a54157aca4da0886da120b",
            "d8f4d5d73249415d91e1baa537945100",
            "38ae01f13d0a45c29e57ced1b770ea0d",
            "fbcfe8ecbec041b5a9a698cae18c2516",
            "2e06619778654cf0908960b8cc841e4b",
            "569ee002247f4999966bcb1d50247ed1",
            "da2fcb02ed0b4ec985603931d5e92f48",
            "ad9a0c09360548768b1f8fd1e1adc9cd",
            "04c1df08d665434dbf7be345b7d77ccb",
            "bbf2acff7dde400da7d5ff1e372da551",
            "91121b66001844b6b356834be9430b1f",
            "ce64be4329b540b685c744e799bb2d13",
            "aefaca834e584c2fa4c9e686a2249758",
            "772b6e6839d5439da7805ba6ba7960cc",
            "9e5db3b9a02f4113978241a5089768ab",
            "e71f0228321440648365f8955723de8e",
            "e49ed22a5064403fbf7e10581f345b15",
            "ad55f7b7fed84582bbea997372cf67ab",
            "fb5aa2959c0244899f67e40b50ded6ad",
            "e2fd32e6169e46639920bb40bb622923",
            "58b5261f663d433da173048e212ad5c7",
            "18d88d557173450cb2bf657f6edd5e43",
            "1c6105e7871e4c089e5b0cef69e0cb67",
            "9756b91623a8476e810862c15e6269d0",
            "b735e227d9434ec28dce34f2311bb9dd",
            "2a763d5000744a8fb20399a2021b89f5",
            "a341b2753f984c4cbd915f523a64215d",
            "b390aff7041c422c80980cc3ff2576a3",
            "74a9e9ddc18e42b2937fbf70cfece723",
            "72521e9f6f4e4d7e9d518b0b5fde2d20",
            "958a28fac7f04e21b5abfea15aa825be",
            "f184d07732cb4c26976d1dc866344dad",
            "f2d71442a147496b8eb053d527be98b7",
            "a5d8e47000cd410ba96f567b1baa1cff",
            "77d3751dece44f4990dc8e4e39ee5a20",
            "d6f76f2ae14e483e87f00e36831b3779",
            "4192b848cfc14ada9feb857b5f9026fb",
            "4fa58fa3e9aa4e338986a2b696c5484e",
            "b939e0c94fb14c4796720c3d3e301e81"
          ]
        },
        "outputId": "7da98256-0705-4c40-82ba-417aa2ee2cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ac159dc87194ff0b449004957c27d1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  1\t Loss: 0.6861\t Train Accuracy: 60.70%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1325f33a32a34cf2834c5f423502038b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  2\t Loss: 0.5473\t Train Accuracy: 72.11%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0698c738d2314436848a176da83c780c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  3\t Loss: 0.4942\t Train Accuracy: 75.76%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db7a401cb5240ffbaf93531440fbf3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  4\t Loss: 0.4543\t Train Accuracy: 78.52%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09245a77fbd143e7809c6b99cddc3035"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  5\t Loss: 0.4146\t Train Accuracy: 80.92%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d45f25e426f1496abc577f2dfa92f454"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  6\t Loss: 0.3777\t Train Accuracy: 82.92%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b157d90e2bb14ef49a6d32f65b5e5358"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  7\t Loss: 0.3396\t Train Accuracy: 85.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da2fcb02ed0b4ec985603931d5e92f48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  8\t Loss: 0.2996\t Train Accuracy: 87.09%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad55f7b7fed84582bbea997372cf67ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch:  9\t Loss: 0.2652\t Train Accuracy: 89.03%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/625 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74a9e9ddc18e42b2937fbf70cfece723"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]\t Epoch: 10\t Loss: 0.2244\t Train Accuracy: 90.78%\n",
            "Model Trained!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':    \n",
        "    N_EPOCHS = 10 # Feel free to change this\n",
        "    \n",
        "    # train model for N_EPOCHS epochs\n",
        "    train_cnn_model(cnn_model, N_EPOCHS, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-OJbZ72t6Yq"
      },
      "source": [
        "## Evaluate CNN Model [20 points]\n",
        "\n",
        "Now that we have trained a model for text classification, it is time to evaluate it. We have provided you with a function to do this; you do not need to modify anything.\n",
        "\n",
        "To pass the autograder for the CNN, you will need to achieve **82% accuracy** on the hidden test set on Gradescope. Note that the Gradescope test set is very similar, and the accuracies between the two datasets should be comparable.\n",
        "\n",
        "<font color='green'><b>Hint:</b> If you receive close to 82% accuracy in the notebook but close to 50% accuracy in the autograder, then the most likely causes are:\n",
        "1. You uploaded an untrained model checkpoint. Make sure you save the model after it is trained.\n",
        "2. Your `TextDataset` class is not deterministic in that the `word2idx` and `idx2word` mappings are not necessarily in the same order when the class is instantiated multiple times. This is a problem as your trained CNN will expect the words in the order seen in this notebook, but the autograder will be using a different ordering. If this is your issue, reimplement the `TextDataset` class so that it is deterministic, and then retrain and upload your model.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vTiiYDZIF--7"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "import random\n",
        "\n",
        "def evaluate(model, data_loader, criterion, use_tqdm=False):\n",
        "    print('Evaluating performance on the test dataset...')\n",
        "    has_printed=False\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    all_predictions = []\n",
        "    iterator = tqdm(data_loader) if use_tqdm else data_loader\n",
        "    total = 0\n",
        "    for texts, labels in iterator:\n",
        "        bs = texts.shape[0]\n",
        "        total += bs\n",
        "        texts = texts.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        \n",
        "        output = model(texts)\n",
        "        acc = accuracy(output, labels) * len(labels)\n",
        "        pred = output.argmax(dim=1)\n",
        "        all_predictions.append(pred)\n",
        "        \n",
        "        loss = criterion(output, labels) * len(labels)\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "        if random.random() < 0.0015 and bs == 1:\n",
        "            if not has_printed: print(\"\\nSOME PREDICTIONS FROM THE MODEL:\")\n",
        "            print(\"Input: \"+' '.join([data_loader.dataset.idx2word[idx] for idx in texts[0].tolist() if idx not in {data_loader.dataset.word2idx[CNN_PAD], data_loader.dataset.word2idx[CNN_END]}]))\n",
        "            print(\"Prediction:\", pred.item(), '\\tCorrect Output:', labels.item(), '\\n')\n",
        "            has_printed=True\n",
        "\n",
        "    full_acc = 100*epoch_acc/total\n",
        "    full_loss = epoch_loss/total\n",
        "    print('[TEST]\\t Loss: {:.4f}\\t Accuracy: {:.2f}%'.format(full_loss, full_acc))\n",
        "    predictions = torch.cat(all_predictions)\n",
        "    return predictions, full_acc, full_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z718w8e0oNoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "de9fa8019cf5420b996fb8f5dc8c41f5",
            "e510fe8ee59949d2a76150ca86f603d7",
            "7d24900ac877453e89bdba6dd74bf37d",
            "254c349b18694ebb81fcb4e8f93a46a3",
            "4bf8cebb623143cb89b121c3fcf76fa9",
            "3788f15fa7c048388a3bf301a7ff1eca",
            "b8d3c752d4f94854b91053fe5d4dfaa4",
            "b354d512d7504c6bbd8aa670e26fe594",
            "18f0d4bc6f84458684c0bdfb741b6bea",
            "8b4580dd873b4f1a9b0f3391f2a812fa",
            "823518d224a046d38822f49a5defec8a"
          ]
        },
        "outputId": "876324fa-d95e-4c06-a031-9586d2ffda73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating performance on the test dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de9fa8019cf5420b996fb8f5dc8c41f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SOME PREDICTIONS FROM THE MODEL:\n",
            "Input: i was browsing through netflix and stumbled upon this movie . having fond memories of the book as a child , i decided to check this out . this is a movie that you should really pass on.<br /><br />it is just not worth seeing . it is very boring and uninteresting . i feel that it would even be that way to small children . it has no magic that the book contains . this movie is not horrible , but you will just find yourself not caring ten minutes into it.<br /><br />there are moments that just come off as weird . the witch character is not very good . the family acts like it is no big deal that these odd things are happening . i know this is a kids movie , so as an older audience we must not look too deeply in things , but the whole movie just feels like it was written and produced by people who have never had any movie making experience before.<br /><br />the dvd that i had began skipping in the final moments of the film , and instead of trying to fix it i just turned it\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: what was franco <UNK> thinking ? was hollywood responsible for this travesty , or can i take comfort in the idea that someone who didn't speak english as a first language just completely missed the point of charlotte bronte's classic ? i don't think i can improve on a comment i read below , so i'll just paraphrase it : \" jane eyre is a great great book , the screenwriter should read it <UNK> \" it's true that this movie's two leads were sadly miscast . but pity the actors , because the screenwriter left out all of the best scenes . the dialog that makes you understand the jane and rochester have a meeting of minds and a shared sense of <UNK> from the script . the marriage proposal , the fortune <UNK> . the allusions , half joking , half sincerely felt , to jane as a fairy <UNK> from <UNK> england come to rescue rochester in his <UNK> /><br />it is unfortunate that <UNK> felt the need to completely rewrite the end of the novel and jane's interactions with the rivers family . but it is unforgivable that he has <UNK> removed the love from one\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: near the beginning of \" the godfather : part <UNK> \" michael <UNK> son wants to drop out of law school and become a musician . michael corleone does not want this . but his estranged ex-wife , kay , manages to convince him to let anthony corleone pursue music as he wishes . so he does.<br /><br />that seems like an odd way to start a review , as it is a minor plot point and has nothing really to do with the major action . just bear with me here ; you'll see where i'm going with this eventually . now let me tell you about the major plot . it is about michael corleone wanting to quit crime for good ( he has largely abandoned all criminal elements in his family <UNK> . but then along comes vincent <UNK> , an illegitimate nephew , who is involved in a feud . so of course michael must endure yet another brush with <UNK> and gun violence and all that good gangster stuff . meanwhile , vincent has a <UNK> affair with michael's daughter mary . oh , and michael and kay are trying to patch up all the\n",
            "Prediction: 0 \tCorrect Output: 0 \n",
            "\n",
            "Input: i enjoyed the cinematographic recreation of china in the 1930s in this beautiful film . the story is simple . an older male performer wants to pass on his art to a young man although he has no living children . the faces of the actors are marvelous to see . the story reveals the devotion and gratitude of children to those who treat them well and their longing to be treated well . the operas in the film remind me of farewell my <UNK> , which was more sophisticated and intricate . the story here reminds me of a dickens tale of days when children were almost <UNK> . the plot is a bit predictable and a bit too sentimental for me but well worth the time to view for the heroism , humanity , and history portrayed .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i watched this movie after seeing it on broadway . i love the broadway musical and i love the movie . i watched the movie like it was not related to the broadway show . i am an avid reader and have seen what happens to most books when they are turned into movies , so i developed a philosophy really early . assume that the movie is going to be based on the book (  or musical in this case ) but that while the story line may be similar it will not be the same , it will be different so watch it for what it is.<br /><br />i danced for 12 years before i had to make a choice . i was a good <UNK> picking up chorus work in local productions as a child etc ) but i wasn't super <UNK> was however super talented as a show rider . i was told by my dance instructor and my trainer (  who i spent several months a year at his farm out of state ) that i had to make a choice when i turned 14 . that i needed to move up from\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: i like the movie . twisted desire had jeremy <UNK> of my favorite and one of the cutest actors ever . melissa joan hart is a good actress . i've seen most of her movies but all of jeremy <UNK> . the thing i dislike about twisted desire is when \" nick \" gets arrested and \" jennifer \" rats him out . twisted desire is my second favorite movie . my first is the <UNK> . but i still love jeremy jordan .\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "Input: this is a plain old spooky ghost story . i showed it to some friends of mine in my movie club , and they were kept spellbound until the ending ! no blood or <UNK> just good old fashioned suspense . it starts out right from the beginning , and builds and builds . the ending is a real twist that caught me <UNK> . <br /><br />well directed and well acted . it is also a \" period <UNK> set in the <UNK> which added to the atmosphere . <br /><br />i was so impressed i got the book by susan hill from amazon . the movie follows the book rather closely . <br /><br />it's a shame it's not readily available on dvd . my copy is vhs . this along with \" haunted \" are probably two of the best ghost stories i've ever scene . which just goes to show that a little creativity outdoes \" in your face \" gore any day !\n",
            "Prediction: 1 \tCorrect Output: 1 \n",
            "\n",
            "[TEST]\t Loss: 0.4115\t Accuracy: 82.10%\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    evaluate(cnn_model, test_loader, criterion, use_tqdm=True) # Compute test data accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WQAV6O2xHvS"
      },
      "source": [
        "# What to Submit\n",
        "\n",
        "To submit the assignment, download this notebook as a <TT>.py</TT> file. You can do this by going to <TT>File > Download > Download .py</TT>. Then (optionally) rename it to `hwk2.py`.\n",
        "\n",
        "You will also need to save the `cnn_model` (you do not need to save anything additional for your word embeddings). You can run the cell below to do this. After you save the files to your Google Drive, you need to manually download the files to your computer, and then submit them to the autograder.\n",
        "\n",
        "You will submit the following files to the autograder:\n",
        "1.   `hwk2.py`, the download of this notebook as a `.py` file (**not** a `.ipynb` file)\n",
        "1.   `cnn.pt`, the saved version of your `cnn_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "abbbMNi8X_ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18ea7b9-74b5-4032-b750-37b987add6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Saving CNN model....\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "if __name__=='__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        cnn_model is None\n",
        "        cnn_exists = True\n",
        "    except:\n",
        "        cnn_exists = False\n",
        "\n",
        "    if cnn_exists:\n",
        "        print(\"Saving CNN model....\") \n",
        "        torch.save(cnn_model, \"drive/My Drive/cnn.pt\")\n",
        "    \n",
        "    print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZ0PAgpehIKT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "246c6d8b460a4133b0c1b8f9ec360f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62d58ad268e04dfca605b80a8723a10e",
              "IPY_MODEL_7229b6cbeb8240d5a15b2d5ef6d99660",
              "IPY_MODEL_0b4cec7870034dae8d30ed9227aefa7b"
            ],
            "layout": "IPY_MODEL_18a12d620d324e2ca00e26e60c39dc34"
          }
        },
        "62d58ad268e04dfca605b80a8723a10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4770f5f9962d46098398bcd5ea3f8ece",
            "placeholder": "​",
            "style": "IPY_MODEL_9e253eaceb2347cd8f8edc09e4303f9e",
            "value": "  1%"
          }
        },
        "7229b6cbeb8240d5a15b2d5ef6d99660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b93f927d8d4aee853292a3524910fe",
            "max": 1684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdb3b30a81de4e658d765e26acb59511",
            "value": 10
          }
        },
        "0b4cec7870034dae8d30ed9227aefa7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dd670015258479aad55c385b83ada16",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1b497a9c3445699d2fb5b460583a4b",
            "value": " 10/1684 [03:54&lt;8:59:08, 19.32s/it]"
          }
        },
        "18a12d620d324e2ca00e26e60c39dc34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4770f5f9962d46098398bcd5ea3f8ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e253eaceb2347cd8f8edc09e4303f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b93f927d8d4aee853292a3524910fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb3b30a81de4e658d765e26acb59511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dd670015258479aad55c385b83ada16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1b497a9c3445699d2fb5b460583a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac159dc87194ff0b449004957c27d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e582078932ae4a23b3a442e73da3ca9a",
              "IPY_MODEL_ac8f9d7e4c364402bcd481d18646ef86",
              "IPY_MODEL_403a174803f04264923ed7a859331358"
            ],
            "layout": "IPY_MODEL_edc2b29e9d41494397ed2f0f926593c6"
          }
        },
        "e582078932ae4a23b3a442e73da3ca9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00b437bf049482fac8768c7478a4f28",
            "placeholder": "​",
            "style": "IPY_MODEL_ef72536f248f49e185c7c898436c792b",
            "value": "100%"
          }
        },
        "ac8f9d7e4c364402bcd481d18646ef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7689894c97146a4842e2f25e3007bf0",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1d6c6645980455580540a4ad1e5002e",
            "value": 625
          }
        },
        "403a174803f04264923ed7a859331358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83764529bb914d0fbda28fd16c1a5ea5",
            "placeholder": "​",
            "style": "IPY_MODEL_f12175feec3442e6aae5f04d9814c4c8",
            "value": " 625/625 [00:12&lt;00:00, 119.88it/s]"
          }
        },
        "edc2b29e9d41494397ed2f0f926593c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00b437bf049482fac8768c7478a4f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef72536f248f49e185c7c898436c792b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7689894c97146a4842e2f25e3007bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d6c6645980455580540a4ad1e5002e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83764529bb914d0fbda28fd16c1a5ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12175feec3442e6aae5f04d9814c4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1325f33a32a34cf2834c5f423502038b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39fe3648b38844ffa9f1d345fd7497e5",
              "IPY_MODEL_df65e3cc86f748eca16276a4332df7f3",
              "IPY_MODEL_c62cdfd6a21c4ba3a83bde9cccfd1481"
            ],
            "layout": "IPY_MODEL_c13bee128b204a2d8729663e89d19bba"
          }
        },
        "39fe3648b38844ffa9f1d345fd7497e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5452a920d9414af69dd61a2be7df7c8c",
            "placeholder": "​",
            "style": "IPY_MODEL_0a2ab581d4d14e47851e00e4978e32dd",
            "value": "100%"
          }
        },
        "df65e3cc86f748eca16276a4332df7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2d1de7fcdb4757b954ba365e01c6de",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_713604b357e04f6b8b0bf87571001475",
            "value": 625
          }
        },
        "c62cdfd6a21c4ba3a83bde9cccfd1481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f798c23b07441c889c0bb9aafc47515",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4bc42d451f4a4c949f5d188f8ad51c",
            "value": " 625/625 [00:06&lt;00:00, 120.22it/s]"
          }
        },
        "c13bee128b204a2d8729663e89d19bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5452a920d9414af69dd61a2be7df7c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2ab581d4d14e47851e00e4978e32dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a2d1de7fcdb4757b954ba365e01c6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713604b357e04f6b8b0bf87571001475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f798c23b07441c889c0bb9aafc47515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4bc42d451f4a4c949f5d188f8ad51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0698c738d2314436848a176da83c780c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_030e805119b74f1ea749f67cde2d3833",
              "IPY_MODEL_b26f580ef4de48eab36c0c9a3237dbbe",
              "IPY_MODEL_58090ace810949ccb33704b4465f4e08"
            ],
            "layout": "IPY_MODEL_d75150f6b0284c768beba8daac3e64f8"
          }
        },
        "030e805119b74f1ea749f67cde2d3833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3605ee5a69ce46f798b20dce44d47074",
            "placeholder": "​",
            "style": "IPY_MODEL_8425b86ac04c4d54b7ef5ab3a5e6c7b0",
            "value": "100%"
          }
        },
        "b26f580ef4de48eab36c0c9a3237dbbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c6e62797adb42fea5a3cc9ac913f7bd",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86dc0d1ec62a43d48b984555e794ee2a",
            "value": 625
          }
        },
        "58090ace810949ccb33704b4465f4e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a206266d7a284577bfc5558b7c3fa828",
            "placeholder": "​",
            "style": "IPY_MODEL_a2453a032b0b46e1a9b95d589bb81702",
            "value": " 625/625 [00:05&lt;00:00, 119.42it/s]"
          }
        },
        "d75150f6b0284c768beba8daac3e64f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3605ee5a69ce46f798b20dce44d47074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8425b86ac04c4d54b7ef5ab3a5e6c7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c6e62797adb42fea5a3cc9ac913f7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86dc0d1ec62a43d48b984555e794ee2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a206266d7a284577bfc5558b7c3fa828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2453a032b0b46e1a9b95d589bb81702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db7a401cb5240ffbaf93531440fbf3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08ae54dc002649189a8239c003b1f2a6",
              "IPY_MODEL_a822339fb5504d93b72e2cd4c6f069c3",
              "IPY_MODEL_92cca41a83ca4247a28e5589138ddb04"
            ],
            "layout": "IPY_MODEL_1d98b8929d1a47e6820453c303f8f851"
          }
        },
        "08ae54dc002649189a8239c003b1f2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dabe28a626143978653499267dad47d",
            "placeholder": "​",
            "style": "IPY_MODEL_5cffc661bc854b11a1f6090aac71d537",
            "value": "100%"
          }
        },
        "a822339fb5504d93b72e2cd4c6f069c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e6f036c893f4320b2d279bf3ce91ac3",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b11519b60a514faa933bf8e6cf87da8d",
            "value": 625
          }
        },
        "92cca41a83ca4247a28e5589138ddb04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c0dc5228dc4c01bc2b49b90a58724d",
            "placeholder": "​",
            "style": "IPY_MODEL_8f38be94bf71492d95d39dc994c562c1",
            "value": " 625/625 [00:05&lt;00:00, 102.85it/s]"
          }
        },
        "1d98b8929d1a47e6820453c303f8f851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dabe28a626143978653499267dad47d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cffc661bc854b11a1f6090aac71d537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e6f036c893f4320b2d279bf3ce91ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11519b60a514faa933bf8e6cf87da8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3c0dc5228dc4c01bc2b49b90a58724d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f38be94bf71492d95d39dc994c562c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09245a77fbd143e7809c6b99cddc3035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14615c60064443f886dfdc0b821df816",
              "IPY_MODEL_7801b26328aa4b7a874e1c45ca7af928",
              "IPY_MODEL_4b30ac7198be4b2c8458fcaf0c48e742"
            ],
            "layout": "IPY_MODEL_e89b2929db9845c5b7a03f5434ae0a9e"
          }
        },
        "14615c60064443f886dfdc0b821df816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22535200d73142309433fd28c1a9e2fe",
            "placeholder": "​",
            "style": "IPY_MODEL_e832f0eef4644e67b21337d6242415ef",
            "value": "100%"
          }
        },
        "7801b26328aa4b7a874e1c45ca7af928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d86a93377654525bbb9b222c6824c7c",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79ad5229bbe74a7f9fc01c48f514fa68",
            "value": 625
          }
        },
        "4b30ac7198be4b2c8458fcaf0c48e742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc93da66d4b54d37874f58a501242621",
            "placeholder": "​",
            "style": "IPY_MODEL_11c7eaf548b540058e4b0ecc8c4de53b",
            "value": " 625/625 [00:06&lt;00:00, 121.26it/s]"
          }
        },
        "e89b2929db9845c5b7a03f5434ae0a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22535200d73142309433fd28c1a9e2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e832f0eef4644e67b21337d6242415ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d86a93377654525bbb9b222c6824c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ad5229bbe74a7f9fc01c48f514fa68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc93da66d4b54d37874f58a501242621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c7eaf548b540058e4b0ecc8c4de53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d45f25e426f1496abc577f2dfa92f454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a6ae2618b8c4dd989cb710599b50f0b",
              "IPY_MODEL_247c859a39c1405f99da652df8ba60d2",
              "IPY_MODEL_eba571f250ef4713b29fe0d04ed032a6"
            ],
            "layout": "IPY_MODEL_d42afdd86a924785b9409f91d047dfb4"
          }
        },
        "1a6ae2618b8c4dd989cb710599b50f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439d61a8a2f44c36bb73d298ede41750",
            "placeholder": "​",
            "style": "IPY_MODEL_0b300e46b0c74d639b700a7ea7123e1b",
            "value": "100%"
          }
        },
        "247c859a39c1405f99da652df8ba60d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754903083fcf425fbfc700ccccb411f6",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_920205c1e1b04875a42371d396a352c0",
            "value": 625
          }
        },
        "eba571f250ef4713b29fe0d04ed032a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bf123eae114b18b84195f2f89de11b",
            "placeholder": "​",
            "style": "IPY_MODEL_d398cc14ac2d46dbbe298c719b74fb7b",
            "value": " 625/625 [00:06&lt;00:00, 93.42it/s]"
          }
        },
        "d42afdd86a924785b9409f91d047dfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439d61a8a2f44c36bb73d298ede41750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b300e46b0c74d639b700a7ea7123e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754903083fcf425fbfc700ccccb411f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920205c1e1b04875a42371d396a352c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22bf123eae114b18b84195f2f89de11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d398cc14ac2d46dbbe298c719b74fb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b157d90e2bb14ef49a6d32f65b5e5358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63861df1daa54aeeae95796d852dd54d",
              "IPY_MODEL_32f011d88bdd4d33aab775b848b5cfd3",
              "IPY_MODEL_4d370240e805494b8e577cfcb9686f99"
            ],
            "layout": "IPY_MODEL_2f4daede5fea4ced9ca315d620b59dcd"
          }
        },
        "63861df1daa54aeeae95796d852dd54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c00e3ccf4a54157aca4da0886da120b",
            "placeholder": "​",
            "style": "IPY_MODEL_d8f4d5d73249415d91e1baa537945100",
            "value": "100%"
          }
        },
        "32f011d88bdd4d33aab775b848b5cfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ae01f13d0a45c29e57ced1b770ea0d",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbcfe8ecbec041b5a9a698cae18c2516",
            "value": 625
          }
        },
        "4d370240e805494b8e577cfcb9686f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e06619778654cf0908960b8cc841e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_569ee002247f4999966bcb1d50247ed1",
            "value": " 625/625 [00:05&lt;00:00, 121.99it/s]"
          }
        },
        "2f4daede5fea4ced9ca315d620b59dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c00e3ccf4a54157aca4da0886da120b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f4d5d73249415d91e1baa537945100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ae01f13d0a45c29e57ced1b770ea0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbcfe8ecbec041b5a9a698cae18c2516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e06619778654cf0908960b8cc841e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569ee002247f4999966bcb1d50247ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da2fcb02ed0b4ec985603931d5e92f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9a0c09360548768b1f8fd1e1adc9cd",
              "IPY_MODEL_04c1df08d665434dbf7be345b7d77ccb",
              "IPY_MODEL_bbf2acff7dde400da7d5ff1e372da551"
            ],
            "layout": "IPY_MODEL_91121b66001844b6b356834be9430b1f"
          }
        },
        "ad9a0c09360548768b1f8fd1e1adc9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce64be4329b540b685c744e799bb2d13",
            "placeholder": "​",
            "style": "IPY_MODEL_aefaca834e584c2fa4c9e686a2249758",
            "value": "100%"
          }
        },
        "04c1df08d665434dbf7be345b7d77ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772b6e6839d5439da7805ba6ba7960cc",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e5db3b9a02f4113978241a5089768ab",
            "value": 625
          }
        },
        "bbf2acff7dde400da7d5ff1e372da551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71f0228321440648365f8955723de8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e49ed22a5064403fbf7e10581f345b15",
            "value": " 625/625 [00:05&lt;00:00, 91.63it/s]"
          }
        },
        "91121b66001844b6b356834be9430b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce64be4329b540b685c744e799bb2d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aefaca834e584c2fa4c9e686a2249758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "772b6e6839d5439da7805ba6ba7960cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5db3b9a02f4113978241a5089768ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e71f0228321440648365f8955723de8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49ed22a5064403fbf7e10581f345b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad55f7b7fed84582bbea997372cf67ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb5aa2959c0244899f67e40b50ded6ad",
              "IPY_MODEL_e2fd32e6169e46639920bb40bb622923",
              "IPY_MODEL_58b5261f663d433da173048e212ad5c7"
            ],
            "layout": "IPY_MODEL_18d88d557173450cb2bf657f6edd5e43"
          }
        },
        "fb5aa2959c0244899f67e40b50ded6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6105e7871e4c089e5b0cef69e0cb67",
            "placeholder": "​",
            "style": "IPY_MODEL_9756b91623a8476e810862c15e6269d0",
            "value": "100%"
          }
        },
        "e2fd32e6169e46639920bb40bb622923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b735e227d9434ec28dce34f2311bb9dd",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a763d5000744a8fb20399a2021b89f5",
            "value": 625
          }
        },
        "58b5261f663d433da173048e212ad5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a341b2753f984c4cbd915f523a64215d",
            "placeholder": "​",
            "style": "IPY_MODEL_b390aff7041c422c80980cc3ff2576a3",
            "value": " 625/625 [00:05&lt;00:00, 112.04it/s]"
          }
        },
        "18d88d557173450cb2bf657f6edd5e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6105e7871e4c089e5b0cef69e0cb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9756b91623a8476e810862c15e6269d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b735e227d9434ec28dce34f2311bb9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a763d5000744a8fb20399a2021b89f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a341b2753f984c4cbd915f523a64215d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b390aff7041c422c80980cc3ff2576a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a9e9ddc18e42b2937fbf70cfece723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72521e9f6f4e4d7e9d518b0b5fde2d20",
              "IPY_MODEL_958a28fac7f04e21b5abfea15aa825be",
              "IPY_MODEL_f184d07732cb4c26976d1dc866344dad"
            ],
            "layout": "IPY_MODEL_f2d71442a147496b8eb053d527be98b7"
          }
        },
        "72521e9f6f4e4d7e9d518b0b5fde2d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d8e47000cd410ba96f567b1baa1cff",
            "placeholder": "​",
            "style": "IPY_MODEL_77d3751dece44f4990dc8e4e39ee5a20",
            "value": "100%"
          }
        },
        "958a28fac7f04e21b5abfea15aa825be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f76f2ae14e483e87f00e36831b3779",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4192b848cfc14ada9feb857b5f9026fb",
            "value": 625
          }
        },
        "f184d07732cb4c26976d1dc866344dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa58fa3e9aa4e338986a2b696c5484e",
            "placeholder": "​",
            "style": "IPY_MODEL_b939e0c94fb14c4796720c3d3e301e81",
            "value": " 625/625 [00:05&lt;00:00, 105.46it/s]"
          }
        },
        "f2d71442a147496b8eb053d527be98b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d8e47000cd410ba96f567b1baa1cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d3751dece44f4990dc8e4e39ee5a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f76f2ae14e483e87f00e36831b3779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4192b848cfc14ada9feb857b5f9026fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fa58fa3e9aa4e338986a2b696c5484e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b939e0c94fb14c4796720c3d3e301e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9fa8019cf5420b996fb8f5dc8c41f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e510fe8ee59949d2a76150ca86f603d7",
              "IPY_MODEL_7d24900ac877453e89bdba6dd74bf37d",
              "IPY_MODEL_254c349b18694ebb81fcb4e8f93a46a3"
            ],
            "layout": "IPY_MODEL_4bf8cebb623143cb89b121c3fcf76fa9"
          }
        },
        "e510fe8ee59949d2a76150ca86f603d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3788f15fa7c048388a3bf301a7ff1eca",
            "placeholder": "​",
            "style": "IPY_MODEL_b8d3c752d4f94854b91053fe5d4dfaa4",
            "value": "100%"
          }
        },
        "7d24900ac877453e89bdba6dd74bf37d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b354d512d7504c6bbd8aa670e26fe594",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18f0d4bc6f84458684c0bdfb741b6bea",
            "value": 5000
          }
        },
        "254c349b18694ebb81fcb4e8f93a46a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4580dd873b4f1a9b0f3391f2a812fa",
            "placeholder": "​",
            "style": "IPY_MODEL_823518d224a046d38822f49a5defec8a",
            "value": " 5000/5000 [00:16&lt;00:00, 315.11it/s]"
          }
        },
        "4bf8cebb623143cb89b121c3fcf76fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3788f15fa7c048388a3bf301a7ff1eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d3c752d4f94854b91053fe5d4dfaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b354d512d7504c6bbd8aa670e26fe594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f0d4bc6f84458684c0bdfb741b6bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b4580dd873b4f1a9b0f3391f2a812fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823518d224a046d38822f49a5defec8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}